
next up previous contents 



 

Next: References and further reading Up: Language models for information Previous: Language modeling versus other Contents Index 

Extended language modeling approaches

In this section we briefly mention some of the work that extends the basic language modeling approach.

There are other ways to think of using the language modeling idea in IR settings, and many of them have been tried in subsequent work. Rather

than looking at the probability of a document language model 



 generating the query, you can look at the probability of a query language model 



 generating the document. The main reason that doing things in this direction and creating a document likelihood model is less appealing is

that there is much less text available to estimate a language model based on the query text, and so the model will be worse estimated, and will have

to depend more on being smoothed with some other language model. On the other hand, it is easy to see how to incorporate relevance feedback

into such a model: you can expand the query with terms taken from relevant documents in the usual way and hence update the language model 



(Zhai and Lafferty, 2001a). Indeed, with appropriate modeling choices, this approach leads to the BIM model of Chapter 11 . The relevance

model of Lavrenko and Croft (2001) is an instance of a document likelihood model, which incorporates pseudo-relevance feedback into a

language modeling approach. It achieves very strong empirical results.

Figure 12.5: Three ways of developing the language modeling

approach: (a) query likelihood, (b) document likelihood, and (c)

model comparison.



Rather than directly generating in either direction, we can make a language model from both the document and query, and then ask how different

these two language models are from each other. Lafferty and Zhai (2001) lay out these three ways of thinking about the problem, which we show

in Figure 12.5 , and develop a general risk minimization approach for document retrieval. For instance, one way to model the risk of returning a

document 



 as relevant to a query 



 is to use the Kullback-Leibler (KL) divergence between their respective language models: 

(109)

KL divergence is an asymmetric divergence measure originating in information theory, which measures how bad the probability distribution 



 is

at modeling 



 (Manning and Schütze, 1999, Cover and Thomas, 1991). Lafferty and Zhai (2001) present results suggesting that a model

comparison approach outperforms both query-likelihood and document-likelihood approaches. One disadvantage of using KL divergence as a

ranking function is that scores are not comparable across queries. This does not matter for ad hoc retrieval, but is important in other applications

such as topic tracking. Kraaij and Spitters (2003) suggest an alternative proposal which models similarity as a normalized log-likelihood ratio (or,

equivalently, as a difference between cross-entropies).

Basic LMs do not address issues of alternate expression, that is, synonymy, or any deviation in use of language between queries and documents.

Berger and Lafferty (1999) introduce translation models to bridge this query-document gap. A translation model lets you generate query words

not in a document by translation to alternate terms with similar meaning. This also provides a basis for performing cross-language IR. We assume

that the translation model can be represented by a conditional probability distribution 

 between vocabulary terms. The form of the

translation query generation model is then: 

(110)

The term 

 is the basic document language model, and the term 

 performs translation. This model is clearly more computationally

intensive and we need to build a translation model. The translation model is usually built using separate resources (such as a traditional thesaurus or


bilingual dictionary or a statistical machine translation system's translation dictionary), but can be built using the document collection if there are

pieces of text that naturally paraphrase or summarize other pieces of text. Candidate examples are documents and their titles or abstracts, or

documents and anchor-text pointing to them in a hypertext environment.

Building extended LM approaches remains an active area of research. In general, translation models, relevance feedback models, and model

comparison approaches have all been demonstrated to improve performance over the basic query likelihood LM.

next up previous contents 



 

Next: References and further reading Up: Language models for information Previous: Language modeling versus other Contents Index

© 2008 Cambridge University Press

This is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.

2009-04-07

