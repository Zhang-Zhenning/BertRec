
Published in

Analytics Vidhya



Jul 21, 2019

·

5 min read

Viterbi algorithm for prediction with HMM — Part 3 of

the HMM series






Viterbi algorithm

this says to find the states that maximize the conditional probability of states given data.

mu function. It depends on its previous step, the transition and the emission matrices.

step 0. All three possible states are listed out for the initial state at time 0. The corresponding probability is assumed

to be some actual numbers to facilitate the following discussion.

step 1–1. For each possible first state, the best possible initial state is chosen. We find that initial state = 2 is most

likely to lead to first state = 1.

step 1–2. Here we find that initial state = 3 is most likely to lead to first state = 2.


step 1–3. We end Step 1 by finding the initial states that are mostly likely leading to the first state, and remembering

their probability values which will be re-used in the next step.

step 2. Repeating the procedure to go from step 0 to step 1 to get step 2 from step 1.

Summary

3

Analytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem

https://www.analyticsvidhya.com



Read more from Analytics Vidhya

Machine Learning

Viterbi

Hidden Markov Models

Hmm

Markov Chains






