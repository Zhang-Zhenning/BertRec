


Jan 10, 2020

·

11 min read

Introduction to Language Modelling and Deep Neural Network Based Text Generation

Introduction

Language Model




N-Gram Models

Limitations of N-gram models:

RNN’s (Recurrent Neural Networks):

Simple RNN architecture

Types of RNN


Image from Andrej Karpathy Blog “Unreasonable Effectiveness of Recurrent Neural Networks”

Pseudocode for RNN

Simple RNN unrolled over time

Disadvantages of RNN’s:

Short Term Dependencies:

sky

Image from Christopher Olah Blog “Understanding LSTM Networks”

Long Term Dependencies:

French

Image from Christopher Olah Blog “Understanding LSTM Networks”


LSTM:

The repeating module in an LSTM

Implementing Character Level Text Generation:

Image from François Chollet’s book of Deep Learning with Python


Sampling Strategy:

Image from François Chollet’s book of Deep Learning with Python

Training Data

Results:

Generated Text After 1st Epoch


Generated Text After 20th Epoch

Result Analysis:


Conclusion:

Referrences:



Follow

Machine Learning

NLP

Deep Learning

Text Generation

Language Model








