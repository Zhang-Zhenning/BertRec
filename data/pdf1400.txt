


Sep 29, 2020

·

7 min read

Building N-gram Language Model From Scratch

Generalization and Sensitivity:

Unknown words:




Context Specific:

Laplace Smoothing:

Add-k smoothing:

Kneser-Ney smoothing: 

IDENTIFYING CORPUS AND PREPROCESSING:

Europarl corpus


BUILD VOCABULARY:

Vocabulary created from preprocessed corpus.

BUILD MODEL:

Top 5 ngrams

Bigram Count

Bigram Model:

P(&lt;s&gt;,i) = C(&lt;s&gt;,i) / C(&lt;s&gt;)


= 21 / C(&lt;s&gt;)

Trigram Count

Trigram Model:

= 3/ 21

= 3/21

GENERATING TEXT

EVALUATING MODEL:

perplexity. 

Smoothing or Discounting. 

Kneser-Ney smoothing. 

Kneser-Ney smoothing

Perplexity calculation


Sources:

https://youtu.be/yGtC10JJNq8

https://youtu.be/Q3mZui3H6MM



Follow



Helping you build something Innovative…





NLP

Ngrams

Statistical Models

Language Model

