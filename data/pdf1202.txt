
1

INTRODUCTION TO INFORMATION THEORY

{ch:intro_info}

This chapter introduces some of the basic concepts of information theory, as well

as the deﬁnitions and notations of probabilities that will be used throughout

the book. The notion of entropy, which is fundamental to the whole topic of

this book, is introduced here. We also present the main questions of information

theory, data compression and error correction, and state Shannon’s theorems.

1.1

Random variables

The main object of this book will be the behavior of large sets of discrete

random variables. A discrete random variable X is completely deﬁned1 by

the set of values it can take, X, which we assume to be a ﬁnite set, and its

probability distribution {pX(x)}x∈X . The value pX(x) is the probability that

the random variable X takes the value x. The probability distribution pX : X →

[0, 1] must satisfy the normalization condition

�

x∈X

pX(x) = 1 .

(1.1)

{proba_norm}

We shall denote by P(A) the probability of an event A ⊆ X, so that pX(x) =

P(X = x). To lighten notations, when there is no ambiguity, we use p(x) to

denote pX(x).

If f(X) is a real valued function of the random variable X, the expectation

value of f(X), which we shall also call the average of f, is denoted by:

E f =

�

x∈X

pX(x)f(x) .

(1.2)

While our main focus will be on random variables taking values in ﬁnite

spaces, we shall sometimes make use of continuous random variables taking

values in Rd or in some smooth ﬁnite-dimensional manifold. The probability

measure for an ‘inﬁnitesimal element’ dx will be denoted by dpX(x). Each time

pX admits a density (with respect to the Lebesgue measure), we shall use the

notation pX(x) for the value of this density at the point x. The total probability

P(X ∈ A) that the variable X takes value in some (Borel) set A ⊆ X is given

by the integral:

1In probabilistic jargon (which we shall avoid hereafter), we take the probability space

(X, P(X), pX) where P(X) is the σ-ﬁeld of the parts of X and pX = P

x∈X pX(x) δx.

1


2

INTRODUCTION TO INFORMATION THEORY

P(X ∈ A) =

�

x∈A

dpX(x) =

�

I(x ∈ A) dpX(x) ,

(1.3)

where the second form uses the indicator function I(s) of a logical statement

s,which is deﬁned to be equal to 1 if the statement s is true, and equal to 0 if

the statement is false.

The expectation value of a real valued function f(x) is given by the integral

on X:

E f(X) =

�

f(x) dpX(x) .

(1.4)

Sometimes we may write EXf(X) for specifying the variable to be integrated

over. We shall often use the shorthand pdf for the probability density func-

tion pX(x).

Example 1.1 A fair dice with M faces has X = {1, 2, ..., M} and p(i) = 1/M

for all i ∈ {1, ..., M}. The average of x is E X = (1 + ... + M)/M = (M + 1)/2.

Example 1.2 Gaussian variable: a continuous variable X ∈ R has a Gaussian

distribution of mean m and variance σ2 if its probability density is

p(x) =

1

√

2πσ exp

�

−[x − m]2

2σ2

�

.

(1.5)

One has EX = m and E(X − m)2 = σ2.

The notations of this chapter mainly deal with discrete variables. Most of the

expressions can be transposed to the case of continuous variables by replacing

sums �

x by integrals and interpreting p(x) as a probability density.

Exercise 1.1 Jensen’s inequality. Let X be a random variable taking value

in a set X ⊆ R and f a convex function (i.e. a function such that ∀x, y and

∀α ∈ [0, 1]: f(αx + (1 − αy)) ≤ αf(x) + (1 − α)f(y)). Then

Ef(X) ≥ f(EX) .

(1.6)

{eq:Jensen}

Supposing for simplicity that X is a ﬁnite set with |X| = n, prove this equality

by recursion on n.

1.2

Entropy

{se:entropy}

The entropy HX of a discrete random variable X with probability distribution

p(x) is deﬁned as

HX ≡ −

�

x∈X

p(x) log2 p(x) = E log2

�

1

p(X)

�

,

(1.7)

{S_def}


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

ENTROPY

3

where we deﬁne by continuity 0 log2 0 = 0. We shall also use the notation H(p)

whenever we want to stress the dependence of the entropy upon the probability

distribution of X.

In this Chapter we use the logarithm to the base 2, which is well adapted

to digital communication, and the entropy is then expressed in bits. In other

contexts one rather uses the natural logarithm (to base e ≈ 2.7182818). It is

sometimes said that, in this case, entropy is measured in nats. In fact, the two

deﬁnitions diﬀer by a global multiplicative constant, which amounts to a change

of units. When there is no ambiguity we use H instead of HX.

Intuitively, the entropy gives a measure of the uncertainty of the random

variable. It is sometimes called the missing information: the larger the entropy,

the less a priori information one has on the value of the random variable. This

measure is roughly speaking the logarithm of the number of typical values that

the variable can take, as the following examples show.

Example 1.3 A fair coin has two values with equal probability. Its entropy is

1 bit.

Example 1.4 Imagine throwing M fair coins: the number of all possible out-

comes is 2M. The entropy equals M bits.

Example 1.5 A fair dice with M faces has entropy log2 M.

Example 1.6 Bernouilli process. A random variable X can take values 0, 1

with probabilities p(0) = q, p(1) = 1 − q. Its entropy is

HX = −q log2 q − (1 − q) log2(1 − q) ,

(1.8)

{S_bern}

it is plotted as a function of q in ﬁg.1.1. This entropy vanishes when q = 0

or q = 1 because the outcome is certain, it is maximal at q = 1/2 when the

uncertainty on the outcome is maximal.

Since Bernoulli variables are ubiquitous, it is convenient to introduce the

function H(q) ≡ −q log q − (1 − q) log(1 − q), for their entropy.

Exercise 1.2 An unfair dice with four faces and p(1) = 1/2,

p(2) =

1/4, p(3) = p(4) = 1/8 has entropy H = 7/4, smaller than the one of the

corresponding fair dice.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

4

INTRODUCTION TO INFORMATION THEORY

 0

 0.1

 0.2

 0.3

 0.4

 0.5

 0.6

 0.7

 0.8

 0.9

 1

 0

 0.1

 0.2

 0.3

 0.4

 0.5

 0.6

 0.7

 0.8

 0.9

 1

H(q)

q

Fig. 1.1. The entropy H(q) of a binary variable with p(X

= 0) = q,

p(X = 1) = 1 − q, plotted versus q

{fig_bernouilli}

Exercise 1.3 DNA is built from a sequence of bases which are of four types,

A,T,G,C. In natural DNA of primates, the four bases have nearly the same

frequency, and the entropy per base, if one makes the simplifying assumptions

of independence of the various bases, is H = − log2(1/4) = 2. In some genus of

bacteria, one can have big diﬀerences in concentrations: p(G) = p(C) = 0.38,

p(A) = p(T) = 0.12, giving a smaller entropy H ≈ 1.79.

Exercise 1.4 In some intuitive way, the entropy of a random variable is related

to the ‘risk’ or ‘surprise’ which are associated to it. In this example we discuss

a simple possibility for making these notions more precise.

Consider a gambler who bets on a sequence of bernouilli random variables

Xt ∈ {0, 1}, t ∈ {0, 1, 2, . . . } with mean EXt = p. Imagine he knows the

distribution of the Xt’s and, at time t he bets a fraction w(1) = p of his money

on 1 and a fraction w(0) = (1−p) on 0. He looses whatever is put on the wrong

number, while he doubles whatever has been put on the right one. Deﬁne the

average doubling rate of his wealth at time t as

Wt = 1

t E log2

�

t�

t′=1

2w(Xt′)

�

.

(1.9)

It is easy to prove that the expected doubling rate EWt is related to the entropy

of Xt: EWt = 1 − H(p). In other words, it is easier to make money out of

predictable events.

Another notion that is directly related to entropy is the Kullback-Leibler


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

ENTROPY

5

(KL) divergence between two probability distributions p(x) and q(x) over the

same ﬁnite space X. This is deﬁned as:

D(q||p) ≡

�

x∈X

q(x) log q(x)

p(x)

(1.10)

where we adopt the conventions 0 log 0 = 0, 0 log(0/0) = 0. It is easy to show

that: (i) D(q||p) is convex in q(x); (ii) D(q||p) ≥ 0; (iii) D(q||p) &gt; 0 unless

q(x) ≡ p(x). The last two properties derive from the concavity of the logarithm

(i.e. the fact that the function − log x is convex) and Jensen’s inequality (1.6):

if E denotes expectation with respect to the distribution q(x), then −D(q||p) =

E log[p(x)/q(x)] ≤ log E[p(x)/q(x)] = 0. The KL divergence D(q||p) thus looks

like a distance between the probability distributions q and p, although it is not

symmetric.

The importance of the entropy, and its use as a measure of information,

derives from the following properties:

1. HX ≥ 0.

2. HX = 0 if and only if the random variable X is certain, which means that

X takes one value with probability one.

3. Among all probability distributions on a set X with M elements, H is

maximum when all events x are equiprobable, with p(x) = 1/M. The

entropy is then HX = log2 M.

Notice in fact that, if X has M elements, then the KL divergence D(p||p)

between p(x) and the uniform distribution p(x) = 1/M is D(p||p) =

log2 M − H(p). The thesis follows from the properties of the KL diver-

gence mentioned above.

4. If X and Y are two independent random variables, meaning that pX,Y (x, y) =

pX(x)pY (y), the total entropy of the pair X, Y is equal to HX + HY :

HX,Y = −

�

x,y

p(x, y) log2 pX,Y (x, y) =

= −

�

x,y

pX(x)pY (y) (log2 pX(x) + log2 pY (y)) = HX + HY(1.11)

5. For any pair of random variables, one has in general HX,Y ≤ HX + HY ,

and this result is immediately generalizable to n variables. (The proof can

⋆

be obtained by using the positivity of the KL divergence D(p1||p2), where

p1 = pX,Y and p2 = pXpY ).

6. Additivity for composite events. Take a ﬁnite set of events X, and decom-

pose it into X = X1 ∪ X2, where X1 ∩ X2 = ∅. Call q1 = �

x∈X1 p(x)

the probability of X1, and q2 the probability of X2. For each x ∈ X1,

deﬁne as usual the conditional probability of x, given that x ∈ X1, by

r1(x) = p(x)/q1 and deﬁne similarly r2(x) as the conditional probability


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

6

INTRODUCTION TO INFORMATION THEORY

of x, given that x ∈ X2. Then the total entropy can be written as the sum

of two contributions HX = − �

x∈X p(x) log2 p(x) = H(q) + H(r), where:

H(q) = −q1 log2 q1 − q2 log2 q2

(1.12)

H(r) = −q1

�

x∈X1

r1(x) log2 r1(x) − q2

�

x∈X1

r2(x) log2 r2(x)

(1.13)

The proof is obvious by just substituting the laws r1 and r2 by their ex-

⋆

panded deﬁnitions. This property is interpreted as the fact that the average

information associated to the choice of an event x is additive, being the

sum of the relative information H(q) associated to a choice of subset, and

the information H(r) associated to the choice of the event inside the sub-

sets (weighted by the probability of the subsetss). It is the main property

of the entropy, which justiﬁes its use as a measure of information. In fact,

this is a simple example of the so called chain rule for conditional entropy,

which will be further illustrated in Sec. 1.4.

Conversely, these properties together with some hypotheses of continuity and

monotonicity can be used to deﬁne axiomatically the entropy.

1.3

Sequences of random variables and entropy rate

{sec:RandomVarSequences}

In many situations of interest one deals with a random process which generates

sequences of random variables {Xt}t∈N, each of them taking values in the

same ﬁnite space X. We denote by PN(x1, . . . , xN) the joint probability dis-

tribution of the ﬁrst N variables. If A ⊂ {1, . . . , N} is a subset of indices, we

shall denote by A its complement A = {1, . . . , N} \ A and use the notations

xA = {xi, i ∈ A} and xA = {xi, i ∈ A}. The marginal distribution of the

variables in A is obtained by summing PN on the variables in A:

PA(xA) =

�

xA

PN(x1, . . . , xN) .

(1.14)

Example 1.7 The simplest case is when the Xt’s are independent. This

means that PN(x1, . . . , xN) = p1(x1)p2(x2) . . . pN(xN). If all the distributions

pi are identical, equal to p, the variables are independent identically dis-

tributed, which will be abbreviated as iid. The joint distribution is

PN(x1, . . . , xN) =

N

�

t=1

p(xi) .

(1.15)


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

SEQUENCES OF RANDOM VARIABLES AND ENTROPY RATE

7

Example 1.8 The sequence {Xt}t∈N is said to be a Markov chain if

PN(x1, . . . , xN) = p1(x1)

N−1

�

t=1

w(xt → xt+1) .

(1.16)

Here {p1(x)}x∈X is called the initial state, and {w(x → y)}x,y∈X are the

transition probabilities of the chain. The transition probabilities must be

non-negative and normalized:

�

y∈X

w(x → y) = 1 ,

for any y ∈ X.

(1.17)

When we have a sequence of random variables generated by a certain process,

it is intuitively clear that the entropy grows with the number N of variables. This

intuition suggests to deﬁne the entropy rate of a sequence {Xt}t∈N as

hX = lim

N→∞ HXN /N ,

(1.18)

if the limit exists. The following examples should convince the reader that the

above deﬁnition is meaningful.

Example 1.9 If the Xt’s are i.i.d. random variables with distribution

{p(x)}x∈X , the additivity of entropy implies

hX = H(p) = −

�

x∈X

p(x) log p(x) .

(1.19)


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

8

INTRODUCTION TO INFORMATION THEORY

Example 1.10 Let {Xt}t∈N be a Markov chain with initial state {p1(x)}x∈X

and transition probabilities {w(x → y)}x,y∈X . Call {pt(x)}x∈X the marginal

distribution of Xt and assume the following limit to exist independently of the

initial condition:

p∗(x) = lim

t→∞ pt(x) .

(1.20)

As we shall see in chapter 4, this turns indeed to be true under quite mild

hypotheses on the transition probabilities {w(x → y)}x,y∈X . Then it is easy to

show that

hX = −

�

x,y∈X

p∗(x) w(x → y) log w(x → y) .

(1.21)

If you imagine for instance that a text in English is generated by picking letters

randomly in the alphabet X, with empirically determined transition probabil-

ities w(x → y), then Eq. (1.21) gives a ﬁrst estimate of the entropy of English.

But if you want to generate a text which looks like English, you need a more

general process, for instance one which will generate a new letter xt+1 given the

value of the k previous letters xt, xt−1, ..., xt−k+1, through transition probabil-

ities w(xt, xt−1, ..., xt−k+1

→

xt+1). Computing the corresponding entropy

rate is easy. For k = 4 one gets an entropy of 2.8 bits per letter, much smaller

than the trivial upper bound log2 27 (there are 26 letters, plus the space sym-

bols), but many words so generated are still not correct English words. Some

better estimates of the entropy of English, through guessing experiments, give

a number around 1.3.

1.4

Correlated variables and mutual entropy

{se:CorrelatedVariables}

Given two random variables X and Y , taking values in X and Y, we denote their

joint probability distribution as pX,Y (x, y), which is abbreviated as p(x, y), and

the conditional probability distribution for the variable y given x as pY |X(y|x),

abbreviated as p(y|x). The reader should be familiar with Bayes’ classical theo-

rem:

p(y|x) = p(x, y)/p(x) .

(1.22)

When the random variables X and Y are independent, p(y|x) is x-independent.

When the variables are dependent, it is interesting to have a measure on their

degree of dependence: how much information does one obtain on the value of y

if one knows x? The notions of conditional entropy and mutual entropy will be

useful in this respect.

Let us deﬁne the conditional entropy HY |X as the entropy of the law

p(y|x), averaged over x:

HY |X ≡ −

�

x∈X

p(x)

�

y∈Y

p(y|x) log2 p(y|x) .

(1.23)

{Scond_def}


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

CORRELATED VARIABLES AND MUTUAL ENTROPY

9

The total entropy HX,Y ≡ − �

x∈X,y∈Y p(x, y) log2 p(x, y) of the pair of variables

x, y can be written as the entropy of x plus the conditional entropy of y given x:

HX,Y = HX + HY |X .

(1.24)

In the simple case where the two variables are independent, HY |X = HY ,

and HX,Y = HX + HY . One way to measure the correlation of the two variables

is the mutual entropy IX,Y which is deﬁned as:

IX,Y ≡

�

x∈X,y∈Y

p(x, y) log2

p(x, y)

p(x)p(y) .

(1.25)

{Smut_def}

It is related to the conditional entropies by:

IX,Y = HY − HY |X = HX − HX|Y ,

(1.26)

which shows that IX,Y measures the reduction in the uncertainty of x due to the

knowledge of y, and is symmetric in x, y.

Proposition 1.11 IX,Y ≥ 0. Moreover IX,Y = 0 if and only if X and Y are

independent variables.

Proof: Write −IX,Y = Ex,y log2

p(x)p(y)

p(x,y) . Consider the random variable u =

(x, y) with probability distribution p(x, y). As the logarithm is a concave function

(i.e. -log is a convex function), one and applies Jensen’s inequality (1.6). This

gives the result IX,Y ≥ 0 □

Exercise 1.5 A large group of friends plays the following game (telephone

without cables). The guy number zero chooses a number X0 ∈ {0, 1} with

equal probability and communicates it to the ﬁrst one without letting the

others hear, and so on. The ﬁrst guy communicates the number to the second

one, without letting anyone else hear. Call Xn the number communicated from

the n-th to the (n+1)-th guy. Assume that, at each step a guy gets confused and

communicates the wrong number with probability p. How much information

does the n-th person have about the choice of the ﬁrst one?

We can quantify this information through IX0,Xn ≡ In. A simple calculation

shows that In = 1 − H(pn) with pn given by 1 − 2pn = (1 − 2p)n. In particular,

as n → ∞

In = (1 − 2p)2n

2 log 2

�

1 + O((1 − 2p)2n)

�

.

(1.27)

The ‘knowledge’ about the original choice decreases exponentially along the

chain.

The mutual entropy gets degraded when data is transmitted or processed.

This is quantiﬁed by:


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

10

INTRODUCTION TO INFORMATION THEORY

Proposition 1.12 Data processing inequality.

Consider a Markov chain X → Y → Z (so that the joint probability of the

three varaibles can be written as p1(x)w2(x → y)w3(y → z)). Then: IX,Z ≤ IX,Y .

In particular, if we apply this result to the case where Z is a function of Y ,

Z = f(Y ), we ﬁnd that applying f degrades the information: IX,f(Y ) ≤ IX,Y .

Proof: Let us introduce, in general, the mutual entropy of two varaibles con-

ditioned to a third one: IX,Y |Z = HX|Z − HX,(Y Z). The mutual information

between a variable X and a pair of varaibles (Y Z) can be decomposed in a sort

of chain rule: IX,(Y Z) = IX,Z + IX,Y |Z = IX,Y + IX,Z|Y . If we have a Markov

chain X → Y → Z, X and Z are independent when one conditions on the value

of Y , therefore IX,Z|Y = 0. The result follows from the fact that IX,Y |Z ≥ 0. □

1.5

Data compression

Imagine an information source which generates a sequence of symbols X =

{X1, . . . , XN} taking values in a ﬁnite alphabet X. Let us assume a probabilistic

model for the source: this means that the Xi’s are taken to be random variables.

We want to store the information contained in a given realization x = {x1 . . . xN}

of the source in the most compact way.

This is the basic problem of source coding. Apart from being an issue of

utmost practical interest, it is a very instructive subject. It allows in fact to

formalize in a concrete fashion the intuitions of ‘information’ and ‘uncertainty’

which are associated to the deﬁnition of entropy. Since entropy will play a crucial

role throughout the book, we present here a little detour into source coding.

1.5.1

Codewords

We ﬁrst need to formalize what is meant by “storing the information”. We deﬁne2

therefore a source code for the random variable X to be a mapping w which

associates to any possible information sequence in X N a string in a reference

alphabet which we shall assume to be {0, 1}:

w : X N→ {0, 1}∗

x �→ w(x) .

(1.28)

Here we used the convention of denoting by {0, 1}∗ the set of binary strings

of arbitrary length. Any binary string which is in the image of w is called a

codeword.

Often the sequence of symbols X1 . . . XN is a part of a longer stream. The

compression of this stream is realized in three steps. First the stream is broken

into blocks of length N. Then each block is encoded separately using w. Finally

the codewords are glued to form a new (hopefully more compact) stream. If

the original stream consisted in the blocks x(1), x(2), . . . , x(r), the output of the

2The expert will notice that here we are restricting our attention to “ﬁxed-to-variable”

codes.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

DATA COMPRESSION

11

encoding process will be the concatenation of w(x(1)), . . . , w(x(r)). In general

there is more than one way of parsing this concatenation into codewords, which

may cause troubles to any one willing to recover the compressed data. We shall

therefore require the code w to be such that any concatenation of codewords can

be parsed unambiguously. The mappings w satisfying this property are called

uniquely decodable codes.

Unique decodability is surely satisﬁed if, for any pair x, x′ ∈ X N, w(x) is

not a preﬁx of w(x′). If this stronger condition is veriﬁed, the code is said to be

instantaneous (see Fig. 1.2). Hereafter we shall focus on instantaneous codes,

since they are both practical and (slightly) simpler to analyze.

Now that we precised how to store information, namely using a source code,

it is useful to introduce some ﬁgure of merit for source codes. If lw(x) is the

length of the string w(x), the average length of the code is:

L(w) =

�

x∈X N

p(x) lw(x) .

(1.29)

{avlength}

Example 1.13 Take N = 1 and consider a random variable X which takes

values in X = {1, 2, . . . , 8} with probabilities p(1) = 1/2, p(2) = 1/4, p(3) =

1/8, p(4) = 1/16, p(5) = 1/32, p(6) = 1/64, p(7) = 1/128, p(8) = 1/128.

Consider the two codes w1 and w2 deﬁned by the table below

x p(x) w1(x)

w2(x)

1

1/2

000

0

2

1/4

001

10

3

1/8

010

110

4 1/16

011

1110

5 1/32

100

11110

6 1/64

101

111110

7 1/128

110

1111110

8 1/128

111

11111110

(1.30)

These two codes are instantaneous. For instance looking at the code w2, the

encoded string 10001101110010 can be parsed in only one way since each symbol

0 ends a codeword. It thus corresponds to the sequence x1 = 2, x2 = 1, x3 =

1, x4 = 3, x5 = 4, x6 = 1, x7 = 2. The average length of code w1 is L(w1) = 3,

the average length of code w2 is L(w2) = 247/128. Notice that w2 achieves a

shorter average length because it assigns the shortest codeword (namely 0) to

the most probable symbol (i.e. 1).


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

12

INTRODUCTION TO INFORMATION THEORY

000

001

101

11

0

1

1

0

1

1

0

0

1

0

0

1

0

1

Fig. 1.2. An instantaneous source code: each codeword is assigned to a node in

a binary tree in such a way that no one among them is the ancestor of another

one. Here the four codewords are framed.

{fig_kraft}

Example 1.14 A useful graphical representation of source code is obtained by

drawing a binary tree and associating each codeword to the corresponding node

in the tree. In Fig. 1.2 we represent in this way a source code with |X N| =

4. It is quite easy to recognize that the code is indeed instantaneous. The

codewords, which are framed, are such that no codeword is the ancestor of

any other codeword in the tree. Given a sequence of codewords, parsing is

immediate. For instance the sequence 00111000101001 can be parsed only in

001, 11, 000, 101, 001

1.5.2

Optimal compression and entropy

Suppose to have a ‘complete probabilistic characterization’ of the source you

want to compress. What is the ‘best code’ w for this source? What is the shortest

achievable average length?

This problem was solved (up to minor reﬁnements) by Shannon in his cel-

ebrated 1948 paper, by connecting the best achievable average length to the

entropy of the source. Following Shannon we assume to know the probability

distribution of the source p(x) (this is what ‘complete probabilistic character-

ization’ means). Moreover we interpret ‘best’ as ‘having the shortest average

length’.

{theorem:ShannonSource}

Theorem 1.15 Let L∗

N the shortest average length achievable by an instanta-

neous code for X = {X1, . . . , XN}, and HX the entropy of the same variable.

Then

1. For any N ≥ 1:

HX ≤ L∗

N ≤ HX + 1 .

(1.31)

{Shcomp1}

2. If the source has a ﬁnite entropy rate h = limN→∞ HX/N, then

lim

N→∞

1

N L∗

N = h .

(1.32)

{Shcomp2}

Proof: The basic idea in the proof of Eq. (1.31) is that, if the codewords

were too short, the code wouldn’t be instantaneous. ‘Kraft’s inequality’ makes


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

DATA COMPRESSION

13

this simple remark more precise. For any instantaneous code w, the lengths lw(x)

satisfy:

�

x∈X N

2−lw(x) ≤ 1 .

(1.33)

{kraft}

This fact is easily proved by representing the set of codewords as a set of leaves

on a binary tree (see ﬁg.1.2). Let LM be the length of the longest codeword.

Consider the set of all the 2LM possible vertices in the binary tree which are

at the generation LM, let us call them the ’descendants’. If the information x

is associated with a codeword at generation l (i.e. lw(x) = l), there can be no

other codewords in the branch of the tree rooted on this codeword, because the

code is instantaneous. We ’erase’ the corresponding 2LM −l descendants which

cannot be codewords. The subsets of erased descendants associated with each

codeword are not overlapping. Therefore the total number of erased descendants,

�

x 2LM −lw(x), must be smaller or equal to the total number of descendants, 2LM .

This establishes Kraft’s inequality.

Conversely, for any set of lengths {l(x)}x∈X N which satisﬁes the inequality

(1.33) there exist at least a code, whose codewords have the lengths {l(x)}x∈X N .

A possible construction is obtained as follows. Consider the smallest length l(x)

and take the ﬁrst allowed binary sequence of length l(x) to be the codeword for

x. Repeat this operation with the next shortest length, and so on until you have

exhausted all the codewords. It is easy to show that this procedure is successful

if Eq. (1.33) is satisﬁed.

The problem is therefore reduced to ﬁnding the set of codeword lengths l(x) =

l∗(x) which minimize the average length L = �

x p(x)l(x) subject to Kraft’s

inequality (1.33). Supposing ﬁrst that l(x) are real numbers, this is easily done

with Lagrange multipliers, and leads to l(x) = − log2 p(x). This set of optimal

lengths, which in general cannot be realized because some of the l(x) are not

integers, gives an average length equal to the entropy HX. This gives the lower

bound in (1.31). In order to build a real code with integer lengths, we use

l∗(x) = ⌈− log2 p(x)⌉ .

(1.34)

Such a code satisﬁes Kraft’s inequality, and its average length is less or equal

than HX + 1, proving the upper bound in (1.31).

The second part of the theorem is a straightforward consequence of the ﬁrst

one. □

The code we have constructed in the proof is often called a Shannon code.

For long strings (N ≫ 1), it gets close to optimal. However it has no reason to be

optimal in general. For instance if only one p(x) is very small, it will code it on

a very long codeword, while shorter codewords are available. It is interesting to

know that, for a given source {X1, . . . , XN}, there exists an explicit construction

of the optimal code, called Huﬀman’s code.

At ﬁrst sight, it may appear that Theorem 1.15, together with the construc-

tion of Shannon codes, completely solves the source coding problem. But this is

far from true, as the following arguments show.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

14

INTRODUCTION TO INFORMATION THEORY

From a computational point of view, the encoding procedure described above

is unpractical. One can build the code once for all, and store it somewhere, but

this requires O(|X|N) memory. On the other hand, one could reconstruct the

code each time a string requires to be encoded, but this takes O(|X|N) time.

One can use the same code and be a bit smarter in the encoding procedure, but

this does not improve things dramatically.

From a practical point of view, the construction of a Shannon code requires

an accurate knowledge of the probabilistic law of the source. Suppose now you

want to compress the complete works of Shakespeare. It is exceedingly diﬃcult

to construct a good model for the source ‘Shakespeare’. Even worse: when you

will ﬁnally have such a model, it will be of little use to compress Dante or Racine.

Happily, source coding has made tremendous progresses in both directions in

the last half century.

1.6

Data transmission

{sec:DataTransmission}

In the previous pages we considered the problem of encoding some information

in a string of symbols (we used bits, but any ﬁnite alphabet is equally good).

Suppose now we want to communicate this string. When the string is transmit-

ted, it may be corrupted by some noise, which depends on the physical device

used in the transmission. One can reduce this problem by adding redundancy to

the string. The redundancy is to be used to correct (some) transmission errors, in

the same way as redundancy in the English language can be used to correct some

of the typos in this book. This is the ﬁeld of channel coding. A central result

in information theory, again due to Shannon’s pioneering work in 1948, relates

the level of redundancy to the maximal level of noise that can be tolerated for

error-free transmission. The entropy again plays a key role in this result. This

is not surprising in view of the symmetry between the two problems. In data

compression, one wants to reduce the redundancy of the data, and the entropy

gives a measure of the ultimate possible reduction. In data transmission, one

wants to add some well tailored redundancy to the data.

1.6.1

Communication channels

The typical ﬂowchart of a communication system is shown in Fig. 1.3. It applies

to situations as diverse as communication between the earth and a satellite, the

cellular phones, or storage within the hard disk of your computer. Alice wants

to send a message m to Bob. Let us assume that m is a M bit sequence. This

message is ﬁrst encoded into a longer one, a N bit message denoted by x with

N &gt; M, where the added bits will provide the redundancy used to correct for

transmission errors. The encoder is a map from {0, 1}M to {0, 1}N. The encoded

message is sent through the communication channel. The output of the channel

is a message y. In a noiseless channel, one would simply have y = x. In a realistic

channel, y is in general a string of symbols diﬀerent from x. Notice that y is

not even necessarily a string of bits. The channel will be described by the

transition probability Q(y|x). This is the probability that the received signal is


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

DATA TRANSMISSION

15

Encoder

Decoder

Channel

Transmission

m

x

y

m’

Original 

message

M bits

message

Received 

Encoded

message

N bits

Estimate of the

original message

M bits

Fig. 1.3. Typical ﬂowchart of a communication device.

{fig_channel}

y, conditional to the transmitted signal being x. Diﬀerent physical channels will

be described by diﬀerent Q(y|x) functions. The decoder takes the message y and

deduces from it an estimate m′ of the sent message.

Exercise 1.6 Consider the following example of a channel with insertions.

When a bit x is fed into the channel, either x or x0 are received with equal

probability 1/2. Suppose that you send the string 111110. The string 1111100

will be received with probability 2 · 1/64 (the same output can be produced by

an error either on the 5th or on the 6th digit). Notice that the output of this

channel is a bit string which is always longer or equal to the transmitted one.

A simple code for this channel is easily constructed: use the string 100 for

each 0 in the original message and 1100 for each 1. Then for instance you have

the encoding

01101 �→ 100110011001001100 .

(1.35)

The reader is invited to deﬁne a decoding algorithm and verify its eﬀectiveness.

Hereafter we shall consider memoryless channels. In this case, for any input

x = (x1, ..., xN), the output message is a string of N letters, y = (y1, ..., yN), from

an alphabet Y ∋ yi (not necessarily binary). In memoryless channels, the noise

acts independently on each bit of the input. This means that the conditional

probability Q(y|x) factorizes:

Q(y|x) =

N

�

i=1

Q(yi|xi) ,

(1.36)

and the transition probability Q(yi|xi) is i independent.

Example 1.16 Binary symmetric channel (BSC). The input xi and the

output yi are both in {0, 1}. The channel is characterized by one number, the

probability p that an input bit is transmitted as the opposite bit. It is customary

to represent it by the diagram of Fig. 1.4.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

16

INTRODUCTION TO INFORMATION THEORY

0

0

1

1

1−p

1−p

p

 

p

1−p

p

p

1−p

0

0 

1

1

e

0

0

1

1

1−p

 

1

p

Fig. 1.4. Three communication channels. Left: the binary symmetric channel.

An error in the transmission, in which the output bit is the opposite of the input

one, occurs with probability p. Middle: the binary erasure channel. An error in

the transmission, signaled by the output e, occurs with probability p. Right: the

Z channel. An error occurs with probability p whenever a 1 is transmitted.

{fig_bsc}

Example 1.17 Binary erasure channel (BEC). In this case some of the

input bits are erased instead of being corrupted: xi is still in {0, 1}, but yi

now belongs to {0, 1, e}, where e means erased. In the symmetric case, this

channel is described by a single number, the probability p that a bit is erased,

see Fig. 1.4.

Example 1.18 Z channel. In this case the output alphabet is again {0, 1}.

Moreover, a 0 is always transmitted correctly, while a 1 becomes a 0 with

probability p. The name of this channel come from its graphical representation,

see Fig. 1.4.

A very important characteristics of a channel is the channel capacity C. It

is deﬁned in terms of the mutual entropy IXY of the variables X (the bit which

was sent) and Y (the signal which was received), through:

C = max

p(x) IXY = max

p(x)

�

x∈X,y∈Y

p(x, y) log2

p(x, y)

p(x)p(y)

(1.37)

{capadef}

We recall that I measures the reduction on the uncertainty of x due to the

knowledge of y. The capacity C gives a measure of how faithful a channel can

be: If the output of the channel is pure noise, x and y are uncorrelated and

C = 0. At the other extreme if y = f(x) is known for sure, given x, then

C = max{p(x)} H(p) = 1 bit. The interest of the capacity will become clear in

section 1.6.3 with Shannon’s coding theorem which shows that C characterizes

the amount of information which can be transmitted faithfully in a channel.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

DATA TRANSMISSION

17

Example 1.19 Consider a binary symmetric channel with ﬂip probability p.

Let us call q the probability that the source sends x = 0, and 1 − q the prob-

ability of x = 1. It is easy to show that the mutual information in Eq. (1.37)

is maximized when zeros and ones are transmitted with equal probability (i.e.

when q = 1/2).

Using the expression (1.37), we get, C = 1 − H(p) bits, where H(p) is the

entropy of Bernouilli’s process with parameter p (plotted in Fig. 1.1).

Example 1.20 Consider now the binary erasure channel with error probabil-

ity p. The same argument as above applies. It is therefore easy to get C = 1−p.

Exercise 1.7 Compute the capacity of the Z channel.

1.6.2

Error correcting codes

{sec:ECC}

The only ingredient which we still need to specify in order to have a complete

deﬁnition of the channel coding problem, is the behavior of the information

source. We shall assume it to produce a sequence of uncorrelated unbiased bits.

This may seem at ﬁrst a very crude model for any real information source.

Surprisingly, Shannon’s source-channel separation theorem assures that there is

indeed no loss of generality in treating this case.

The sequence of bits produced by the source is divided in blocks m1, m2, m3, . . .

of length M. The encoding is a mapping from {0, 1}M ∋ m to {0, 1}N, with

N ≥ M. Each possible M-bit message m is mapped to a codeword x(m) which

is a point in the N-dimensional unit hypercube. The codeword length N is also

called the blocklength. There are 2M codewords, and the set of all possible

codewords is called the codebook. When the message is transmitted, the code-

word x is corrupted to y ∈ YN with probability Q(y|x) = �N

i=1 Q(yi|xi). The

output alphabet Y depends on the channel. The decoding is a mapping from

YN to {0, 1}M which takes the received message y ∈ YN and maps it to one of

the possible original messages m′ = d(y) ∈ {0, 1}M.

An error correcting code is deﬁned by the set of two functions, the encod-

ing x(m) and the decoding d(y). The ratio

R = M

N

(1.38)

of the original number of bits to the transmitted number of bits is called the rate

of the code. The rate is a measure of the redundancy of the code. The smaller

the rate, the more redundancy is added to the code, and the more errors one

should be able to correct.

The block error probability of a code on the input message m, denoted

by PB(m), is given by the probability that the decoded messages diﬀers from the

one which was sent:


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

18

INTRODUCTION TO INFORMATION THEORY

PB(m) =

�

y

Q(y|x(m)) I(d(y) ̸= m) .

(1.39)

Knowing thee probability for each possible transmitted message is an exceedingly

detailed characterization of the code performances. One can therefore introduce

a maximal block error probability as

Pmax

B

≡

max

m∈{0,1}M PB(m) .

(1.40)

This corresponds to characterizing the code by its ‘worst case’ performances.

A more optimistic point of view consists in averaging over the input messages.

Since we assumed all of them to be equiprobable, we introduce the average

block error probability as

Pav

B ≡

1

2M

�

m∈{0,1}M

PB(m) .

(1.41)

Since this is a very common ﬁgure of merit for error correcting codes, we shall call

it block error probability and use the symbol PB without further speciﬁcation

hereafter.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

DATA TRANSMISSION

19

Example 1.21 Repetition code. Consider a BSC which transmits a wrong

bit with probability p. A simple code consists in repeating k times each bit,

with k odd. Formally we have M = 1, N = k and

x(0) = 000 . . . 00

�

��

�

k

,

(1.42)

x(1) = 111 . . . 11

�

��

�

k

(1.43)

For instance with k

=

3, the original stream 0110001 is encoded as

00011111100000 0000111. A possible decoder consists in parsing the received

sequence in groups of k bits, and ﬁnding the message m′ from a majority

rule among the k bits. In our example with k = 3, if the received group

of three bits is 111 or 110 or any permutation, the corresponding bit is as-

signed to 1, otherwise it is assigned to 0. For instance if the channel output is

000101111011000010111, the decoding gives 0111001.

This k = 3 repetition code has rate R = M/N = 1/3. It is a simple exercise

to see that the block error probability is PB = p3 + 3p2(1 − p) independently

of the information bit.

Clearly the k = 3 repetition code is able to correct mistakes induced from

the transmission only when there is at most one mistake per group of three

bits. Therefore the block error probability stays ﬁnite at any nonzero value of

the noise. In order to improve the performances of these codes, k must increase.

The error probability for a general k is

PB =

k

�

r=⌈k/2⌉

� k

r

�

(1 − p)k−rpr .

(1.44)

Notice that for any ﬁnite k, p &gt; 0 it stays ﬁnite. In order to have PB → 0

we must consider k → ∞. Since the rate is R = 1/k, the price to pay for a

vanishing block error probability is a vanishing communication rate!

Happily enough much better codes exist as we will see below.

1.6.3

The channel coding theorem

{sec:channeltheorem}

Consider a communication device in which the channel capacity (1.37) is C. In

his seminal 1948 paper, Shannon proved the following theorem.

{theorem:Shannon_channel}

Theorem 1.22 For every rate R &lt; C, there exists a sequence of codes {CN},

of blocklength N, rate RN, and block error probability PB,N, such that RN → R

and PB,N → 0 as N → ∞. Conversely, if for a sequence of codes {CN}, one has

RN → R and PB,N → 0 as N → ∞, then R &lt; C.

In practice, for long messages (i.e. large N), reliable communication is possible

if and only if the communication rate stays below capacity. We shall not give the


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

20

INTRODUCTION TO INFORMATION THEORY

proof here but diﬀer it to Chapters 6 and ???. Here we keep to some qualitative

comments and provide the intuitive idea underlying this result.

First of all, the result is rather surprising when one meets it for the ﬁrst

time. As we saw on the example of repetition codes above, simple minded codes

typically have a ﬁnite error probability, for any non-vanishing noise strength.

Shannon’s theorem establishes that it is possible to achieve zero error probability,

while keeping the communication rate ﬁnite.

One can get an intuitive understanding of the role of the capacity through a

qualitative reasoning, which uses the fact that a random variable with entropy

H ‘typically’ takes 2H values. For a given codeword x(m) ∈ {0, 1}N, the channel

output y is a random variable with an entropy Hy|x = NHy|x. There exist of

order 2NHy|x such outputs. For a perfect decoding, one needs a decoding function

d(y) that maps each of them to the original message m. Globally, the typical

number of possible outputs is 2NHy, therefore one can send at most 2N(Hy−Hy|x)

codewords. In order to have zero maximal error probability, one needs to be able

to send all the 2M = 2NR codewords. This is possible only if R &lt; Hy −Hy|x &lt; C.

Notes

There are many textbooks introducing to probability and to information theory.

A standard probability textbook is the one of Feller (Feller, 1968). The original

Shannon paper (Shannon, 1948) is universally recognized as the foundation of

information theory. A very nice modern introduction to the subject is the book

by Cover and Thomas (Cover and Thomas, 1991). The reader may ﬁnd there a

description of Huﬀman codes which did not treat in the present Chapter, as well

as more advanced topics in source coding.

We did not show that the six properties listed in Sec. 1.2 provide in fact an

alternative (axiomatic) deﬁnition of entropy. The interested reader is referred to

(Csisz´ar and K¨orner, 1981). An advanced information theory book with much

space devoted to coding theory is (Gallager, 1968). The recent (and very rich)

book by MacKay (MacKay, 2002) discusses the relations with statistical inference

and machine learning.

The information-theoretic deﬁnition of entropy has been used in many con-

texts. It can be taken as a founding concept in statistical mechanics. Such an

approach is discussed in (Balian, 1992).


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

2

STATISTICAL PHYSICS AND PROBABILITY THEORY

{chap:StatisticalPhysicsIntro

One of the greatest achievement of science has been to realize that matter is

made out of a small number of simple elementary components. This result seems

to be in striking contrast with our experience. Both at a simply perceptual level

and with more reﬁned scientiﬁc experience, we come in touch with an ever-

growing variety of states of the matter with disparate properties. The ambitious

purpose of statistical physics (and, more generally, of a large branch of condensed

matter physics) is to understand this variety. It aims at explaining how complex

behaviors can emerge when large numbers of identical elementary components

are allowed to interact.

We have, for instance, experience of water in three diﬀerent states (solid,

liquid and gaseous). Water molecules and their interactions do not change when

passing from one state to the other. Understanding how the same interactions

can result in qualitatively diﬀerent macroscopic states, and what rules the change

of state, is a central topic of statistical physics.

The foundations of statistical physics rely on two important steps. The ﬁrst

one consists in passing form the deterministic laws of physics, like Newton’s law,

to a probabilistic description. The idea is that a precise knowledge of the motion

of each molecule in a macroscopic system is inessential to the understanding of

the system as a whole: instead, one can postulate that the microscopic dynam-

ics, because of its chaoticity, allows for a purely probabilistic description. The

detailed justiﬁcation of this basic step has been achieved only in a small num-

ber of concrete cases. Here we shall bypass any attempt at such a justiﬁcation:

we directly adopt a purely probabilistic point of view, as a basic postulate of

statistical physics.

The second step starts from the probabilistic description and recovers deter-

minism at a macroscopic level by some sort of law of large numbers. We all know

that water boils at 100o Celsius (at atmospheric pressure) or that its density

(at 25o Celsius and atmospheric pressures) is 1 gr/cm3. The regularity of these

phenomena is not related to the deterministic laws which rule the motions of

water molecule. It is instead the consequence of the fact that, because of the

large number of particles involved in any macroscopic system, the ﬂuctuations

are “averaged out”. We shall discuss this kind of phenomena in Sec. 2.4 and,

more mathematically, in Ch. 4.

The purpose of this Chapter is to introduce the most basic concepts of this

discipline, for an audience of non-physicists with a mathematical background.

We adopt a somewhat restrictive point of view, which keeps to classical (as

opposed to quantum) statistical physics, and basically describes it as a branch

21


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

22

STATISTICAL PHYSICS AND PROBABILITY THEORY

of probability theory (Secs. 2.1 to 2.3). In Section 2.4 we focus on large systems,

and stress that the statistical physics approach becomes particularly meaningful

in this regime. Theoretical statistical physics often deal with highly idealized

mathematical models of real materials. The most interesting (and challenging)

task is in fact to understand the qualitative behavior of such systems. With this

aim, one can discard any “irrelevant” microscopic detail from the mathematical

description of the model. This modelization procedure is exempliﬁed on the case

study of ferromagnetism through the introduction of the Ising model in Sec. 2.5.

It is fair to say that the theoretical understanding of Ising ferromagnets is quite

advanced. The situation is by far more challenging when Ising spin glasses are

considered. Section 2.6 presents a rapid preview of this fascinating subject.

2.1

The Boltzmann distribution

{se:Boltzmann}

The basic ingredients for a probabilistic description of a physical system are:

• A space of conﬁgurations X. One should think of x ∈ X as giving

a complete microscopic determination of the state of the system under

consideration. We are not interested in deﬁning the most general mathe-

matical structure for X such that a statistical physics formalism can be

constructed. Throughout this book we will in fact consider only two very

simple types of conﬁguration spaces: (i) ﬁnite sets, and (ii) smooth, com-

pact, ﬁnite-dimensional manifolds. If the system contains N ‘particles’, the

conﬁguration space is a product space:

XN = X × · · · × X

�

��

�

N

.

(2.1)

The conﬁguration of the system has the form x = (x1, . . . , xN). Each co-

ordinate xi ∈ X is meant to represent the state (position, orientation, etc)

of one of the particles.

But for a few examples, we shall focus on conﬁguration spaces of type (i).

We will therefore adopt a discrete-space notation for X. The generaliza-

tion to continuous conﬁguration spaces is in most cases intuitively clear

(although it may present some technical diﬃculties).

• A set of observables, which are real-valued functions on the conﬁguration

space O : x �→ O(x). If X is a manifold, we shall limit ourselves to observ-

ables which are smooth functions of the conﬁguration x. Observables are

physical quantities which can be measured through an experiment (at least

in principle).

• Among all the observables, a special role is played by the energy function

E(x). When the system is a N particle system, the energy function gen-

erally takes the form of sums of terms involving few particles. An energy

function of the form:

E(x) =

N

�

i=1

Ei(xi)

(2.2)


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

THE BOLTZMANN DISTRIBUTION

23

corresponds to a non-interacting system. An energy of the form

E(x) =

�

i1,..,ik

Ei1,..,ik(xi1, ..., xik)

(2.3)

is called a k-body interaction. In general, the energy will contain some

pieces involving k-body interactions, with k ∈ {1, 2, ..., K}. An important

feature of real physical systems is that K is never a large number (usually

K = 2 or 3), even when the number of particles N is very large. The same

property holds for all measurable observables. However, for the general

mathematical formulation which we will use here, the energy can be any

real valued function on X.

Once the conﬁguration space X and the energy function are ﬁxed, the prob-

ability pβ(x) for the system to be found in the conﬁguration x is given by the

Boltzmann distribution:

pβ(x) =

1

Z(β) e−βE(x) ;

Z(β) =

�

x∈X

e−βE(x) .

(2.4)

The real parameter T = 1/β is the temperature (and one refers to β as the

inverse temperature)3. The normalization constant Z(β) is called the partition

function. Notice that Eq. (2.4) deﬁnes indeed the density of the Boltzmann

distribution with respect to some reference measure. The reference measure is

usually the counting measure if X is discrete or the Lebesgue measure if X

is continuous. It is customary to denote the expectation value with respect to

Boltzmann’s measure by brackets: the expectation value ⟨O(x)⟩ of an observable

O(x), also called its Boltzmann average is given by:

⟨O⟩ =

�

x∈X

pβ(x)O(x) =

1

Z(β)

�

x∈X

e−βE(x)O(x) .

(2.5)

3In most books of statistical physics, the temperature is deﬁned as T = 1/(kBβ) where

kB is a constant called Boltzmann’s constant, whose value is determined by historical reasons.

Here we adopt the simple choice kB = 1 which amounts to a special choice of the temperature

scale


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

24

STATISTICAL PHYSICS AND PROBABILITY THEORY

Example 2.1 One intrinsic property of elementary particles is their spin. For

‘spin 1/2’ particles, the spin σ takes only two values: σ = ±1. A localized spin

1/2 particle, in which the only degree of freedom is the spin, is described by

X = {+1, −1}, and is called an Ising spin. The energy of the spin in the state

σ ∈ X in a magnetic ﬁeld B is

E(σ) = −B σ

(2.6)

{eq:Ising_energy_1spin}

Boltzmann’s probability of ﬁnding the spin in the state σ is

pβ(σ) =

1

Z(β) e−βE(σ)

Z(β) = e−βB + eβB = 2 cosh(βB) .

(2.7)

{eq:boltz_spin}

The average value of the spin, called the magnetization is

⟨σ⟩ =

�

σ∈{1,−1}

pβ(σ) σ = tanh(βB) .

(2.8)

{eq:mag_tanh_beta_B}

At high temperatures, T ≫ |B|, the magnetization is small. At low temper-

atures, the magnetization its close to its maximal value, ⟨σ⟩ = 1 if B &gt; 0.

Section 2.5 will discuss the behaviors of many Ising spins, with some more

complicated energy functions.

Example 2.2 Some spin variables can have a larger space of possible values.

For instance a Potts spin with q states takes values in X = {1, 2, ..., q}. In

presence of a magnetic ﬁeld of intensity h pointing in direction r ∈ {1, .., q},

the energy of the Potts spin is

E(σ) = −B δσ,r .

(2.9)

In this case, the average value of the spin in the direction of the ﬁeld is

⟨δσ,r⟩ =

exp(βB)

exp(βB) + (q − 1) .

(2.10)


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

THE BOLTZMANN DISTRIBUTION

25

Example 2.3 Let us consider a single water molecule inside a closed container,

for instance, inside a bottle. A water molecule H2O is already a complicated

object. In a ﬁrst approximation, we can neglect its structure and model the

molecule as a point inside the bottle. The space of conﬁgurations reduces then

to:

X = BOTTLE ⊂ R3 ,

(2.11)

where we denoted by BOTTLE the region of R3 delimited by the container. Notice

that this description is not very accurate at a microscopic level.

The description of the precise form of the bottle can be quite complex. On

the other hand, it is a good approximation to assume that all positions of the

molecule are equiprobable: the energy is independent of the particle’s position

x ∈ BOTTLE. One has then:

p(x) = 1

Z ,

Z = |X| ,

(2.12)

and the Boltzmann average of the particle’s position, ⟨x⟩, is the barycentre of

the bottle.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

26

STATISTICAL PHYSICS AND PROBABILITY THEORY

Example 2.4 In assuming that all the conﬁgurations of the previous example

are equiprobable, we neglected the eﬀect of gravity on the water molecule. In

the presence of gravity our water molecule at position x has an energy:

E(x) = w he(x) ,

(2.13)

where he(x) is the height corresponding to the position x and w is a positive

constant, determined by terrestrial attraction, which is proportional to the

mass of the molecule. Given two positions x and y in the bottle, the ratio of

the probabilities to ﬁnd the particle at these positions is

pβ(x)

pβ(y) = exp{−βw[he(x) − he(y)]}

(2.14)

For a water molecule at a room temperature of 20 degrees Celsius (T = 293

degrees Kelvin), one has βw ≈ 7×10−5 m−1. Given a point x at the bottom of

the bottle and y at a height of 20 cm, the probability to ﬁnd a water molecule

‘near’ x is approximatively 1.000014 times larger than the probability to ﬁnd it

‘near’ y. For a tobacco-mosaic virus, which is about 2 × 106 times heavier than

a water molecule, the ratio is pβ(x)/pβ(y) ≈ 1.4 × 1012 which is very large. For

a grain of sand the ratio is so large that one never observes it ﬂoating around y.

Notice that, while these ratios of probability densities are easy to compute, the

partition function and therefore the absolute values of the probability densities

can be much more complicated to estimate, depending on the shape of the

bottle.

Example 2.5 In many important cases, we are given the space of conﬁgura-

tions X and a stochastic dynamics deﬁned on it. The most interesting probabil-

ity distribution for such a system is the stationary state pst(x) (we assume that

it is unique). For sake of simplicity, we can consider a ﬁnite space X and a dis-

crete time Markov chain with transition probabilities {w(x → y)} (in Chapter

4 we shall recall some basic deﬁnitions concerning Markov chains). It happens

sometimes that the transition rates satisfy, for any couple of conﬁgurations

x, y ∈ X, the relation

f(x)w(x → y) = f(y)w(y → x) ,

(2.15)

for some positive function f(x). As we shall see in Chapter 4, when this condi-

tion, called the detailed balance, is satisﬁed (together with a couple of other

technical conditions), the stationary state has the Boltzmann form (2.4) with

e−βE(x) = f(x).


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

THERMODYNAMIC POTENTIALS

27

Exercise 2.1 As a particular realization of the above example, consider an

8 × 8 chessboard and a special piece sitting on it. At any time step the piece

will stay still (with probability 1/2) or move randomly to one of the neighboring

positions (with probability 1/2). Does this process satisfy the condition (2.15)?

Which positions on the chessboard have lower (higher) “energy”? Compute the

partition function.

From a purely probabilistic point of view, one can wonder why one bothers

to decompose the distribution pβ(x) into the two factors e−βE(x) and 1/Z(β). Of

course the motivations for writing the Boltzmann factor e−βE(x) in exponential

form come essentially from physics, where one knows (either exactly or within

some level of approximation) the form of the energy. This also justiﬁes the use

of the inverse temperature β (after all, one could always redeﬁne the energy

function in such a way to set β = 1).

However, it is important to stress that, even if we adopt a mathematical view-

point, and if we are interested in a particular distribution p(x) which corresponds

to a particular value of the temperature, it is often illuminating to embed it into

a one-parameter family as is done in the Boltzmann expression (2.4). Indeed,

(2.4) interpolates smoothly between several interesting situations. As β → 0

(high-temperature limit), one recovers the ﬂat probability distribution

lim

β→0 pβ(x) =

1

|X| .

(2.16)

Both the probabilities pβ(x) and the observables expectation values ⟨O(x)⟩ can

be expressed as convergent Taylor expansions around β = 0. For small β the

Boltzmann distribution can be thought as a “softening” of the original one.

In the limit β → ∞ (low-temperature limit), the Boltzmann distribution

concentrates over the global maxima of the original one. More precisely, one says

x0 ∈ X to be a ground state if E(x) ≥ E(x0) for any x ∈ X. The minimum

value of the energy E0 = E(x0) is called the ground state energy. We will

denote the set of ground states as X0. It is elementary to show that

lim

β→∞ pβ(x) =

1

|X0| I(x ∈ X0) ,

(2.17)

where I(x ∈ X0) = 1 if x ∈ X0 and I(x ∈ X0) = 0 otherwise. The above behavior

is summarized in physicists jargon by saying that, at low temperature, “low

energy conﬁgurations dominate” the behavior of the system.

2.2

Thermodynamic potentials

{se:Potentials}

Several properties of the Boltzmann distribution (2.4) are conveniently summa-

rized through the thermodynamic potentials. These are functions of the temper-

ature 1/β and of the various parameters deﬁning the energy E(x). The most

important thermodynamic potential is the free energy:


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

28

STATISTICAL PHYSICS AND PROBABILITY THEORY

F(β) = − 1

β log Z(β) ,

(2.18)

where Z(β) is the partition function already deﬁned in Eq. (2.4). The factor −1/β

in Eq. (2.18) is due essentially to historical reasons. In calculations it is sometimes

more convenient to use the free entropy4 Φ(β) = −βF(β) = log Z(β).

Two more thermodynamic potentials are derived from the free energy: the

internal energy U(β) and the canonical entropy S(β):

U(β) = ∂

∂β (βF(β)) ,

S(β) = β2 ∂F(β)

∂β

.

(2.19)

By direct computation one obtains the following identities concerning the po-

tentials deﬁned so far:

F(β) = U(β) − 1

β S(β) = − 1

β Φ(β) ,

(2.20)

U(β) = ⟨E(x)⟩ ,

(2.21)

S(β) = −

�

x

pβ(x) log pβ(x) ,

(2.22)

−∂2

∂β2 (βF(β)) = ⟨E(x)2⟩ − ⟨E(x)⟩2 .

(2.23)

Equation (2.22) can be rephrased by saying that the canonical entropy is the

Shannon entropy of the Boltzmann distribution, as we deﬁned it in Ch. 1. It

implies that S(β) ≥ 0. Equation (2.23) implies that the free entropy is a con-

vex function of the temperature. Finally, Eq. (2.21) justiﬁes the name “internal

energy” for U(β).

In order to have some intuition of the content of these deﬁnitions, let us

reconsider the high- and low-temperature limits already treated in the previous

Section. In the high-temperature limit, β → 0, one ﬁnds

F(β) = − 1

β log |X| + ⟨E(x)⟩0 + Θ(β) ,

(2.24)

U(β) = ⟨E(x)⟩0 + Θ(β) ,

(2.25)

S(β) = log |X| + Θ(β) .

(2.26)

(The symbol Θ means ’of the order of’; the precise deﬁnition is given in Appendix

). The interpretation of these formulae is straightforward. At high temperature

{ch:Notation}

the system can be found in any possible conﬁguration with similar probabilities

(the probabilities being exactly equal when β = 0). The entropy counts the

number of possible conﬁgurations. The internal energy is just the average value

of the energy over the conﬁgurations with ﬂat probability distribution.

4Unlike the other potentials, there is no universally accepted name for Φ(β); because this

potential is very useful, we adopt for it the name ‘free entropy’


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

THERMODYNAMIC POTENTIALS

29

-3

-2.5

-2

-1.5

-1

-0.5

0

0.5

1

0

0.5

1

1.5

2

2.5

3

T

F(β)

-3

-2.5

-2

-1.5

-1

-0.5

0

0.5

1

0

0.5

1

1.5

2

2.5

3

T

U(β)

-3

-2.5

-2

-1.5

-1

-0.5

0

0.5

1

0

0.5

1

1.5

2

2.5

3

T

S(β)

Fig. 2.1. Thermodynamic potentials for a two-level system with ǫ1 = −1,

ǫ2 = +1 as a function of the temperature T = 1/β.

{fig:twolevel}

While the high temperature expansions (2.24)–(2.26) have the same form

both for a discrete and a continuous conﬁguration space X, in the low tempera-

ture case, we must be more careful. If X is ﬁnite we can meaningfully deﬁne the

energy gap ∆E &gt; 0 as follows (recall that we denoted by E0 the ground-state

energy)

∆E = min{E(y) − E0 : y ∈ X\X0} .

(2.27)

With this deﬁnition we get

F(β) = E0 − 1

β log |X0| + Θ(e−β∆E) ,

(2.28)

E(β) = E0 + Θ(e−β∆E) ,

(2.29)

S(β) = log |X0| + Θ(e−β∆E) .

(2.30)

The interpretation is that, at low temperature, the system is found with equal

probability in any of the ground states, and nowhere else. Once again the entropy

counts the number of available conﬁgurations and the internal energy is the

average of their energies (which coincide with the ground state).


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

30

STATISTICAL PHYSICS AND PROBABILITY THEORY

Exercise 2.2 A two level system. This is the simplest non-trivial example:

X = {1, 2}, E(1) = ǫ1, E(2) = ǫ2. Without loss of generality we assume

ǫ1 &lt; ǫ2. It can be used as a mathematical model for many physical systems,

like the spin 1/2 particle discussed above.

Derive the following results for the thermodynamic potentials (∆ = ǫ2 − ǫ1

is the energy gap):

F(β) = ǫ1 − 1

β log(1 + e−β∆) ,

(2.31)

U(β) = ǫ1 +

e−β∆

1 + e−β∆ ∆ ,

(2.32)

S(β) =

e−β∆

1 + e−β∆ β∆ + log(1 + e−β∆) .

(2.33)

The behavior of these functions is presented in Fig. 2.1. The reader can work

out the asymptotics, and check the general high and low temperature behaviors

given above.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

THERMODYNAMIC POTENTIALS

31

Exercise 2.3 We come back to the example of the previous section: one water

molecule, modeled as a point, in a bottle. Moreover, we consider the case of a

cylindric bottle of base B ⊂ R2 (surface |B|) and height d.

Using the energy function (2.13), derive the following explicit expressions

for the thermodynamic potentials:

F(β) = − 1

β log |B| − 1

β log 1 − e−βwd

βw

,

(2.34)

U(β) = 1

β −

wd

eβwd − 1 ,

(2.35)

S(β) = log |Bd| + 1 −

βwd

eβwd − 1 − log

�

βwd

1 − e−βwd

�

.

(2.36)

Notice that the internal energy formula can be used to compute the average

height of the molecule ⟨he(x)⟩ = U(β)/w. This is a consequence of the deﬁni-

tion of the energy, cf. Eq. (2.13) and of Eq. (2.21). Plugging in the correct w

constant, one may ﬁnd that the average height descends below 49.99% of the

bottle height d = 20 cm only when the temperature is below 3.2o K.

Using the expressions (2.34)–(2.36) one obtains the low-temperature expan-

sions for the same quantities:

F(β) = − 1

β log

�|B|

βw

�

+ Θ(e−βwd) ,

(2.37)

U(β) = 1

β + Θ(e−βwd) ,

(2.38)

S(β) = log

�|B|e

βw

�

+ Θ(e−βwd) .

(2.39)

In this case X is continuous, and the energy has no gap. But these results

can be understood as follows: at low temperature the molecule is conﬁned to

a layer of height of order 1/(βw) above the bottom of the bottle. It occupies

therefore a volume of size |B|/(βw). Its entropy is approximatively given by

the logarithm of such a volume.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

32

STATISTICAL PHYSICS AND PROBABILITY THEORY

Exercise 2.4 Let us reconsider the above example and assume the bottle to

have a diﬀerent shape, for instance a sphere of radius R. In this case it is

diﬃcult to compute explicit expressions for the thermodynamic potentials but

one can easily compute the low-temperature expansions. For the entropy one

gets at large β:

S(β) = log

�2πe2R

β2w2

�

+ Θ(1/β) .

(2.40)

The reader should try understand the diﬀerence between this result and Eq.

(2.39) and provide an intuitive explanation as in the previous example. Physi-

cists say that the low-temperature thermodynamic potentials reveal the “low-

energy structure” of the system.

2.3

The ﬂuctuation dissipation relations

{se:free_energy}

It often happens that the energy function depends smoothly upon some real

parameters. They can be related to the experimental conditions under which

a physical system is studied, or to some fundamental physical quantity. For

instance, the energy of a water molecule in the gravitational ﬁeld, cf. Eq. (2.13),

depends upon the weight w of the molecule itself. Although this is a constant

number in the physical world, it is useful, in the theoretical treatment, to consider

it as an adjustable parameter.

It is therefore interesting to consider an energy function Eλ(x) which depends

smoothly upon some parameter λ and admit the following Taylor expansion in

the neighborhood of λ = λ0:

Eλ(x) = Eλ0(x) + (λ − λ0) ∂E

∂λ

����

λ0

(x) + O((λ − λ0)2) .

(2.41)

The dependence of the free energy and of other thermodynamic potentials

upon λ in the neighborhood of λ0 is easily related to the explicit dependence of

the energy function itself. Let us consider the partition function, and expand it

to ﬁrst order in λ − λ0:

Z(λ) =

�

x

exp

�

−β

�

Eλ0(x) + (λ − λ0) ∂E

∂λ

����

λ0

(x) + O((λ − λ0)2)

��

= Z(λ0)

�

1 − β(λ − λ0)⟨ ∂E

∂λ

����

λ0

⟩0 + O((λ − λ0)2)

�

(2.42)

where we denoted by ⟨·⟩0 the expectation with respect to the Boltzmann distri-

bution at λ = λ0.

This shows that the free entropy behaves as:

∂Φ

∂λ

����

λ0

= −β ⟨ ∂E

∂λ

����

λ0

⟩0 ,

(2.43)


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

THE THERMODYNAMIC LIMIT

33

One can also consider the λ dependence of the expectation value of a generic

observable A(x). Using again the Taylor expansion one ﬁnds that

∂⟨A⟩λ

∂λ

����

λ0

= −β ⟨ A ; ∂E

∂λ

����

λ0

⟩0 .

(2.44)

where we denoted by ⟨A; B⟩ the connected correlation function: ⟨A; B⟩ =

⟨AB⟩ − ⟨A⟩⟨B⟩. A particular example of this relation was given in Eq. (2.23).

The result (2.44) has important practical consequences and many general-

izations. Imagine you have an experimental apparatus that allows you to tune

some parameter λ (for instance the pressure of a gas, or the magnetic or electric

ﬁeld acting on some material) and to monitor the value of the observable A(x)

(the volume of the gas, the polarization or magnetization of the material). The

quantity on the left-hand side of Eq. (2.44) is the response of the system to an

inﬁnitesimal variation of the tunable parameter. On the right-hand side, we ﬁnd

some correlation function within the “unperturbed” system. One possible appli-

cation is to measure correlations within a system by monitoring its response to

an external perturbation. Such a relation between a correlation and a response

is called a ﬂuctuation dissipation relation.

2.4

The thermodynamic limit

{se:Thermodynamic}

The main purpose of statistical physics is to understand the macroscopic be-

havior of a large number, N ≫ 1, of simple components (atoms, molecules, etc)

when they are brought together.

To be concrete, let us consider a few drops of water in a bottle. A conﬁguration

of the system is given by the positions and orientations of all the H2O molecules

inside the bottle. In this case X is the set of positions and orientations of a single

molecule, and N is typically of order 1023 (more precisely 18 gr of water contain

approximatively 6·1023 molecules). The sheer magnitude of such a number leads

physicists to focus on the N → ∞ limit, also called the thermodynamic limit.

As shown by the examples below, for large N the thermodynamic potentials

are often proportional to N. One is thus lead to introduce the intensive ther-

modynamic potentials as follows. Let us denote by FN(β), UN(β), SN(β) the

free energy, internal energy and canonical entropy for a system with N ‘particles’.

The free energy density is deﬁned by

f(β) = lim

N→∞ FN(β)/N ,

(2.45)

if the limit exists 5. One deﬁnes analogously the energy density u(β) and the

entropy density s(β).

The free energy FN(β), is, quite generally, an analytic function of β in a

neighborhood of the real β axis. This is a consequence of the fact that Z(β)

5The limit usually exist, at least if the forces between particles decrease fast enough at large

inter-particle distances


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

34

STATISTICAL PHYSICS AND PROBABILITY THEORY

is analytic throughout the entire β plane, and strictly positive for real β’s. A

question of great interest is whether analyticity is preserved in the thermody-

namic limit (2.45), under the assumption that the limit exists. Whenever the free

energy density f(β) is non-analytic, one says that a phase transition occurs.

Since the free entropy density φ(β) = −βf(β) is convex, the free energy density

is necessarily continuous whenever it exists.

In the simplest cases the non-analyticities occur at isolated points. Let βc be

such a point. Two particular type of singularities occur frequently:

• The free energy density is continuous, but its derivative with respect to

β is discontinuous at βc. This singularity is named a ﬁrst order phase

transition.

• The free energy and its ﬁrst derivative are continuous, but the second

derivative is discontinuous at βc. This is called a second order phase

transition.

Higher order phase transitions can be deﬁned as well on the same line.

Apart from being interesting mathematical phenomena, phase transitions

correspond to qualitative changes in the underlying physical system. For instance

the transition from water to vapor at 100oC at normal atmospheric pressure is

modeled mathematically as a ﬁrst order phase transition in the above sense. A

great part of this book will be devoted to the study of phase transitions in many

diﬀerent systems, where the interacting ‘particles’ can be very diverse objects

like information bits or occupation numbers on the vertices of a graph.

When N grows, the volume of the conﬁguration space increases exponentially:

|XN| = |X|N. Of course, not all the conﬁgurations are equally important under

the Boltzmann distribution: lowest energy conﬁgurations have greater proba-

bility. What is important is therefore the number of conﬁgurations at a given

energy. This information is encoded in the energy spectrum of the system:

N∆(E) = |Ω∆(E)| ;

Ω∆(E) ≡ {x ∈ XN : E ≤ E(x) &lt; E + ∆} . (2.46)

In many systems of interest, the energy spectrum diverges exponentially as N →

∞, if the energy is scaled linearly with N. More precisely, there exist a function

s(e) such that, given two ﬁxed numbers e and δ &gt; 0,

lim

N→∞

1

N log NNδ(Ne) =

sup

e′∈[e,e+δ]

s(e′) .

(2.47)

The function s(e) is called microcanonical entropy density. The statement

(2.47) is often rewritten in the more compact form:

N∆(E) .=N exp

�

Ns

� E

N

��

.

(2.48)

The notation AN .=N BN is used throughout the book to denote that two quan-

tities AN and BN, which normally behave exponentially in N, are equal to lead-

ing exponential order when N is large, meaning: limN→∞(1/N) log(AN/BN) =


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

THE THERMODYNAMIC LIMIT

35

0. We often use .= without index when there is no ambiguity on what the large

variable N is.

The microcanonical entropy density s(e) conveys a great amount of infor-

mation about the system. Furthermore it is directly related to the intensive

thermodynamic potentials through a fundamental relation:

{prop:micro_cano}

Proposition 2.6 If the microcanonical entropy density (2.47) exists for any e

and if the limit in (2.47) uniform in e, then the free entropy density (2.45) exists

and is given by:

φ(β) = max

e [s(e) − βe] .

(2.49)

If the maximum of the s(e)−βe is unique, then the internal energy density equals

arg max[s(e) − βe].

Proof: For a rigorous proof of this statement, we refer the reader to (Galavotti,

1999; Ruelle, 1999). The basic idea is to write the partition function as follows

ZN(β) .=

∞

�

k=−∞

N∆(k∆) e−β∆ .=

�

de exp{Ns(e) − Nβe} ,

(2.50)

and to evaluate the last integral by saddle point. □.

Example 2.7 Let us consider N identical two-level systems: XN = X ×· · ·×X,

with X = {1, 2}. We take the energy to be the sum of single-systems energies:

E(x) = Esingle(x1) + · · · + Esingle(xN), with xi ∈ X. As in the previous Section

we set Esingle(1) = ǫ1, and Esingle(2) = ǫ2 &gt; ǫ1 and ∆ = ǫ2 − ǫ1.

The energy spectrum of this model is quite simple. For any energy E =

Nǫ1 + n∆, there are

�N

n

�

conﬁgurations x with E(x) = E. Therefore, using the

deﬁnition (2.47), we get

s(e) = H

�e − ǫ1

∆

�

.

(2.51)

Equation (2.49) can now be used to get

f(β) = ǫ1 − 1

β log(1 + e−β∆) ,

(2.52)

which agrees with the result obtained directly from the deﬁnition (2.18).

The great attention paid by physicists to the thermodynamic limit is ex-

tremely well justiﬁed by the huge number of degrees of freedom involved in a

macroscopic piece of matter. Let us stress that the interest of the thermodynamic

limit is more general than these huge numbers might suggest. First of all, it often

happens that fairly small systems are well approximated by the thermodynamic

limit. This is extremely important for numerical simulations of physical systems:


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

36

STATISTICAL PHYSICS AND PROBABILITY THEORY

Fig. 2.2. A conﬁguration of a two dimensional Ising model with L = 5. There

is an Ising spin σi on each vertex i, shown by an arrow pointing up if σi = +1,

pointing down if σi = −1. The energy (2.53) is given by the sum of two types of

contributions: (i) A term −σiσj for each edge (ij) of the graph, such that the

energy is minimized when the two neighboring spins σi and σj point in the same

direction; (ii) A term −Bσi for each site i, due to the coupling to an external

magnetic ﬁeld. The conﬁguration depicted here has energy −8 + 9B

{fig:ising_def}

one cannot of course simulate 1023 molecules on a computer! Even the cases in

which the thermodynamic limit is not a good approximation are often fruitfully

analyzed as violations of this limit. Finally, the insight gained in analyzing the

N → ∞ limit is always crucial in understanding moderate-size systems.

2.5

Ferromagnets and Ising models

{se:ising}

Magnetic materials contain molecules with a magnetic moment, a three-dimensional

vector which tends to align with the magnetic ﬁeld felt by the molecule. More-

over, the magnetic moments of two distinct molecules interact with each other.

Quantum mechanics plays an important role in magnetism. Because of its eﬀects,

the space of possible conﬁgurations of a magnetic moment becomes discrete. It

is also at the origin of the so-called exchange interaction between magnetic mo-

ments. In many materials, the eﬀect of the exchange interactions are such that

the energy is lower when two moments align. While the behavior of a single

magnetic moment in an external ﬁeld is qualitatively simple, when we consider a

bunch of interacting moments, the problem is much richer, and exhibits remark-

able collective phenomena.

A simple mathematical model for such materials is the Ising model. It de-

scribes the magnetic moments by Ising spins localized at the vertices of a certain

region of the d-dimensional cubic lattice. To keep things simple, let us consider

a region L which is a cube of side L: L = {1, . . . , L}d. On each site i ∈ L there

is an Ising spin σi ∈ {+1, −1}.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

FERROMAGNETS AND ISING MODELS

37

A conﬁguration σ = (σ1 . . . σN) of the system is given by assigning the

values of all the spins in the system. Therefore the space of conﬁgurations

XN = {+1, −1}L has the form (2.1) with X = {+1, −1} and N = Ld.

The deﬁnition of ferromagnetic Ising models is completed by the deﬁnition

of the energy function. A conﬁguration σ has an energy:

E(σ) = −

�

(ij)

σiσj − B

�

i∈L

σi ,

(2.53)

where the sum over (ij) runs over all the (unordered) couples of sites i, j ∈ L

which are nearest neighbors. The real number B measures the applied external

magnetic ﬁeld.

Determining the free energy density f(β) in the thermodynamic limit for

this model is a non-trivial task. The model was invented by Wilhem Lenz in the

early twenties, who assigned the task of analyzing it to his student Ernst Ising.

In his dissertation thesis (1924) Ising solved the d = 1 case and showed the

absence of phase transitions. In 1948, Lars Onsager brilliantly solved the d = 2

case, exhibiting the ﬁrst soluble “ﬁnite-dimensional” model with a second order

phase transition. In higher dimensions the problem is unsolved although many

important features of the solution are well understood.

Before embarking in any calculation, let us discuss what we expect to be

the qualitative properties of this model. Two limiting cases are easily under-

stood. At inﬁnite temperature, β = 0, the energy (2.53) no longer matters and

the Boltzmann distribution weights all the conﬁgurations with the same factor

2−N. We have therefore an assembly of completely independent spins. At zero

temperature, β → ∞, the Boltzmann distribution concentrates onto the ground

state(s). If there is no magnetic ﬁeld, h = 0, there are two degenerate ground

states: the conﬁgurations σ(+) with all the spins pointing up, σi = +1, and the

conﬁguration σ(−) with all the spins pointing down, σi = −1. If the magnetic

ﬁeld is set to some non-zero value, one of the two conﬁguration dominates: σ(+)

for h &gt; 0 and σ(−) for h &lt; 0.

Notice that the reaction of the system to the external magnetic ﬁeld h is

quite diﬀerent in the two cases. To see this fact, deﬁne a “rescaled” magnetic

ﬁeld x = βh and take the limits β → 0 or β → ∞ keeping x ﬁxed. The expected

value of any spin in L, in the two limits, is:

⟨σi⟩ =

�

tanh(x)

for β → 0

tanh(Nx) for β → ∞ .

(2.54)

Each spin reacts independently for β → 0. On the contrary, they react as a whole

as β → ∞: one says that the response is cooperative.

A useful quantity for describing the response of the system to the external

ﬁeld is the average magnetization:

MN(β, B) = 1

N

�

i∈L

⟨σi⟩ .

(2.55)


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

38

STATISTICAL PHYSICS AND PROBABILITY THEORY

Because of the symmetry between the up and down directions, MN(β, B) is an

odd function of B. In particular MN(β, 0) = 0. A cooperative response can be

evidenced by considering the spontaneous magnetization

M+(β) =

lim

B→0+ lim

N→∞ MN(β, B) .

(2.56)

It is important to understand that a non-zero spontaneous magnetization can

appear only in an inﬁnite system: the order of the limits in Eq. (2.56) is crucial.

Our analysis so far has shown that the spontaneous magnetization exists at β =

∞: M+(∞) = 1. On the other hand M+(0) = 0. It can be shown that actually

the spontaneous magnetization M(β) is always zero in a high temperature phase

β &lt; βc(d) (such a phase is called paramagnetic). In one dimension (d = 1), we

will show below that βc(1) = ∞. The spontaneous magnetization is always zero,

except at zero temperature (β = ∞): one speaks of a zero temperature phase

transition. In dimensions d ≥ 2, βc(d) is ﬁnite, and M(β) becomes non zero in

the so called ferromagnetic phase β &gt; βc: a phase transition takes place at

β = βc. The temperature Tc = 1/βc is called the critical temperature. In the

following we shall discuss the d = 1 case, and a variant of the model, called the

Curie Weiss model, where each spin interacts with all the other spins: this is a

solvable model which exhibits a ﬁnite temperature phase transition.

2.5.1

The one-dimensional case

sec:OneDimensionalIsing}

The d = 1 case has the advantage of being simple to solve. We want to com-

pute the partition function (2.4) for a system of N spins with energy E(σ) =

− �N−1

i=1 σiσi+1 − B �N

i=1 σi. We will use a method called the transfer matrix

method, which belongs to the general ‘dynamic programming’ strategy familiar

to computer scientists.

We introduce the partial partition function where the conﬁgurations of all

spins σ1,. . . , σp have been summed over, at ﬁxed σp+1:

zp(β, B, σp+1) ≡

�

σ1,...,σp

exp

�

β

p

�

i=1

σiσi+1 + βB

p

�

i=1

σi

�

.

(2.57)

The partition function (2.4) is given by ZN(β, B) = �

σN zN−1(β, B, σN) exp(βBσN).

Obviously zp satisﬁes the recursion relation

zp(β, B, σp+1) =

�

σp=±1

T(σp+1, σp)zp−1(β, B, σp)

(2.58)

where we deﬁne the so-called transfer matrix T(σ, σ′) = exp [βσσ′ + βBσ′],

which is a 2 × 2 matrix:

T =

�

eβ+βB e−β−βB

e−β+βB eβ−βB

�

(2.59)


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

FERROMAGNETS AND ISING MODELS

39

Introducing the two component vectors ψL =

�

exp(βB)

exp(−βB)

�

and ψR =

�

1

1

�

,

and the standard scalar product between such vectors (a, b) = a1b1 + a2b2, the

partition function can be written in matrix form:

ZN(β, B) = (ψL, T N−1ψR) .

(2.60)

Let us call λ1, λ2 the eigenvalues of T, and ψ1, ψ2 the corresponding eigenvectors.

Since ψ1, ψ2 can be chosen to be linearly independent, ψR can be decomposed

as ψR = u1ψ1 + u2ψ2. The partition function is then expressed as:

ZN(β, B) = u1 (ψL, ψ1) λN−1

1

+ u2 (ψL, ψ2) λN−1

2

.

(2.61)

The diagonalization of the matrix T gives:

λ1,2 = eβ cosh(βB) ±

�

e2β sinh2 βB + e−2β .

(2.62)

For β ﬁnite, in the large N limit, the partition function is dominated by the

largest eigenvalue λ1, and the free entropy density is given by φ = log λ1.

φ(β, B) = log

�

eβ cosh(βB) +

�

e2β sinh2 βB + e−2β

�

.

(2.63)

Using the same transfer matrix technique we can compute expectation values

of observables. For instance the expected value of a given spin is

⟨σi⟩ =

1

ZN(β, B) (ψL, T i−1ˆσT N−iψR) ,

(2.64)

where ˆσ is the following matrix:

ˆσ =

�

1 0

0 −1

�

.

(2.65)

Averaging over the position i, one can compute the average magnetization MN(β, B).

In the thermodynamic limit we get

lim

N→∞ MN(β, B) =

sinh βB

�

sinh2 βh + e−4β = 1

β

∂φ

∂B (β, B) .

(2.66)

Both the free energy and the average magnetization turn out to be analytic

functions of β and h for β &lt; ∞. In particular the spontaneous magnetization

vanishes at any non-zero temperature:

M+(β) = 0 ,

∀β &lt; ∞ .

(2.67)

In Fig. 2.3 we plot the average magnetization M(β, B) ≡ limN→∞ MN(β, B) as

a function of the applied magnetic ﬁeld h for various values of the temperature


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

40

STATISTICAL PHYSICS AND PROBABILITY THEORY

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

0

0.2

0.4

0.6

0.8

1

1.2

M

h

Fig. 2.3. The average magnetization of the one dimensional Ising model, as a

function of the magnetic ﬁeld B, at inverse temperatures β = 0.5, 1, 1.5, 2 (from

bottom to top)

{fig:ising1d_mag}

β. The curves become steeper and steeper as β increases. This statement can

be made more quantitative by computing the susceptibility associated to the

average magnetization:

χM(β) = ∂M

∂h (β, 0) = β e2β .

(2.68)

This result can be interpreted as follows. A single spin in a ﬁeld has sus-

ceptibility χ(β) = β. If we consider N spins constrained to take the the same

value, the corresponding susceptibility will be Nβ, as in Eq (2.54). In the present

case the system behaves as if the spins were blocked into groups of χ(β)/β spins

each. The spins in each group are constrained to take the same value, while spins

belonging to diﬀerent blocks are independent.

This qualitative interpretation receives further support by computing a cor-

relation function. For h = 0 and δN &lt; i &lt; j &lt; (1 − δ)N, one ﬁnds, at large

N:

⋆

⟨σiσj⟩ = e−|i−j|/ξ(β) + Θ(e−αN) ,

(2.69)

with ξ(β) = −1/ log tanh β. Notice that ξ(β) gives the typical distance below

which two spins in the system are well correlated. For this reason it is usually

called the correlation length of the model. This correlation length increases

when the temperature decreases: spins become correlated at larger and larger

distances. The result (2.69) is clearly consistent with our interpretation of the

susceptibility. In particular, as β → ∞, ξ(β) ≈ e2β/2 and χ(β) ≈ 2βξ(β).

The connection between correlation length and susceptibility is very general

and can be understood as a consequence of the ﬂuctuation-dissipation theorem

(2.44):


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

FERROMAGNETS AND ISING MODELS

41

χM(β) = βN

��

1

N

N

�

i=1

σi

�

;

�

1

N

N

�

i=1

σi

��

= β

N

N

�

i,j=1

⟨σi ; σj⟩ = β

N

N

�

i,j=1

⟨σiσj⟩ ,

(2.70)

where the last equality comes from the fact that ⟨σi⟩ = 0 when B = 0. Using

(2.69), we get

χM(β) = β

+∞

�

i=−∞

e−|i|/ξ(β) + Θ(e−αN) .

(2.71)

It is therefore evident that a large susceptibility must correspond to a large

correlation length.

2.5.2

The Curie-Weiss model

{se:CurieWeiss}

The exact solution of the one-dimensional model, lead Ising to think that there

couldn’t be a phase transition in any dimension. Some thirty years earlier a

qualitative theory of ferromagnetism had been put forward by Pierre Curie. Such

a theory assumed the existence of a phase transition at non-zero temperature Tc

(the so-called the “Curie point”) and a non-vanishing spontaneous magnetization

for T &lt; Tc. The dilemma was eventually solved by Onsager solution of the two-

dimensional model.

Curie theory is realized exactly within a rather abstract model: the so-called

Curie-Weiss model. We shall present it here as one of the simplest solvable

models with a ﬁnite temperature phase transition. Once again we have N Ising

spins σi ∈ {±1} and a conﬁguration is given by σ = (σ1, . . . , σN). However the

spins no longer sits on a d-dimensional lattice: they all interact in pairs. The

energy function, in presence of a magnetic ﬁeld B, is given by:

E(σ) = − 1

N

�

(ij)

σiσj − B

N

�

i=1

σi ,

(2.72)

where the sum on (ij) runs over all the couples of spins. Notice the peculiar 1/N

scaling in front of the exchange term. The exact solution presented below shows

that this is the only choice which yields a non-trivial free-energy density in the

thermodynamic limit. This can be easily understood intuitively as follows. The

sum over (ij) involves O(N 2) terms of order O(1). In order to get an energy

function scaling as N, we need to put a 1/N coeﬃcient in front.

In adopting the energy function (2.72), we gave up the description of any

ﬁnite-dimensional geometrical structure. This is a severe simpliﬁcation, but has

the advantage of making the model exactly soluble. The Curie-Weiss model is

the ﬁrst example of a large family: the so-called mean-ﬁeld models. We will

explore many instances of this family throughout the book.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

42

STATISTICAL PHYSICS AND PROBABILITY THEORY

A possible approach to the computation of the partition function consists in

observing that the energy function can be written in terms of a simple observable,

the instantaneous magnetization:

m(σ) = 1

N

N

�

i=1

σi .

(2.73)

Notice that this is a function of the conﬁguration σ, and shouldn’t be confused

with its expected value, the average magnetization, cf. Eq. (2.55). It is a “simple”

observable because it is equal to the sum of observables depending upon a single

spin.

We can write the energy of a conﬁguration in terms of its instantaneous

magnetization:

E(σ) = 1

2N − 1

2N m(σ)2 − NB m(σ) .

(2.74)

This implies the following formula for the partition function

ZN(β, B) = e−Nβ/2 �

m

NN(m) exp

�Nβ

2 m2 + NβBm

�

,

(2.75)

where the sum over m runs over all the possible instantaneous magnetizations of

N Ising spins: m = −1+2k/N with 0 ≤ k ≤ N an integer number, and NN(m) is

the number of conﬁgurations having a given instantaneous magnetization. This

is given by a binomial coeﬃcient whose large N behavior is given in terms of the

entropy function of a Bernoulli process:

NN(m) =

�

N

N 1+m

2

�

.= exp

�

N H

�1 + m

2

��

.

(2.76)

To leading exponential order in N, the partition function can thus be written

as:

ZN(β, B) .=

� +1

−1

dm eNφmf(m;β,B)

(2.77)

where we have deﬁned

φmf(m; β, B) = −β

2 (1 − m2) + βBm + H

�1 + m

2

�

.

(2.78)

The integral in (2.77) is easily evaluated by Laplace method, to get the ﬁnal

result for the free-energy density

φ(β, B) =

max

m∈[−1,+1] φmf(m; β, B) .

(2.79)


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

FERROMAGNETS AND ISING MODELS

43

-1

-0.5

0

0.5

1

m

0

0.1

0.2

0.3

0.4

0

1

2

3

beta

-1

-0.5

0

0.5

1

m

Fig. 2.4. Left: the function φmf(m; β, B

=

0) is plotted versus m, for

β = .7, .9, 1.1, 1.3 (from top to bottom). For β &lt; βc = 1 there is a unique

maximum at m = 0, for β &lt; βc = 1 there are two degenerate maxima at two

symmetric values ±m+(β).Right: values of m which maximize φmf(m; β, B = 0)

are plotted versus β. The phase transition at βc = 1 is signaled by the bifurcation.

{fig:phiCW}

One can see that the maximum is obtained away from the boundary points, so

that the corresponding m must be a stationary point of φmf(m; β, B), which

satisﬁes the saddle-point equation ∂φmf(m; β, B)/∂m = 0:

m∗ = tanh(βm∗ + βB) .

(2.80)

In the above derivation we were slightly sloppy at two steps: substituting the

binomial coeﬃcient with its asymptotic form and changing the sum over m into

an integral. The mathematically minded reader is invited to show that these

passages are indeed correct.

⋆

With a bit more work the above method can be extended to expectation

values of observables. Let us consider for instance the average magnetization

M(β, B). It can be easily shown that, whenever the maximum of φmf(m; β, B)

⋆

over m is non-degenerate,

M(β, B) ≡ lim

N→∞⟨m(σ)⟩ = m∗(β, B) ≡ arg max

m φmf(m; β, B) ,

(2.81)

We can now examine the implications that can be drawn from Eqs. (2.79)

and (2.80). Let us ﬁrst consider the B = 0 case (see Fig.2.4). The function

φmf(m; β, 0) is symmetric in m. For 0 ≤ β ≤ 1 ≡ βc, it is also concave and

achieves its unique maximum in m∗(β) = 0. For β &gt; 1, m = 0 remains a

stationary point but becomes a local minimum, and the function develops two

degenerate global maxima at m±(β) with m+(β) = −m−(β) &gt; 0. These two

maxima bifurcate continuously from m = 0 at β = βc.

A phase transition takes place at βc. Its meaning can be understood by com-

puting the expectation value of the spins. Notice that the energy function (2.72)

is symmetric a spin-ﬂip transformation which maps σi → −σi for all i’s. There-

fore ⟨σi⟩ = ⟨(−σi)⟩ = 0 and the average magnetization vanishes M(β, 0) = 0.

On the other hand, the spontaneous magnetization, deﬁned in (2.56), is zero


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

44

STATISTICAL PHYSICS AND PROBABILITY THEORY

in the paramagnetic phase β &lt; βc, and equal to m+(β) in the ferromagnetic

phase β &gt; βc. The physical interpretation of this phase is the following: for any

ﬁnite N the pdf of the instantaneous magnetization m(σ) has two symmetric

peaks, at m±(β), which become sharper and sharper as N increases. Any exter-

nal perturbation which breaks the symmetry between the peaks, for instance a

small positive magnetic ﬁeld B, favors one peak with respect to the other one,

and therefore the system develops a spontaneous magnetization. Notice that, in

mathematical terms, the phase transition is a property of systems in the ther-

modynamic limit N → ∞.

In physical magnets the symmetry breaking can come for instance from im-

purities, subtle eﬀects of dipolar interactions together with the shape of the

magnet, or an external magnetic ﬁeld. The result is that at low enough temper-

atures some systems, the ferromagnets develop a spontaneous magnetization. If

you heat a magnet made of iron, its magnetization disappears at a critical tem-

perature Tc = 1/βc = 770 degrees Celsius. The Curie Weiss model is a simple

solvable case exhibiting the phase transition.

Exercise 2.5 Compute the expansion of m+(β) and of φ(β, B = 0) near

β = βc, and show that the transition is of second order. Compute the low

temperature behavior of the spontaneous magnetization.

{ex:Ising_inhom}

Exercise 2.6 Inhomogeneous Ising chain. The one dimensional Ising problem

does not have a ﬁnite temperature phase transition, as long as the interactions

are short range and translational invariant. But when the couplings in the Ising

chain grow fast enough at large distance, one can have a phase transition. This

is not a very realistic model from the point of view of physics, but it is useful

as a solvable example of phase transition.

Consider a chain of Ising spins σ0, σ1, . . . , σN

with energy E(σ)

=

− �N−1

n=0 Jnσnσn+1. Suppose that the coupling constants Jn form a positive,

monotonously increasing sequence, growing logarithmically. More precisely, we

assume that limn→∞Jn/ log n = 1 . Denote by ⟨.⟩+ (resp. ⟨.⟩−) the expectation

value with respect to Boltzmann’s probability distribution when the spin σN

is ﬁxed to σN = +1 (resp. ﬁxed to σN = −1).

(i) Show that , for any n ∈ {0. . . . , N − 1}, the magnetization is ⟨σn⟩± =

�N−1

p=n tanh(βJp)

(ii) Show that the critical inverse temperature βc = 1/2 separates two

regimes, such that: for β &lt; βc, one has limN→∞⟨σn⟩+ = limN→∞⟨σn⟩− =

0; for β &gt; βc, one has limN→∞⟨σn⟩± = ±M(β), and M(β) &gt; 0.

Notice that in this case, the role of the symmetry breaking ﬁeld is played by

the choice of boundary condition.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

THE ISING SPIN GLASS

45

Fig. 2.5. A conﬁguration of a two dimensional Edwards-Anderson model with

L = 5. Spins are coupled by two types of interactions: ferromagnetic (Jij = +1),

indicated by a continuous line, and antiferromagnetic (Jij = −1), indicated by

a dashed line. The energy of the conﬁguration shown here is −14 − 7h.

{fig:ea_def}

2.6

The Ising spin glass

{sec:SpinGlass}

In real magnetic materials, localized magnetic moments are subject to several

sources of interactions. Apart from the exchange interaction mentioned in the

previous Section, they may interact through intermediate conduction electrons,

etc... As a result, depending on the material which one considers, their interaction

can be either ferromagnetic (their energy is minimized when they are parallel)

or antiferromagnetic (their energy is minimized when they point opposite to

each other ). Spin glasses are a family of materials whose magnetic properties

are particularly complex. They can be produced by diluting a small fraction of

a ‘transition magnetic metal’ like manganese into a ‘noble metal’ like copper in

a ratio 1 : 100. In such an alloy, magnetic moments are localized at manganese

atoms, which are placed at random positions in a copper background. Depend-

ing on the distance of two manganese atoms, the net interaction between their

magnetic moments can be either ferromagnetic or antiferromagnetic.

The Edwards-Anderson model is a widely accepted mathematical ab-

straction of these physical systems. Once again, the basic degrees of freedom are

Ising spins σi ∈ {−1, +1} sitting at the corners of a d-dimensional cubic lattice

L = {1, . . . , L}d, i ∈ L. The conﬁguration space is therefore {−1, +1}L. As in

the Ising model, the energy function reads

E(σ) = −

�

(ij)

Jijσiσj − B

�

i∈L

σi ,

(2.82)

where �

(ij) runs over each edge of the lattice. Unlike in the Ising ferromagnet,

a diﬀerent coupling constant Jij is now associated to each edge (ij), and its


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

46

STATISTICAL PHYSICS AND PROBABILITY THEORY

Fig. 2.6. Four conﬁgurations of a small Edwards-Anderson model: continuous

lines indicate ferromagnetic interactions (Jij = +1), while dashed lines are for

antiferromagnetic interactions (Jij = −1). In zero magnetic ﬁeld (h = 0), the

four conﬁgurations are degenerate and have energy E = −2. The bars indicate

the unsatisﬁed interaction. Notice that there is no conﬁguration with lower en-

ergy. This system is frustrated since it is impossible to satisfy simultaneously all

constraints.

{fig:frustr}

sign can be positive or negative. The interaction between spins σi and σj is

ferromagnetic if Jij &gt; 0 and antiferromagnetic if Jij &lt; 0.

A pictorial representation of this energy function is given in Fig. 2.5. The

Boltzmann distribution is given by

pβ(σ) =

1

Z(β) exp





β

�

(ij)

Jijσiσj + βB

�

i∈L

σi





 ,

(2.83)

Z(β) =

�

σ

exp





β

�

(ij)

Jijσiσj + βB

�

i∈L

σi





 .

(2.84)

It is important to notice that the couplings {Jij} play a completely diﬀerent role

from the spins {σi}. The couplings are just parameters involved in the deﬁnition

of the energy function, as the magnetic ﬁeld B, and they are not summed over

when computing the partition function. In principle, for any particular sample

of a magnetic material, one should estimate experimentally the values of the

Jij’s, and then compute the partition function. We could have made explicit

the dependence of the partition function and of the Boltzmann distribution on

the couplings by using notations such as Z(β, B; {Jij}), pβ,B;{Jij}(σ). However,

when it is not necessary, we prefer to keep to lighter notations.

The present understanding of the Edwards-Anderson model is much poorer

than for the ferromagnetic models introduced in the previous Section. The basic

reason of this diﬀerence is frustration and is illustrated in Fig. 2.6 on an L = 2,

d = 2 model (a model consisting of just 4 spins). A spin glass is frustrated

whenever there exist local constraints that are in conﬂict, meaning that it is not

possible to all of them satisfy simultaneously. In the Edwards Anderson model,

a plaquette is a group of four neighbouring spins building a square. A plaquette

is frustrated if and only if the product of the Jij along all four edges of the

plaquette is negative. As shown in Fig. 2.6, it is then impossible to minimize

simultaneously all the four local energy terms associated with each edge. In a

spin glass, the presence of a ﬁnite density of frustrated plaquettes generates a


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

NOTES

47

very complicated energy landscape. The resulting eﬀect of all the interactions

is not obtained by ‘summing’ the eﬀects of each of them separately, but is is

the outcome of a complex interplay. The ground state spin conﬁguration (the

one satisfying the largest possible number of interactions) is diﬃcult to ﬁnd: it

cannot be guessed on symmetry grounds. It is also frequent to ﬁnd in a spin glass

a conﬁguration which is very diﬀerent form the ground state but has an energy

very close to the ground state energy. We shall explore these and related issues

throughout the book.

Notes

There are many good introductory textbooks on statistical physics and thermo-

dynamics, for instance the books by Reif (Reif, 1965) or Huang (Huang, 1987).

Going towards more advanced texts, one can suggest the books by Ma (Ma,

1985) and Parisi (Parisi, 1998b). A more mathematically minded presentation

can be found in the books by Gallavotti (Galavotti, 1999) and Ruelle (Ruelle,

1999).

The two dimensional Ising model at vanishing external ﬁeld can also be solved

by a transfer matrix technique, see for instance (Baxter, 1982). The transfer

matrix, which passes from a column of the lattice to the next, is a 2L × 2L

matrix, and its dimension diverges exponentially with the lattice size L. Finding

its largest eigenvalue is therefore a complicated task. Nobody has found the

solution so far for B ̸= 0.

Spin glasses will be a recurring theme in this book, and more will be said

about them in the next Chapters. An introduction to this subject from a physicist

point of view is provided by the book of Fischer and Hertz (Fischer and Hetz,

1993) or the review by Binder and Young (Binder and Young, 1986). The concept

of frustration was introduced in a beautiful paper by Gerard Toulouse (Toulouse,

1977).


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

3

INTRODUCTION TO COMBINATORIAL OPTIMIZATION

{ch:intro_optim}

This Chapter provides an elementary introduction to some basic concepts in

theoretical computer science. Which computational tasks can/cannot be accom-

plished eﬃciently by a computer? How much resources (time, memory, etc.) are

needed for solving a speciﬁc problem? What are the performances of a spe-

ciﬁc solution method (an algorithm), and, whenever more than one method is

available, which one is preferable? Are some problems intrinsically harder than

others? This are some of the questions one would like to answer.

One large family of computational problems is formed by combinatorial op-

timization problems. These consist in ﬁnding a member of a ﬁnite set which

maximizes (or minimizes) an easy-to-evaluate objective function. Several fea-

tures make such problems particularly interesting. First of all, most of the time

they can be converted into decision problems (questions which require a YES/NO

answer), which are the simplest problems allowing for a rich theory of computa-

tional complexity. Second, optimization problems are ubiquitous both in appli-

cations and in pure sciences. In particular, there exist some evident connections

both with statistical mechanics and with coding theory. Finally, they form a very

large and well studied family, and therefore an ideal context for understanding

some advanced issues. One should however keep in mind that computation is

more than just combinatorial optimization. A distinct (and in some sense larger)

family consists of counting problems. In this case one is asked to count how many

elements of a ﬁnite set have some easy-to-check property. We shall say something

about such problems in later Chapters. Another large family on which we will

say basically nothing consists of continuous optimization problems.

This Chapter is organized as follows. The study of combinatorial optimization

is introduced in Sec. 3.1 through a simple example. This section also contains

the basic deﬁnition of graph theory that we use throughout the book. General

deﬁnitions and terminology are given in Sec. 3.2. These deﬁnitions are further

illustrated in Sec. 3.3 through several additional examples. Section 3.4 provides

an informal introduction to some basic concepts in computational complexity.

As mentioned above, combinatorial optimization problems often appear in pure

sciences and applications. The examples of statistical physics and coding are

brieﬂy discussed in Secs. 3.5 and 3.6.

3.1

A ﬁrst example: minimum spanning tree

{sec:MST}

The minimum spanning tree problem is easily stated and may appear in many

practical applications. Suppose for instance you have a bunch of computers in a

48


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

A FIRST EXAMPLE: MINIMUM SPANNING TREE

49

4

2

2

5

7

5

1

6

5

3

d

b

c

e

f

g

a

Fig. 3.1. This graph has 7 vertices (labeled a to g) and 10 edges. The ‘cost’ of

each edge is indicated next to it. In the Minimum Spanning Tree problem, one

seeks a subgraph connecting all vertices, without any loop, of minimum cost.

{fig:MSTree}

building. You may want to connect them pairwise in such a way that the resulting

network is completely connected and the amount of cable used is minimum.

3.1.1

Deﬁnition of the problem and basics of graph theory

A mathematical abstraction of the above practical problem requires us to ﬁrst

deﬁne basic graph theoretic deﬁnitions. A graph is a set V of vertices, labeled

by {1, 2, . . . , |V|} and a set E of edges connecting them: G = (V, E). The ver-

tex set can be any ﬁnite set but one often takes the set of the ﬁrst |V| inte-

gers: V = {1, 2, . . . , |V|}. The edges are simply unordered couples of distinct

vertices E ⊆ V × V. For instance an edge joining vertices i and j is identi-

ﬁed as e = (i, j). A weighted graph is a graph where a cost (a real num-

ber) is associated with every edge. The degree of a vertex is the number of

edges connected to it. A path between two vertices i and j is a set of edges

{(j, i2), (i2, i3), (i3, i4), . . . , (ir−1, ir), (ir, j). A graph is connected if, for every

pair of vertices, there is a path which connects them. A completely con-

nected graph, or complete graph, also called a clique, is a graph where all the

|V|(|V| − 1)/2 edges are present. A cycle is a path starting and ending on the

same vertex. A tree is a connected graph without a cycle.

Consider the graph in Fig. 3.1. You are asked to ﬁnd a tree (a subset of the

edges buiding a cycle-free subgraph) such that any two vertices are connected

by exactly one path (in this case the tree is said to be spanning). To ﬁnd such

a subgraph is an easy task. The edges {(a, b); (b, c); (c, d); (b, g); (d, e)}, for in-

stance, do the job. However in our problem a cost is associated with each edge.

The cost of a subgraph is assumed to be equal to the sum of the costs of its

edges. Your problem is to ﬁnd the spanning tree with minimum cost. This is a

non-trivial problem.

In general, an instance of the minimum spanning tree (MST) problem is

given by a connected weighted graph (each edge e has a cost w(e) ∈ R). The

optimization problem consists in ﬁnding a spanning tree with minimum cost.

What one seeks is an algorithm which, given an instance of the MST problem,

outputs the spanning tree with lowest cost.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

50

INTRODUCTION TO COMBINATORIAL OPTIMIZATION

3.1.2

An eﬃcient algorithm for the minimum spanning tree problem

{sec:efficient}

The simple minded approach would consist in enumerating all the spanning

trees for the given graph, and comparing their weights. However the number of

spanning trees grows very rapidly with the size of the graph. Consider, as an

example, the complete graph on N vertices. The number of spanning trees of

such a graph is, according to the Cayley formula, N N−2. Even if the cost of any

such tree were evaluated in 10−3 sec, it would take 2 years to ﬁnd the MST of

a N = 12 graph, and half a century for N = 13. At the other extreme, if the

graph is very simple, it may contain a small number of spanning trees, a single

one in the extreme case where the graph is itself a tree. Nevertheless, in most

interesting examples the situation is nearly as dramatic as in the complete graph

case.

A much better algorithm can be obtained from the following theorem:

{thm:MSTtheorem}

Theorem 3.1 Let U ⊂ V be a proper subset of the vertex set V (such that neither

U nor V\U are empty). Let us consider the subset F of edges which connect a

vertex in U to a vertex in V\U, and let e ∈ F be an edge of lowest cost in this

subset: w(e) ≤ w(e′) for any e′ ∈ F. If there are several such edges, e can be any

of them. Then there exists a minimum spanning tree which contains e.

Proof: Consider a MST T , and suppose that it does not contain the edge e.

This edge is such that e = (i, j) with i ∈ U and j ∈ V\U. The spanning tree

T must contain a path between i and j. This path contains at least one edge

f connecting a vertex in U to a vertex in V\U, and f is distinct from e. Now

consider the subgraph T ′ built from T by removing the edge f and adding the

edge e. We leave to the reader the exercise of showing that T ′ is a spanning tree.

Moreover E(T ′) = E(T ) + w(e) − w(f). Since T is a MST, E(T ′) ≥ E(T ). On

the other hand e has minimum cost within F, hence w(e) ≤ w(f). Therefore

w(e) = w(f) and T ′ is a MST containing e. □

This result allows to construct a minimum spanning tree of a graph incre-

mentally. One starts from a single vertex. At each step a new edge can be added

to the tree, whose cost is minimum among all the ones connecting the already

existing tree with the remaining vertices. After N − 1 iterations, the tree will be

spanning.

MST algorithm ((Prim, 1957))

Input: A non-empty connected graph G = (V, E), and a weight function w :

E → R+.

Output: A minimum spanning tree T and its cost E(T ).

1. Set U := {1}, T := ∅ and E = 0.

2. While V\U is not empty

2.1 Let F := {e = (ij) ∈ E such that i ∈ U, j ∈ V\U}.

2.2 Find e∗ := arg mine∈F{w(e)}. Let e∗ := (i∗, j∗) with i∗ ∈ U,

j∗ ∈ V\U.

2.3 Set U := U ∪ i∗, T := T ∪ e∗, and E := E + w(e∗).

3. Output the spanning tree T and its cost E.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

GENERAL DEFINITIONS

51

d

2

4

1

3

5

7

2

b

c

g

h

a

e

f

Fig. 3.2. A minimum spanning tree for the graph deﬁned in Fig. 3.1. The cost

of this tree is E = 17.

{fig:MSTree_sol}

Figure 3.2 gives the MST for the problem described in Fig. 3.1. It is easy to

obtain it by applying the above algorithm.

⋆

Exercise 3.1 Show explicitly that the algorithm MST always outputs a mini-

mum spanning tree.

Theorem 3.1 establishes that, for any U ⊂ V, and any lowest cost edge e

among the ones connecting U to V\U, there exists a MST containing e. This

does not guarantee that, when two diﬀerent sets U1 and U2, and the correspond-

ing lowest cost edges e1 and e2 are considered, there exists a MST containing

both e1 and e2. The above algorithm works by constructing a sequence of such

U’s and adding to the tree the corresponding lowest weight edges. It is therefore

not obvious a priori that it will output a MST (unless this is unique).

Let us analyze the number of elementary operations required by the algorithm

to construct a spanning tree on an N nodes graph. By ‘elementary operation’

we mean comparisons, sums, multiplications, etc, all of them counting as one.

Of course, the number of such operations depends on the graph, but we can

ﬁnd a simple upper bound by considering the completely connected graph. Most

of the operations in the above algorithm are comparisons among edge weights

for ﬁnding e∗ in step 2.2. In order to identify e∗, one has to scan at most

|U| × |V\U| = |U| × (N − |U|) edges connecting U to V\U. Since |U| = 1 at the

beginning and is augmented of one element at each iteration of the cycle 2.1-2.3,

the number of comparisons is upper bounded by �N

U=0 U(N − U) ≤ N 3/66.

This is an example of a polynomial algorithm, whose computing time grows like

a power law of the number of vertices. The insight gained from the theorem

provides an algorithm which is much better than the naive one, at least when N

gets large.

3.2

General deﬁnitions

{sec:gendef}

MST is an example of a combinatorial optimization problem. This is deﬁned

by a set of possible instances. An instance of MST is deﬁned by a connected

6The algorithm can be easily improved by keeping an ordered list of the edges already

encountered


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

52

INTRODUCTION TO COMBINATORIAL OPTIMIZATION

weighted graph. In general, an instance of a combinatorial optimization problem

is described by a ﬁnite set X of allowed conﬁgurations and a cost function E

deﬁned on this set and taking values in R. The optimization problem consists in

ﬁnding the optimal conﬁguration C ∈ X, namely the one with the smallest cost

E(C). Any set of such instances deﬁnes a combinatorial optimization problem.

For a particular instance of MST, the space of conﬁgurations is simply the set of

spanning trees on the given graph, while the cost function associated with each

spanning tree is the sum of the costs of its edges.

We shall say that an algorithm solves an optimization problem if, for every

instance of the optimization problem, it gives the optimal conﬁguration, or if it

computes its cost. In all the problems which we shall discuss, there is a ‘natural’

measure of the size of the problem N (typically a number of variables used

to deﬁne a conﬁguration, like the number of edges of the graph in MST), and

the number of conﬁgurations scales, at large N like cN, or in some cases even

faster, e. g. like N! or N N. Notice that, quite generally, evaluating the cost

function on a particular conﬁguration is an easy task. The diﬃculty of solving

the combinatorial optimization problem comes therefore essentially from the size

of the conﬁguration space.

It is a generally accepted practice to estimate the complexity of an algorithm

as the number of ‘elementary operations’ required to solve the problem. Usually

one focuses onto the asymptotic behavior of this quantity as N → ∞. It is

obviously of great practical interest to construct algorithms whose complexity is

as small as possible.

One can solve a combinatorial optimization problem at several levels of re-

ﬁnement. Usually one distinguishes three types of problems:

• The optimization problem: Find an optimal conﬁguration C∗.

• The evaluation problem: Determine the cost E(C∗) of an optimal conﬁg-

uration.

• The decision problem: Answer to the question: “Is there a conﬁguration

of cost less than a given value E0?”

3.3

More examples

{sec:Examples}

The general setting described in the previous Section includes a large variety of

problems having both practical and theoretical interest. In the following we shall

provide a few selected examples.

3.3.1

Eulerian circuit

One of the oldest documented examples goes back to the 18th century. The

old city of K¨onigsberg had seven bridges (see Fig. 3.3), and its habitants were

wondering whether it was possible to cross once each of this bridges and get back

home. This can be generalized and translated in graph-theoretic language as the

following decision problem. Deﬁne a multigraph exactly as a graph but for the

fact that two given vertices can be connected by several edges. The problem

consists in ﬁnding whether there is there a circuit which goes through all edges


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

MORE EXAMPLES

53



A

B

D

C

Fig. 3.3. Left: a map of the old city of K¨onigsberg, with its seven bridges, as

drawn in Euler’s paper of 1736. The problem is whether one can walk along the

city, crossing each bridge exactly once and getting back home. Right: a graph

summarizing the problem. The vertices A, B, C, D are the various parts of lands

separated by a river, an edge exists between two vertices whenever there is a

bridge. The problem is to make a closed circuit on this graph, going exactly once

through every edge.

{fig:seven-bridges}

of the graph only once, and returns to its starting point. Such a circuit is now

called a Eulerian circuit, because this problem was solved by Euler in 1736,

when he proved the following nice theorem. As for ordinary graphs, we deﬁne

the degree of a vertex as the number of edges which have the vertex as an

end-point.

Theorem 3.2 Given a connected multigraph, there exists an Eulerian circuit if

and only if every vertex has an even degree.

{th:euler}

This theorem automatically provides an algorithm for the decision problem

whose complexity grows linearly with the number of vertices of the graph: just

go through all the vertices of the graph and check their degree.

Exercise 3.2 Show that, if an Eulerian circuit exists the degrees are necessar-

ily even.

Proving the inverse implication is slightly more diﬃcult. A possible ap-

proach consists in showing the following slightly stronger result. If all the ver-

tices of a connected graph G have even degree but i and j, then there exists a

path from i to j that visits once each edge in G. This can be proved by induc-

tion on the number of vertices. [Hint: Stat from i and make a step along the

edge (i, i′). Show that it is possible to choose i′ in such a way that the residual

graph G\(i, i′) is connected.]

3.3.2

Hamiltonian cycle

More than a century after Euler’s theorem, the great scientist sir William Hamil-

ton introduced in 1859 a game called the icosian game. In its generalized form,


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

54

INTRODUCTION TO COMBINATORIAL OPTIMIZATION

it basically asks whether there exists, in a graph, a Hamiltonian cycle, which

is a path going once through every vertex of the graph, and getting back to its

starting point. This is another decision problem, and, at a ﬁrst look, it seems

very similar to the Eulerian circuit. However it turns out to be much more com-

plicated. The best existing algorithms for determining the existence of an Hamil-

tonian cycle on a given graph run in a time which grows exponentially with the

number of vertices N. Moreover, the theory of computational complexity, which

we shall describe later in this Chapter, strongly suggests that this problem is in

fact intrinsically diﬃcult.

3.3.3

Traveling salesman

Given a complete graph with N points, and the distances dij between all pairs

of points 1 ≤ i &lt; j ≤ N, the famous traveling salesman problem (TSP) is an

optimization problem: ﬁnd a Hamiltonian cycle of minimum total length. One

can consider the case where the points are in a portion of the plane, and the

distances are Euclidean distances (we then speak of a Euclidean TSP), but of

course the problem can be stated more generally, with dij representing general

costs, which are not necessarily distances. As for the Hamiltonian cycle prob-

lem, the best algorithms known so far for the TSP have a running time which

grows exponentially with N at large N. Nevertheless Euclidean problems with

thousands of points can be solved.

3.3.4

Assignment

Given N persons and N jobs, and a matrix Cij giving the aﬃnity of person i for

job j, the assignment problem consists in ﬁnding the assignment of the jobs

to the persons (an exact one-to-one correspondence between jobs and persons)

which maximizes the total aﬃnity. A conﬁguration is characterized by a permu-

tation of the N indices (there are thus N! conﬁgurations), and the cost of the

permutation π is �

i Ciπ(i). This is an example of a polynomial problem: there

exists an algorithm solving it in a time growing like N 3.

3.3.5

Satisﬁability

In the satisﬁability problem one has to ﬁnd the values of N Boolean variables

xi ∈ {T, F} which satisfy a set of logical constraints. Since each variable can be

either true or false, the space of conﬁgurations has size |X| = 2N. Each logical

constraint, called in this context a clause, takes a special form: it is the logical

OR (for which we use the symbol ∨) of some variables or their negations. For

instance x1 ∨ x2 is a 2-clause (2-clause means a clause of length 2, i.e. which

involves exactly 2 variables), which is satisﬁed if either x1 = T, or x2 = F, or

both. x1∨x2∨x3 is a 3-clause, which is satisﬁed by all conﬁgurations of the three

variables except x1 = x2 = T, x3 = F. The problem is to determine whether

there exists a conﬁguration which satisﬁes all constraints (decision problem), or

to ﬁnd the conﬁguration which minimizes the number of violated constraints

(optimization problem). The decision problem is easy when all the clauses have

length smaller or equal to 2: there exists an algorithm running in a time growing


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

ELEMENTS OF THE THEORY OF COMPUTATIONAL COMPLEXITY

55

linearly with N. In other cases, all known algorithms solving the satisﬁability

decision problem run in a time which grows exponentially with N.

3.3.6

Coloring and vertex covering

Given a graph and an integer q, the famous q-coloring problem asks if it is

possible to color the vertices of the graph using q colors, in such a way that

two vertices connected by an edge have diﬀerent colors. In the same spirit, the

vertex-cover problem asks to cover the vertices with ‘pebbles’, using the small-

est possible number of pebbles, in such a way that every edge of the graph has

at least one of its two endpoints covered by a pebble.

3.3.7

Number partitioning

Number partitioning is an example which does not come from graph theory.

An instance is a set S of N integers S = {x1, .., xN}. A conﬁguration is a partition

of these numbers into two groups A and S \ A . Is there a partition such that

�

i∈A xi = �

i∈S\A xi?

3.4

Elements of the theory of computational complexity

{sec:Complexity}

One main branch of theoretical computer science aims at constructing an intrinsic

theory of computational complexity. One would like, for instance, to establish

which problems are harder than others. By ‘harder problem’, we mean a problem

that takes a longer running time to be solved. In order to discuss rigorously

the computational complexity of a problem, we would need to deﬁne a precise

model of computation (introducing, for instance, Turing machines). This would

take us too far. We will instead evaluate the running time of an algorithm in

terms of ‘elementary operations’: comparisons, sums, multiplications, etc. This

informal approach is essentially correct as long as the size of the operands remains

uniformly bounded.

3.4.1

The worst case scenario

As we already mentioned in Sec. 3.2, a combinatorial optimization problem,

is deﬁned by the set of its possible instances. Given an algorithm solving the

problem, its running time will vary from instance to instance, even if the instance

‘size’ is ﬁxed. How should we quantify the overall hardness of the problem? A

crucial choice of computational complexity theory consists in considering the

‘worst’ (i.e. the one which takes longer time to be solved) instance among all the

ones having the same size.

This choice has two advantages: (i) It allows to construct a ‘universal’ theory.

(ii) Once the worst case running time of a given algorithm is estimated, this

provides a performance guarantee on any instance of the problem.

3.4.2

Polynomial or not?

A second crucial choice consists in classifying algorithms in two classes: (i) Poly-

nomial, if the running time is upper bounded by a ﬁxed polynomial in the size


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

56

INTRODUCTION TO COMBINATORIAL OPTIMIZATION

of the instance. In mathematical terms, let TN the number of operations required

for solving an instance of size N in the worst case. The algorithm is polynomial

when there exist a constant k such that TN = O(N k). (ii) Super-polynomial,

if no such upper bound exists. This is for instance the case if the time grows

exponentially with the size of the instance (we shall call algorithms of this type

exponential), i.e. TN = Θ(kN) for some constant k.

Example 3.3 In 3.1.2, we were able to show that the running time of the

MST algorithm is upper bounded by N 3, with N the number of vertices tin the

graph. This implies that such an algorithm is polynomial.

Notice that we did not give a precise deﬁnition of the ‘size’ of a problem.

One may wonder whether, changing the deﬁnition, a particular problem can be

classiﬁed both as polynomial an as super-polynomial. Consider, for instance, the

assignment problem with 2N points. One can deﬁne the size as being N, or 2N ,

or even N 2 which is the number of possible person-job pairs. The last deﬁnition

would be relevant if one would work for instance with occupation numbers nij ∈

{0, 1}, the number nij being one if and only if the job i is assigned to person j.

However, any two of these ‘natural’ deﬁnitions of size are a polynomial function

one of the other. Therefore they do not aﬀect the classiﬁcation of an algorithm

as polynomial or super-polynomial. We will discard other deﬁnitions (such as eN

or N!) as ‘unnatural’, without any further ado. The reader can convince himself

on each of the examples of the previous Section.

3.4.3

Optimization, evaluation, decision

In order to get a feeling of their relative levels of diﬃculty, let us come back for a

while to the three types of optimization problems deﬁned in Sec. 3.2, and study

which one is the hardest.

Clearly, if the cost of any conﬁguration can be computed in polynomial time,

the evaluation problem is not harder than the optimization problem: if one can

ﬁnd the optimal conﬁguration in polynomial time, one can compute its cost also

in polynomial time. The decision problem (deciding whether there exists a con-

ﬁguration of cost smaller than a given E0) is not harder than the evaluation

problem. So the order of increasing diﬃculty is: decision, evaluation, optimiza-

tion.

But actually, in many cases where the costs take discrete values, the evalu-

ation problem is not harder than the decision problem, in the following sense.

Suppose that we have a polynomial algorithm solving the decision problem, and

that the costs of all conﬁgurations can be scaled to be integers in an interval

[0, Emax] of length Emax = exp{O(N k)} for some k &gt; 0. An algorithm solving

the decision problem can be used to solve the evaluation problem by dichotomy:

one ﬁrst takes E0 = Emax/2. If there exists a conﬁguration of energy smaller

than E0, one iterates with E0 the center of the interval [0, Emax/2]. In the oppo-

site case, one iterates with E0 the center of the interval [Emax/2, Emax]. Clearly


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

ELEMENTS OF THE THEORY OF COMPUTATIONAL COMPLEXITY

57

this procedure ﬁnds the cost of the optimal conﬁguration(s) in a time which is

also polynomial.

3.4.4

Polynomial reduction

{sub:polred}

One would like to compare the levels of diﬃculty of various decision problems.

The notion of polynomial reduction formalizes the sentence “not harder than”

which we used so far, and helps to get a classiﬁcation of decision problems.

Roughly speaking, we say that a problem B is not harder than A if any eﬃ-

cient algorithm for A (if such an algorithm existed) could be used as a subroutine

of an algorithm solving eﬃciently B. More precisely, given two decision problems

A and B, one says that B is polynomially reducible to A if the following

conditions hold:

1. There exists a mapping R which transforms any instance I of problem B

into an instance R(I) of problem A, such that the solution (yes/no) of the

instance R(I) of A gives the solution (yes/no) of the instance I of B.

2. The mapping I �→ R(I) can be computed in a time which is polynomial in

the size of I.

3. The size of R(I) is polynomial in the size of I. This is in fact a consequence

of the previous assumptions but there is no harm in stating it explicitly.

A mapping R satisfying the above requirements is called a polynomial reduc-

tion. Constructing a polynomial reduction among two problems is an important

achievement since it eﬀectively reduces their study to the study of just one of

them. Suppose for instance to have a polynomial algorithm AlgA for solving A.

Then a polynomial reduction of B to A can be used for constructing a poly-

nomial algorithm for solving B. Given an instance I of B, the algorithm just

compute R(I), feeds it into the AlgA, and outputs the output of AlgA. Since the

size of R(I) is polynomial in the size of I, the resulting algorithm for B is still

polynomial.

For concreteness, we will work out an explicit example. We will show that the

problem of existence of a Hamiltonian cycle in a graph is polynomially reducible

to the satisﬁability problem.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

58

INTRODUCTION TO COMBINATORIAL OPTIMIZATION

Example 3.4 An instance of the Hamiltonian cycle problem is a graph with

N vertices, labeled by i ∈ {1, ..., N}. If there exists a Hamiltonian cycle in the

graph, it can be characterized by N 2 Boolean variables xri ∈ {0, 1}, where

xri = 1 if vertex number i is the r’th vertex in the cycle, and xri = 0 otherwise

(one can take for instance x11 = 1). We shall now write a number of constraints

that the variables xri must satisfy in order for a Hamiltonian cycle to exist,

and we shall ensure that these constraints take the forms of the clauses used

in the satisﬁability problem (identifying x = 1 as true, x = 0 as false):

• Each vertex i ∈ {1, ..., N} must belong to the cycle: this can be written

as the clause x1i ∨ x2i ∨ .... ∨ xNi, which is satisﬁed only if at least one of

the numbers x1i, x2i, ..., xNi equals one.

• For every r ∈ {1, ..., N}, one vertex must be the r’th visited vertex in the

cycle: xr1 ∨ xr2 ∨ ... ∨ xrN

• Each vertex i ∈ {1, ..., N} must be visited only once. This can be imple-

mented through the N(N − 1)/2 clauses ¯xrj ∨ ¯xsj, for 1 ≤ r &lt; s ≤ N.

• For every r ∈ {1, ..., N}, there must be only one r’th visited vertex in the

cycle; This can be implemented through the N(N −1)/2 clauses xri∨xrj,

for 1 ≤ i &lt; j ≤ N.

• For every pair of vertices i &lt; j which are not connected by an edge of

the graph, these vertices should not appear consecutively in the list of

vertices of the cycle. Therefore we add, for every such pair and for every

r ∈ {1, ..., N},the clauses xri ∨ x(r+1)j and xrj ∨ x(r+1)i (with the ‘cyclic’

convention N + 1 = 1).

It is straightforward to show that the size of the satisﬁability problem con-

structed in this way is polynomial in the size of the Hamiltonian cycle prob-

lem. We leave as an exercise to show that the set of all above clauses is a

suﬃcient set: if the N 2 variables satisfy all the above constraints, they describe

a Hamiltonian cycle.

3.4.5

Complexity classes

Let us continue to focus onto decision problems. The classiﬁcation of these prob-

lems with respect to polynomiality is as follows:

• Class P: These are the polynomial problems, for which there exists an

algorithm running in polynomial time. An example, cf. Sec. 3.1, is the

decision version of the minimum spanning tree (which asks for a yes/no

answer to the question: given a graph with costs on the edges, and a number

E0, is there a spanning tree with total cost less than E0?).

• Class NP: This is the class of non-deterministic polynomial problems,

which can be solved in polynomial time by a ‘non deterministic’ algorithm.

Roughly speaking, such an algorithm can run in parallel on an arbitrarily

large number of processors. We shall not explain this notion in detail here,

but rather use an alternative and equivalent characterization. We say that a


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

ELEMENTS OF THE THEORY OF COMPUTATIONAL COMPLEXITY

59

problem is in the class NP if there exists a ‘short’ certiﬁcate which allows to

check a ‘yes’ answer to the problem. A short certiﬁcate means a certiﬁcate

that can be checked in polynomial time.

A polynomial problem like the minimum spanning tree describes above

is automatically in NP so P ⊆ NP. The decision version of the TSP is

also in NP: if there is a TSP tour with cost smaller than E0, the short

certiﬁcate is simple: just give the tour, and its cost will be computed in

linear time, allowing to check that it is smaller than E0. Satisﬁability also

belongs to NP: a certiﬁcate is obtained from the assignment of variables

satisfying all clauses. Checking that all clauses are satisﬁed is linear in

the number of clauses, taken here as the size of the system. In fact there

are many important problems in the class NP, with a broad spectrum of

applications ranging from routing to scheduling, to chip veriﬁcation, or to

protein folding. . .

• Class NP-complete: These are the hardest problem in the NP class. A

problem is NP-complete if: (i) it is in NP, (ii) any other problem in NP

can be polynomially reduced to it, using the notion of polynomial reduction

deﬁned in Sec. 3.4.4. If A is NP-complete, then: for any other problem B

in NP, there is a polynomial reduction mapping B to A. So if we had a

polynomial algorithm to solve A, then all the problems in the broad class

NP would be solved in polynomial time.

It is not a priori obvious whether there exist any NP-complete problem. A major

achievement of the theory of computational complexity is the following theorem,

obtained by Cook in 1971.

Theorem 3.5 The satisﬁability problem is NP-complete

We shall not give here the proof of the theorem. Let us just mention that the

satisﬁability problem has a very universal structure (an example of which was

shown above, in the polynomial reduction of the Hamiltonian cycle problem to

satisﬁability). A clause is built as the logical OR (denoted by ∨) of some variables,

or their negations. A set of several clauses, to be satisﬁed simultaneously, is the

logical AND (denoted by ∧) of the clauses. Therefore a satisﬁability problem is

written in general in the form (a1∨a2∨...)∧(b1∨b2∨...)∧...., where the ai, bi are

‘literals’, i.e. any of the original variables or their negations. This form is called

a

conjunctive normal form (CNF), and it is easy to see that any logical

statement between Boolean variables can be written as a CNF. This universal

decomposition gives some idea of why the satisﬁability problem can play a central

role.

3.4.6

P=NP ?

When a NP-complete problem A is known, one can relatively easily ﬁnd other

NP-complete problems: if there exists a polynomial reduction from A to another

problem B ∈ NP, then B is also NP-complete. In fact, whenever RA←P is a

polynomial reduction from a problem P to A and RB←A is a polynomial reduc-


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

60

INTRODUCTION TO COMBINATORIAL OPTIMIZATION

NP-complete

P

NP

SAT

3SAT 

TSP

Hamiltonian cycle

(d)

3-Colouring

Eulerian circuit

Assignment

2-colouring

2SAT

Fig. 3.4. Classiﬁcation of some famous decision problems. If P ̸= NP, the classes

P and NP-complete are disjoint. If it happened that P = NP, all the problems in

NP, and in particular all those mentioned here, would be solvable in polynomial

time.

tion from A to B, then RB←A ◦ RA←P is a polynomial reduction from P to B.

Starting from satisﬁability, it has been possible to ﬁnd, with this method, thou-

sands of NP-complete problems. To quote a few of them, among the problems

we have encountered so far, Hamiltonian circuit, TSP, and 3-satisﬁability (i.e.

satisﬁability with clauses of length 3 only) are NP-complete. Actually most of

NP problems can be classiﬁed either as being in P, or being NP-complete. The

precise status of some NP problems, like graph isomorphism, is still unknown.

Finally, those problems which, not being in NP are at least as hard as NP-

complete problems, are usually called NP-hard. These includes both decision

problems for which a short certiﬁcate does not exist, and non-decision problems.

For instance the optimization and evaluation versions of TSP are NP-hard. How-

ever, in such cases, we shall chose among the expressions ‘TSP is NP-complete’

or ‘TSP is NP-hard’ rather freely.

One major open problem in the theory of computational complexity is whether

the classes P and NP are distinct or not. It might be that P=NP=NP-complete:

this would be the case if someone found a polynomial algorithm for one NP-

complete problem. This would imply that no problem in the broad NP-class

could be solved in polynomial time.

It is a widespread conjecture that there exist no polynomial algorithm for

NP-complete problems. Then the classes P and NP-complete would be disjoint.

In fact it is known that, if P ̸= NP, then there are NP problems which are neither

in P nor in NP-complete.

3.4.7

Other complexity classes

Notice the fundamental asymmetry in the deﬁnition of the NP class: the exis-

tence of a short certiﬁcate is requested only for the yes answers. To understand

the meaning of this asymmetry, consider the problem of unsatisﬁability (which

is the complement of the satisﬁability problem) formulated as: “given a set of


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

OPTIMIZATION AND STATISTICAL PHYSICS

61

clauses, is the problem unsatisﬁable?”. It is not clear if there exists a short cer-

tiﬁcate allowing to check a yes answer: it is very diﬃcult to prove that a problem

cannot be satisﬁed without checking an exponentially large number of possible

conﬁgurations. So it is not at all obvious that unsatisﬁability is in NP. Problems

which are complements of those in NP deﬁne the class of co-NP problems, ans

it is not known whether NP=co-NP or not, although it is widely believed that

co-NP is diﬀerent from NP. This consideration opens a Pandora box with many

other classes of complexities, but we shall immediately close it since it would

carry us too far.

3.5

Optimization and statistical physics

{sec:OptimizationPhysics}

3.5.1

General relation

There exists a natural mapping from optimization to statistical physics. Consider

an optimization problem deﬁned by a ﬁnite set X of allowed conﬁgurations, and a

cost function E deﬁned on this set with values in R. While optimization consists

in ﬁnding the conﬁguration C ∈ X with the smallest cost, one can introduce a

probability measure of the Boltzmann type on the space of conﬁgurations: For

any β, each C is assigned a probability 7

pβ(C) =

1

Z(β)e−βE(C) ;

Z(β) =

�

C∈X

e−βE(C) .

(3.1)

{eq:boltzmann_optim}

The positive parameter β plays the role of an inverse temperature. In the limit

β → ∞, the probability distribution pβ concentrates on the conﬁgurations of

minimum energy (ground states in the statistical physics jargon). This is the

relevant limit for optimization problems. In the statistical physics approach one

generalizes the problem to study properties of the distribution pβ at ﬁnite β. In

many cases it is useful to follow pβ when β increases (for instance by monitoring

the thermodynamic properties: internal energy, the entropy, and the speciﬁc

heat). This may be particularly useful, both for analytical and for algorithmic

purpose, when the thermodynamic properties evolve smoothly. An example of

practical application is the simulated annealing method, which actually samples

the conﬁguration space at larger and larger values of β until it ﬁnds a ground

state. It will be described in Chap. 4. Of course the existence of phase transitions

pose major challenges to this kind of strategies, as we will see.

3.5.2

Spin glasses and maximum cuts

To give a concrete example, let us go back to the spin glass problem of Sec. 2.6.

This involves N Ising spins σ1, . . . , σN in {±1}, located on the vertices of a

graph, and the energy function is:

7Notice that there exist alternatives to the straightforward generalization (3.1). In some

problems the conﬁguration space involves hard constraints, which can also be relaxed in a

ﬁnite temperature version.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

62

INTRODUCTION TO COMBINATORIAL OPTIMIZATION

E(σ) = −

�

(ij)

Jijσiσj,

(3.2)

where the sum �

(ij) runs over all edges of the graph and the Jij variables are

exchange couplings which can be either positive or negative. Given the graph and

the exchange couplings, what is the ground state of the corresponding spin glass?

This is a typical optimization problem. In fact, it very well known in computer

science in a slightly diﬀerent form.

Each spin conﬁguration partitions the set of vertices into two complementary

subsets: V± = {i | σi = ±1}. Let us call γ(V+) the set of edges with one endpoint

in V+, the other in V−. The energy of the conﬁguration can be written as:

E(σ) = −C + 2

�

(ij)∈γ(V+)

Jij,

(3.3)

where C = �

(ij) Jij. Finding the ground state of the spin glass is thus equivalent

to ﬁnding a partition of the vertices, V = V+ ∪ V−, such that �

(ij)∈γ(V+) cij is

maximum, where cij ≡ −Jij. This problem is known as the maximum cut

problem (MAX-CUT): the set of edges γ(V+) is a cut, each cut is assigned a

weight �

(ij)∈γ(V+) cij, and one seeks the cut with maximal weight.

Standard results on max-cut immediately apply: In general this is an NP-hard

problem, but there are some categories of graphs for which it is polynomially

solvable. In particular the max-cut of a planar graph can be found in polynomial

time, providing an eﬃcient method to obtain the ground state of a spin glass

on a square lattice in two dimensions. The three dimensional spin glass problem

falls into the general NP-hard class, but nice ‘branch and bound’ methods, based

on its max-cut formulation, have been developed for it in recent years.

Another well known application of optimization to physics is the random

ﬁeld Ising model, which is a system of Ising spins with ferromagnetic couplings

(all Jij are positive), but with a magnetic ﬁeld hi which varies from site to site

taking positive and negative values. Its ground state can be found in polynomial

time thanks to its equivalence with the problem of ﬁnding a maximal ﬂow in a

graph.

3.6

Optimization and coding

{sec:OptimizationCoding}

Computational complexity issues are also crucial in all problems of information

theory. We will see it recurrently in this book, but let us just give here some

small examples in order to ﬁx ideas.

Consider the error correcting code problem of Chapter 1. We have a code,

which maps an original message to a codeword x, which is a point in the N-

dimensional hypercube {0, 1}N. There are 2M codewords (with M &lt; N), which

we assume to be a priori equiprobable. When the message is transmitted, the

codeword x is corrupted to -say- a vector y with probability Q(y|x). The decoding


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

NOTES

63

maps the received message y to one of the possible original codewords x′ = d(y).

As we saw, a measure of performance is the average block error probability:

Pav

B ≡

1

2M

�

x

�

y

Q(y|x) I(d(y) ̸= x)

(3.4)

A simple decoding algorithm would be the following: for each received message

y, consider all the 2N codewords, and determine the most likely one: d(y) =

arg maxx Q(y|x). It is clear that this algorithm minimizes the average block error

probability.

For a general code, there is no better way for maximizing Q(y|x) than going

through all codewords and computing their likelihood one by one. This takes a

time of order 2M, which is deﬁnitely too large. Recall in fact that, to achieve

reliable communication, M and N have to be large (in data transmission appli-

cation one may use N as large as 105). One may object that ‘decoding a general

code’ is too a general optimization problem. Just for specifying a single instance

we would need to specify all the codewords, which takes N 2M bits. Therefore,

the complexity of decoding could be a trivial consequence of the fact that even

reading the input takes a huge time. However, it can be proved that also decod-

ing codes possessing a concise (polynomial in the blocklength) speciﬁcation is

NP-hard. Examples of such codes will be given in the following chapters.

Notes

We have left aside most algorithmic issues in this chapter. In particular many

optimization algorithms are based on linear programming. There exist nice the-

oretical frameworks, and very eﬃcient algorithms, for solving continuous opti-

mization problems in which the cost function, and the constraints, are linear

functions of the variables. These tools can be successfully exploited for address-

ing optimization problems with discrete variables. The idea is to relax the integer

constraints. For instance, in the MAX-CUT problem, one should assign a value

xe ∈ {0, 1} to an edge e, saying whether e is in the cut. If ce is the cost of the

edge, one needs to maximize �

e xece over all feasible cuts. A ﬁrst step consists

in relaxing the integer constraints xe ∈ {0, 1} to xe ∈ [0, 1], enlarging the space

search. One then solves the continuous problem using linear programming. If the

maximum is achieved over integer xe’s, this yields the solution of the original

discrete problem. In the opposite case one can add extra constraints in order

to reduce again the space search until the a real MAX-CUT will be found. A

general introduction to combinatorial optimization, including all these aspects,

is provided by (Papadimitriou and Steiglitz, 1998).

A complete treatment of computational complexity theory can be found in

(Garey and Johnson, 1979), or in the more recent (Papadimitriou, 1994). The

seminal theorem by Cook was independently rediscovered by Levin in 1973. The

reader can ﬁnd its proof in one of the above books.

Euler discussed the K¨onisberg’s 7 bridges problem in (Euler, 1736).


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

64

INTRODUCTION TO COMBINATORIAL OPTIMIZATION

The TSP, which is simple to state, diﬃcult to solve, and lends itself to nice

pictorial representations, has attracted lots of works. The interested reader can

ﬁnd many references, pictures of TSP’s optimal tours with thousands of vertices,

including tours among the main cities in various countries, applets, etc.. on the

web, starting from instance from (Applegate, Bixby, Chv´atal and Cook, ).

The book (Hartmann and Rieger, 2002) focuses on the use of optimization al-

gorithms for solving some problems in statistical physics. In particular it explains

the determination of the ground state of a random ﬁeld Ising model with a max-

imum ﬂow algorithm. A recent volume edited by these same authors (Hartmann

and Rieger, 2004) addresses several algorithmic issues connecting optimization

and physics; in particular chapter 4 by Liers, J¨unger, Reinelt and Rinaldi de-

scribes the branch-and-cut approach to the maximum cut problem used for spin

glass studies.

An overview classical computational problems from coding theory is the re-

view by Barg (Barg, 1998). Some more recent issues are addressed by Spielman

(Spielman, 1997). Finally, the ﬁrst proof of NP-completeness for a decoding

problem was obtained by Berlekamp, McEliecee and van Tilborg (Berlekamp,

McEliecee and van Tilborg, 1978).


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

4

PROBABILISTIC TOOLBOX

{ch:Bridges}

The three ﬁelds that form the subject of this book, all deal with large sets of

random variables. Not surprisingly, they possess common underlying structures

and techniques. This Chapter describes some of them, insisting on the mathe-

matical structures, large deviations on one hand, and Markov chains for Monte

Carlo computations on the other hand. These tools will reappear several times

in the following Chapters.

Since this Chapter is more technical than the previous ones, we devote the

entire Section 4.1 to a qualitative introduction to the subject. In Sec. 4.2 we

consider the large deviation properties of simple functions of many independent

random variables. In this case many explicit results can be easily obtained. We

present a few general tools for correlated random variables in Sec. 4.3 and the

idea of Gibbs free energy in Sec. 4.4. Section 4.5 provide a simple introduction to

the Monte Carlo Markov chain method for sampling conﬁgurations from a given

probability distribution. Finally, in Sec. 4.6 we show how sinulated annealing

exploits Monte Carlo techniques for solving optimization problems.

4.1

Many random variables: a qualitative preview

{sec:Preview}

Consider a set of random variables x = (x1, x2, . . . , xN), with xi ∈ X and an N

dependent probability distribution

PN(x) = PN(x1, . . . , xN) .

(4.1)

This could be for instance the Boltzmann distribution for a physical system with

N degrees of freedom. The entropy of this law is HN = −E log PN(x). It often

happens that this entropy grows linearly with N at large N. This means that

the entropy per variable hN = HN/N has a ﬁnite limit limN→∞ hN = h. It is

then natural to characterize any particular realization of the random variables

(x1, . . . , xN) by computing the quantity

f(x) = 1

N log

�

1

PN(x)

�

,

(4.2)

{eq:Deff}

which measures how probable the event (x1, . . . , xN) is.. The expectation of f

is Ef(x) = hN. One may wonder if f(x) ﬂuctuates a lot, or if its distribution

is strongly peaked around f = hN. The latter hypothesis turns out to be the

correct one in many cases: When N ≫ 1, it often happens that the probability

distribution of f, QN(f) behaves exponentially:

65


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

66

PROBABILISTIC TOOLBOX

QN(f) .= e−NI(f) .

(4.3)

{eq:larged_ex}

where I(f) has a non-degenerate minimum at f = h, and I(h) = 0. This means

that, with large probability, a randomly chosen conﬁguration x has f(x) ‘close

to’ h, and, because of the deﬁnition (4.2) its probability is approximatively

exp(−Nh). Since the total probability of realizations x such that f(x) ≈ h

is close to one, their number must behave as N

.= exp(Nh). In other words,

the whole probability is carried by a small fraction of all conﬁgurations (since

their number, exp(Nh), is in general exponentially smaller than |X|N), and these

conﬁgurations all have the same probability. When such a property (often called

‘asymptotic equipartition’) holds, it has important consequences.

Suppose for instance one is interested in compressing the information con-

tained in the variables (x1, . . . , xN), which is a sequence of symbols produced by

an information source. Clearly, one should focus on those ‘typical’ sequences x

such that f(x) is close to h, because all the other sequences have vanishing small

probability. Since there are exp(Nh) such typical sequences, one must be able to

encode them in Nh/ log 2 bits by simply numbering them.

Another very general problem consists in sampling from the probability distri-

bution PN(x). With r realizations x1, . . . , xr drawn independently from PN(x),

one can estimate an expectation values E O(x) = �

x PN(x)O(x) as E O(x) ≈

1

r

�r

k=1 O(xk) without summing over |X|N terms, and the precision usually im-

proves like 1/√r at large r. A naive sampling algorithm could be the follow-

ing. First ‘propose’ a conﬁguration x from the uniform probability distribution

P unif

N

(x) = 1/|X|N: this is simple to be sampled8. Then ‘accept’ the conﬁguration

with probability PN(x). Such an algorithm is totally uneﬃcient: It is clear that,

for the expectation values of ‘well behaved’ observables, we seek conﬁgurations

x such that f(x) is close to h. However, such conﬁgurations are exponentially

rare, and the above algorithm will require a time of order exp[N(log |X| − h)] to

ﬁnd just one of them. The Monte Carlo method will provide a better alternative.

4.2

Large deviations for independent variables

{sec:LargedevIID}

A behavior of the type (4.3) is an example of a large deviation principle. One often

encounters systems with this property, and it can also hold with more general

functions f(x). The simplest case where such behaviors are found, and the case

where all properties can be controlled in great details, is that of independent

random variables. We study this case in the present section.

4.2.1

How typical is a series of observations?

Suppose that you are given given the values s1, . . . , sN of N i.i.d. random vari-

ables drawn from a ﬁnite space X according to a known probability distribution

8Here we are assuming that we have access to a source of randomness: ⌈N log2 |X|⌉ unbiased

random bits are suﬃcient to sample from P unif

N

(x). In practice one replaces the source of

randomness by a pseudorandom generator.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

LARGE DEVIATIONS FOR INDEPENDENT VARIABLES

67

{p(s)}s∈X . The si’s could be produced for instance by an information source, or

by some repeated measurements on a physical system. You would like to know

if the sequence s = (s1, . . . , sN) is a typical one, or if you found a rare event.

If N is large, one can expect that the number of appearances of a given x ∈ X

in a typical sequence should be close to Np(x). The method of types allows to

quantify this statement.

The type qs(x) of the sequence s is the frequency of appearance of symbol

x in the sequence:

qs(x) = 1

N

N

�

i=1

δx,si ,

(4.4)

where δ is the Kronecker symbol, such that δx,y = 1 if x = y and 0 otherwise.

For any observation s, the type qs(x), considered as a function of x, has the

properties of a probability distribution over X: q(x) ≥ 0 for any x ∈ X and

�

x q(x) = 1. In the following we shall denote by M(X) the space of probability

distributions over X: M(X) ≡ {q ∈ RX s.t. q(x) ≥ 0 , �

x q(x) = 1}. Therefore

qs ∈ M(X).

The expectation of the type qs(x) coincides with the original probability

distribution:

E qs(x) = p(x) .

(4.5)

Sanov’s theorem estimates the probability that the type of the sequence diﬀers

from p(x).

{thm:Sanov}

Theorem 4.1. (Sanov) Let x1, . . . , xN ∈ X be N i.i.d.’s random variables

drawn from the probability distribution p(x), and K ⊂ M(X) a compact set

of probability distributions over X. If q is the type of (x1, . . . , xN), then

Prob [q ∈ K] .= exp[−ND(q∗||p)] ,

(4.6)

where q∗ = arg minq∈K D(q||p), and D(q||p) is the KL divergence deﬁned in

Eq. (1.10) .

Basically this theorem means that the probability of ﬁnding a sequence with

type q behaves at large N like exp[−ND(q||p)]. Therefore, for large N, typical

sequences have a type q(x) = p(x), and those with a diﬀerent type are exponen-

tially rare. The proof of the theorem is a straightforward application of Stirling’s

formula and is left as an exercise for the reader. In Appendix 4.7 we give a

⋆

derivation using a ‘ﬁeld theoretical’ method as used in physics. It may be an

instructive simple example for the reader who wants to get used to these kinds

of techniques, frequently used by physicists.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

68

PROBABILISTIC TOOLBOX

Example 4.2 Let the xi’s be the outcome of a biased coin: X = {head, tail},

with p(head) = 1 − p(tail) = 0.8. What is the probability of getting 50 heads

and 50 tails in 100 throws of the coin? Using the expression (4.6) and (1.10) with

N = 100 and q(head) = q(tail) = 0.5, we get Prob[50 tails] ≈ 2.04 · 10−10.

Example 4.3 Let us consider the reverse case: we take a fair coin (p(head) =

p(tail) = 0.5) and ask what is the probability of getting 80 heads and 20 tails.

Sanov theorem provides the estimate Prob[80 heads] ≈ 4.27 · 10−9, which is

much higher than the one computed in the previous example.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

LARGE DEVIATIONS FOR INDEPENDENT VARIABLES

69

Example 4.4 A simple model of a column of the atmosphere consists in

studying N particles in the earth gravitational ﬁeld. The state of particle

i ∈ {1, . . . , N} is given by a single coordinate zi ≥ 0 which measures its height

with respect to earth level. For the sake of simplicity, we assume zi’s to be in-

teger numbers. We can, for instance, imagine to discretize the heights in terms

of some small unit length (e.g. millimeters). The N-particles energy function

reads, in properly chosen units:

E =

N

�

i=1

zi .

(4.7)

The type of a conﬁguration {x1, . . . , xN} can be interpreted as the density

proﬁle ρ(z)of the conﬁguration:

ρ(z) = 1

N

N

�

i=1

δz,zi .

(4.8)

Using the Boltzmann probability distribution (2.4), it is simple to compute the

expected density proﬁle, which is usually called the ‘equilibrium’ proﬁle:

ρeq(z) ≡ ⟨ρ(z)⟩ = (1 − e−β) e−βz .

(4.9)

If we take a snapshot of the N particles at a given instant, their density will

present some deviations with respect to ρeq(z). The probability of seeing a

density proﬁle ρ(z) is given by Eq. (4.6) with p(z) = ρeq(z) and q(z) = ρ(z). For

instance, we can compute the probability of observing an exponential density

proﬁle, like (4.9) with a diﬀerent parameter λ: ρλ(x) = (1 − e−λ) e−λx. Using

Eq. (1.10) we get:

D(ρλ||ρeq) = log

�1 − e−λ

1 − e−β

�

+ β − λ

eλ − 1 .

(4.10)

The function Iβ(λ) ≡ D(ρλ||ρeq) is depicted in Fig. 4.1.

Exercise 4.1 The previous example is easily generalized to the density proﬁle

of N particles in an arbitrary potential V (x). Show that the Kullback-Leibler

divergence takes the form

D(ρ||ρeq) = β

�

x

V (x)ρ(x) −

�

x

ρ(x) log ρ(x) + log z(β) .

(4.11)


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

70

PROBABILISTIC TOOLBOX

0

0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

2

0

0.5

1

1.5

2

2.5

3

3.5

4

Iβ(λ)

λ

β = 0.5

β = 1

β = 2

Fig. 4.1. Example 3: In an atmosphere where the equilibrium density proﬁle is

ρeq(z) ∝ e−βz, the probability of observing an atypical proﬁle ρ(z) ∝ e−λz is, for

a large number of particles N, exp[−NIβ(λ)]. The curves Iβ(λ), plotted here,

show that small values of λ are very rare.

{fig:profilefluc}

4.2.2

How typical is an empirical average?

The result (4.6) contains a detailed information concerning the large ﬂuctua-

tions of the random variables {xi}. Often one is interested in monitoring the

ﬂuctuations of the empirical average of a measurement, which is a real number

f(x):

f ≡ 1

N

N

�

i=1

f(xi) .

(4.12)

Of course f, will be “close” to E f(x) with high probability. The following result

quantiﬁes the probability of rare ﬂuctuations.

{thm:EmpiricalAverage}

Corollary 4.5 Let x1, . . . , xN be N i.i.d.’s random variables drawn from the

probability distribution p(x). Let f : X → R be a real valued function and f be

its empirical average. If A ⊂ R is a closed interval of the real axis

Prob [f ∈ A] .= exp[−NI(A)] ,

(4.13)

where

I(A) = min

q

�

D(q||p)

�����

�

x∈X

q(x)f(x) ∈ A

�

.

(4.14)

Proof: We apply Theorem 4.1 with the compact set

K = {q ∈ M(X) |

�

x∈X

q(x)f(x) ∈ A} .

(4.15)


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

LARGE DEVIATIONS FOR INDEPENDENT VARIABLES

71

0

0.2

0.4

0.6

0.8

1

0

0.5

1

1.5

2

2.5

3

3.5

4

4.5

5

5.5

6

I(h)

h

heq = 1

heq = 2

heq = 3

Fig. 4.2. Probability of an atypical average height for N particles with energy

function (4.7).

{fig:heightfluc}

This implies straightforwardly Eq. (4.13) with

I(ϕ) = min

�

D(q||p)

�����

�

x∈X

q(x)f(x) = ϕ

�

.

(4.16)

The minimum in the above equation can be found by Lagrange multipliers

method, yielding Eq. (4.14). □

Example 4.6 We look again at N particles in a gravitational ﬁeld, as in Ex-

ample 3, and consider the average height of the particles:

z = 1

N

N

�

i=1

zi .

(4.17)

The expected value of this quantity is E(z) = zeq = (eβ − 1)−1. The prob-

ability of a ﬂuctuation of z is easily computed using the above Corollary. For

z &gt; zeq, one gets P[z &gt; z] .= exp[−N I(z)], with

I(z) = (1 + z) log

�1 + zeq

1 + z

�

+ z log

� z

zeq

�

.

(4.18)

Analogously, for z &lt; zeq, P[z &lt; z] .= exp[−N I(z)], with the same rate function

I(z). The function I(z) is depicted in Fig. 4.2.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

72

PROBABILISTIC TOOLBOX

Exercise 4.2 One can construct a thermometer using the system of N par-

ticles with the energy function (4.7). Whenever the temperature is required,

you take a snapshot of the N particles, compute x and estimate the inverse

temperature βest using the formula (eβest −1)−1 = x. What is (for N ≫ 1) the

probability of getting a result βest ̸= β?

4.2.3

Asymptotic equipartition

{subsec:AEQ}

The above tools can also be used for counting the number of conﬁgurations

s = (s1, . . . , sN) with either a given type q(x) or a given empirical average of

some observable f. One ﬁnds for instance:

Proposition 4.7 The number NK,N of sequences s which have a type belonging

to the compact K ⊂ M(X) behaves as NK,N

.= exp{NH(q∗)}, where q∗ =

arg max{H(q) | q ∈ K}.

{prop:counting}

This result can be stated informally by saying that “there are approximately

eNH(q) sequences with type q”.

Proof:The idea is to apply Sanov’s theorem, taking the “reference” distribu-

tion p(x) to be the ﬂat probability distribution pﬂat(x) = 1/|X|. Using Eq. (4.6),

we get

NK,N = |X|NProbﬂat[q ∈ K] .= exp{N log |X|−ND(q∗||pﬂat)} = exp{NH(q∗)} .

(4.19)

□

We now get back to a generic sequence s = (s1, . . . , sN) ofN iid variables with

a probability distribution p(x). As a consequence of Sanov’s theorem, we know

that the most probable type is p(x) itself, and that deviations are exponentially

rare in N. We expect that almost all the probability is concentrated on sequences

having a type in some sense close to p(x). On the other hand, because of the

above proposition, the number of such sequences is exponentially smaller than

the total number of possible sequences |X|N.

These remarks can be made more precise by deﬁning what is meant by a

sequence having a type ‘close to p(x)’. Given the sequence s, we introduce the

quantity

r(s) ≡ − 1

N log PN(s) = − 1

N

N

�

i=1

log p(xi) .

(4.20)

Clearly, E r(s) = H(p). The sequence s is said to be ε-typical if and only if

|r(s) − H(p)| ≤ ε. Let TN,ε be the set of ε-typical sequences. It has the following

properties:

Theorem 4.8

(i) limN→∞ Prob[s ∈ TN,ε] = 1.

(ii) For N large enough, eN[H(p)−ε] ≤ |TN,ε| ≤ eN[H(p)+ε].

(iii) For any s ∈ TN,ε, e−N[H(p)+ε] ≤ PN(s) ≤ e−N[H(p)−ε].

Proof:Since r( s) is an empirical average, we can apply Corollary 4.5. This allows

to estimate the probability of not being typical as Prob[ s /∈ TN,ε] .= exp(−NI).


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

CORRELATED VARIABLES

73

The exponent is given by I = minq D(q||p), the minimum being taken over all

probability distributions q(x) such that

�� �

x∈X q(x) log[1/q(x)] − H(p)

�� ≥ ε.

But D(q||p) &gt; 0 unless q = p, and p does not belong to the of minimization.

Therefore I &gt; 0 and limN→∞ Prob[ s /∈ TN,ε] = 0, which proves (i).

The condition for q(x) to be the type of a ε-typical sequence can be rewritten

as |D(q||p) + H(q) − H(p)| ≤ ε. Therefore, for any ε-typical sequence, |H(q) − H(p)| ≤

ε and Proposition 4.7 leads to (ii). Finally, (iii) is a direct consequence of the

deﬁnition of ε-typical sequences. □

The behavior described in this proposition is usually denoted as asymptotic

equipartition property. Although we proved it for i.i.d. random variables, this

is not the only context in which it is expected to hold. In fact it will be found in

many interesting systems throughout the book.

4.3

Correlated variables

{sec:CorrelatedVariables}

In the case of independent random variables on ﬁnite spaces, the probability of

a large ﬂuctuation is easily computed by combinatorics. It would be nice to have

some general result for large deviations of non-independent random variables. In

this Section we want to describe the use of Legendre transforms and saddle point

methods to study the general case. As it often happens, this method corresponds

to a precise mathematical statement: the G¨artner-Ellis theorem. We ﬁrst describe

the approach informally and apply it to a few of examples. Then we will state

the theorem and discuss it.

4.3.1

Legendre transformation

To be concrete, we consider a set of random variables x = (x1, . . . , xN), with

xi ∈ X and an N dependent probability distribution

PN(x) = PN(x1, . . . , xN) .

(4.21)

Let f : X → R be a real valued function. We are interested in estimating, at

large N, the probability distribution of its empirical average

f(x) = 1

N

N

�

i=1

f(xi) .

(4.22)

In the previous Section, we studied the particular case in which the xi’s are

i.i.d. random variables. We proved that, quite generally, a ﬁnite ﬂuctuation of

f(x) is exponentially unlikely. It is natural to expect that the same statement

holds true if the xi’s are “weakly correlated”. Whenever PN(x) is the Gibbs-

Boltzmann distribution for some physical system, this expectation is supported

by physical intuition. We can think of the xi’s as the microscopic degrees of

freedom composing the system and of f(x) as a macroscopic observable (pressure,

magnetization, etc.). It is a common observation that the relative ﬂuctuations of

macroscopic observables are very small.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

74

PROBABILISTIC TOOLBOX

Let us thus assume that the distribution of f follows a large deviation

principle, meaning that the asymptotic behavior of the distribution at large N

is:

PN(f) .= exp[−NI(f)] ,

(4.23)

with a rate function I(f) ≥ 0.

In order to determine I(f), a useful method consists in “tilting” the measure

PN(·) in such a way that the rare events responsible for O(1) ﬂuctuations of f

become likely. In practice we deﬁne the (logarithmic) moment generating

function of f as follows

ψN(t) = 1

N log

�

E eNtf(x)�

,

t ∈ R .

(4.24)

When the property (4.23) holds, we can evaluate the large N limit of ψN(t) using

the saddle point method:

lim

N→∞ ψN(t) = lim

N→∞

1

N log

��

eNtf−NI(f)df

�

= ψ(t) ,

(4.25)

with

ψ(t) = sup

f∈R

�

tf − I(f)

�

.

(4.26)

ψ(t) is the Legendre transform of I(f), and it is a convex function of t by con-

struction (this is proved by diﬀerentiating twice Eq. (4.24)). It is therefore natural

to invert the Legendre transform (4.26) as follows:

Iψ(f) = sup

t∈R

�

tf − ψ(t)

�

,

(4.27)

and we expect Iψ(f) to coincide with the convex envelope of I(f). This procedure

is useful whenever computing ψ(t) is easier than directly estimate the probability

distribution PN(f).

4.3.2

Examples

It is useful to gain some insight by considering a few examples.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

CORRELATED VARIABLES

75

Example 4.9 Consider the one-dimensional Ising model, without external

magnetic ﬁeld, cf. Sec. 2.5.1. To be precise we have xi = σi ∈ {+1, −1}, and

PN(σ) = exp[−βE(σ)]/Z the Boltzmann distribution with energy function

E(σ) = −

N−1

�

i=1

σiσi+1 .

(4.28)

We want to compute the large deviation properties of the magnetization

m(σ) = 1

N

N

�

i=1

σi .

(4.29)

We know from Sec. 2.5.1, and from the symmetry of the energy function under

spin reversal (σi → −σi) that ⟨m(σ)⟩ = 0. In order to compute the probability

of a large ﬂuctuation of m, we apply the method described above. A little

thought shows that ψ(t) = φ(β, t/β) − φ(β, 0) where φ(β, B) is the free energy

density of the model in an external magnetic ﬁeld B, found in (2.63). We thus

get

ψ(t) = log

�

cosh t +

�

sinh2 t + e−4β

1 + e−2β

�

.

(4.30)

One sees that ψ(t) is convex and analytic for any β &lt; ∞. We can apply

Eq. (4.27) in order to obtain the rate function Iψ(m). In Fig. 4.3 we report

the resulting function for several temperatures β. Notice that Iψ(m) is analytic

and has strictly positive second derivative for any m and β &lt; ∞, so that we

expect I(m) = Iψ(m). This expectation is conﬁrmed by Theorem 4.12 below.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

76

PROBABILISTIC TOOLBOX

0

0.05

0.1

0.15

0.2

0.25

0.3

-1

-0.8 -0.6 -0.4 -0.2

0

0.2

0.4

0.6

0.8

1

I(m)

m

β = 0.25

β = 0.5

β = 1

β = 2

Fig. 4.3. Rate function for the magnetization of the one-dimensional Ising

model. Notice that, as the temperature is lowered (β increased) the probabil-

ity of large ﬂuctuations increases.

{fig:largedev1dIsing}

Example 4.10 Consider a Markov chain X0, X1, . . . , Xi, . . . taking values in

a ﬁnite state space X, as in the Example 2 of Sec. 1.3, and assume all the

elements of the transition matrix w(x → y) to be strictly positive. Let us study

the large deviation properties of the empirical average

1

N

�

i f(Xi).

One can show that the limit moment generating function ψ(t), cf. Eq. (4.24)

exists, and can be computed using the following recipe. Deﬁne the ‘tilted’ tran-

sition probabilities as wt(x → y) = w(x → y) exp[t f(y)]. Let λ(t) be the largest

solution of the eigenvalue problem

�

x∈X

φl

t(x) wt(x → y) = λ(t) φl

t(y) .

(4.31)

The moment generating function is simply given by ψ(t) = log λ(t) (which is

unique and positive because of Perron-Frobenius theorem).

Notice that Eq. (4.31) resembles the stationarity condition for a Markov

chain with transition probabilities wt(x → y). Unhappily the rates wt(x → y)

are not properly normalized (�

y wt(x → y) ̸= 1). This point can be overcome

as follows. Call φr

t(x) the right eigenvector of wt(x → y) with eigenvalue λ(t)

and deﬁne:

wt(x → y) ≡

1

λ(t)φr

t(x) wt(x → y) φr

t(y) .

(4.32)

We leave to the reader the exercise of showing that: (i) These rates are prop-

erly normalized; (ii) Eq. (4.31) is indeed the stationarity condition for the

distribution pt(x) ∝ φl

t(x)φr

t(x) with respect to the rates wt(x → y).


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

CORRELATED VARIABLES

77

Example 4.11 Consider now the Curie-Weiss model without external ﬁeld,

cf. Sec. 2.5.2. As in Example 1, we take xi = σi ∈ {+1, −1} and PN(σ) =

exp[−βE(σ)]/Z, and we are interested in the large ﬂuctuations of the global

magnetization (4.29). The energy function is

E(σ) = − 1

N

�

(ij)

σiσj .

(4.33)

By repeating the arguments of Sec. 2.5.2, it is easy to show that, for any

−1 ≤ m1 &lt; m2 ≤ 1:

PN{m(σ) ∈ [m1, m2]} .=

1

ZN(β)

� m2

m1

dm eNφmf(m;β) ,

(4.34)

where φmf(m; β) = β

2 m2 −log[2 cosh(βm)]. The large deviation property (4.23)

holds, with:

I(m) = φmf(m∗; β) − φmf(m; β) .

(4.35)

and m∗(β) is the largest solution of the Curie Weiss equation m = tanh(βm).

The function I(m) is represented in Fig. 4.4, left frame, for several values of

the inverse temperature β. For β &lt; βc = 1, I(m) is convex and has its unique

minimum in m = 0.

A new and interesting situation appears when β &gt; βc. The function I(m)

is non convex, with two degenerate minima at m = ±m∗(β). In words, the

system can be found in either of two well-distinguished ‘states’: the positive

and negative magnetization states. There is no longer a unique typical value

of the magnetization such that large ﬂuctuations away from this value are

exponentially rare.

Let us now look at what happens if the generating function approach is

adopted. It is easy to realize that the limit (4.24) exists and is given by

ψ(t) =

sup

m∈[−1,1]

[mt − I(m)] .

(4.36)

While at high temperature β &lt; 1, ψ(t) is convex and analytic, for β &gt; 1 it devel-

ops a singularity at t = 0. In particular one has ψ′(0+) = m∗(β) = −ψ′(0−).

Compute now Iψ(m) using Eq. (4.27). A little thought shows that, for any

m ∈ [−m∗(β), m∗(β)] the supremum is achieved for t = 0, which yields

Iψ(m) = 0. Outside this interval, the supremum is achieved at the unique

solution of ψ′(t) = m, and Iψ(m). As anticipated, Iψ(m) is the convex enve-

lope of I(m). In the range (−m∗(β), m∗(β)), an estimate of the magnetization

ﬂuctuations through the function .= exp(−NIψ(m)) would overestimate the

ﬂuctuations.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

78

PROBABILISTIC TOOLBOX

4.3.3

The G¨artner-Ellis theorem

The G¨artner-Ellis theorem has several formulations which usually require some

technical deﬁnitions beforehand. Here we shall state it in a simpliﬁed (and some-

what weakened) form. We need only the deﬁnition of an exposed point: x ∈ R

is an exposed point of the function F : R → R if there exists t ∈ R such that

ty − F(y) &gt; tx − F(x) for any y ̸= x. If, for instance, F is convex, a suﬃcient

condition for x to be an exposed point is that F is twice diﬀerentiable at x with

F ′′(x) &gt; 0.

{thm:GE}

Theorem 4.12. (G¨artner-Ellis) Consider a function f(x) (not necessarily of

the form (4.22)) and assume that the moment generating function ψN(t) deﬁned

in (4.24) exists and has a ﬁnite limit ψ(t) = limN→∞ ψN(t) for any t ∈ R.

Deﬁne Iψ(·) as the inverse Legendre transform of Eq. (4.27) and let E be the set

of exposed points of Iψ(·).

1. For any closed set F ∈ R:

lim sup

N→∞

1

N log PN(f ∈ F) ≤ − inf

f∈F Iψ(f) .

(4.37)

2. For any open set G ∈ R:

lim sup

N→∞

1

N log PN(f ∈ G) ≥ −

inf

f∈G∩E Iψ(f) .

(4.38)

3. If moreover ψ(t) is diﬀerentiable for any t ∈ R, then the last statement

holds true with the inf being taken over the whole set G (rather than over

G ∩ E).

Informally, the inverse Legendre transform (4.27) generically yields an upper

bound on the probability of a large ﬂuctuation of the macroscopic observable.

This upper bound is tight unless a ‘ﬁrst order phase transition’ occurs, corre-

sponding to a discontinuity in the ﬁrst derivative of ψ(t).

It is worth mentioning that ψ(t) can be non-analytic at a point t∗ while its

ﬁrst derivative is continuous at t∗. This correspondsm in the statistical mechanics

jargon, to a ‘higher order’ phase transition. As we shall see in the following

Chapters, such phenomena have interesting probabilistic interpretations too.

4.3.4

Typical sequences

Let us get back to the concept of typical sequences, introduced in Section 4.2.

More precisely, we want to investigate the large deviation of the probability itself,

measured by r(x) = − 1

N log P(x). For independent random variables, the study

of sect. 4.2.3 led to the concept of ε-typical sequences. What can one say about

general sequences?

Let us compute the corresponding moment generating function (4.24):

ψN(t) = 1

N log







�

x

PN(x)1−t





 .

(4.39)


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

GIBBS FREE ENERGY

79

Without loss of generality, we can assume PN(x) to have the Boltzmann form:

PN(x) =

1

ZN(β) exp{−βEN(x)} ,

(4.40)

with energy function EN(x). Inserting this into Eq. (4.39), we get

ψN(t) = βfN(β) − βfN(β(1 − t)) ,

(4.41)

where fN(β) = −(1/N) log ZN(β) is the free energy density of the system with

energy function EN(x) at inverse temperature β. Let us assume that the ther-

modynamic limit f(β) = limN→∞ fN(β) exists and is ﬁnite. It follows that the

limiting generating function ψ(t) exists and we can apply the G¨artner-Ellis the-

orem to compute the probability of a large ﬂuctuation of r(x). As long as f(β)

is analytic, large ﬂuctuations are exponentially depressed and the asymptotic

equipartition property of independent random variables is essentially recovered.

On the other hand, if there is a phase transition at β = βc, where the ﬁrst

derivative of f(β) is discontinuous, then the likelihood r(x) may take several

distinct values with a non-vanishing probability. This is what happened with the

magnetization in Example 3 above.

4.4

Gibbs free energy

{sec:Gibbs}

In the introduction to statistical physics of chapter 2, we assumed that the

probability distribution of the conﬁgurations of a physical system is Boltzmann’s

distribution. It turns out that this distribution can be obtained from a variational

principle. This is interesting, both as a matter of principle and in order to ﬁnd

approximation schemes.

Consider a system with a conﬁguration space X, and a real valued energy

function E(x) deﬁned on this space. The Boltzmann distribution is Pβ(x) =

exp[−β(E(x)−F(β))], where F(β), the ‘free energy’, is a function of the inverse

temperature β deﬁned by the fact that �

x∈X Pβ(x) = 1. Let us deﬁne the

Gibbs free energy G[P] (not to be confused with F(β)), which is a real valued

functional over the space of probability distributions P(x) on X:

G[P] =

�

x∈X

P(x)E(x) + 1

β

�

x∈X

P(x) log P(x) .

(4.42)

It is easy to rewrite the Gibbs free energy in terms of the KL divergence between

P(x) and the Boltzmann distribution Pβ(x):

G[P] = 1

β D(P||Pβ) + F(β) ,

(4.43)

This representation implies straightforwardly the following proposition (Gibbs

variational principle):


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

80

PROBABILISTIC TOOLBOX

Proposition 4.13 The Gibbs free energy G[P] is a convex functional of P(x),

and it achieves its unique minimum on the Boltzmann distribution P(x) = Pβ(x).

Moreover G[Pβ] = F(β), where F(β) is the free energy.

When the partition function of a system cannot be computed exactly, the above

result suggests a general line of approach for estimating the free energy: one can

minimize the Gibbs free energy in some restricted subspace of “trial probability

distributions” P(x). These trial distributions should be simple enough that G[P]

can be computed, but the restricted subspace should also contain distributions

which are able to give a good approximation to the true behavior of the physical

system. For each new physical system one will thus need to ﬁnd a good restricted

subspace.

Example 4.14 Consider a system with space of conﬁgurations X = R and

energy:

E(x) = 1

2t x2 + 1

4x4 ,

(4.44)

with t ∈ R. We ask the question of computing its free energy at temperature

β = 1 as a function of t. With a slight abuse of notation, we are interested in

F(t) = − log

��

dx e−E(x)

�

.

(4.45)

The above integral cannot be computed in closed form and so we recur to the

Gibbs variational principle. We consider the following family of trial probability

distributions:

Qa(x) =

1

√

2πa e−x2/2a .

(4.46)

It is easy to compute the corresponding Gibbs free energy for β = 1:

G[Qa] = 1

2 ta + 3

4a2 − 1

2 (1 + log 2πa) ≡ G(a, t) .

(4.47)

The Gibbs principle implies that F(t) ≤ mina G(a, t). In Fig. 4.5 we plot the

optimal value of a, aopt(t) = arg mina G(a, t) and the corresponding estimate

Gopt(t) = G(aopt(t), t).


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

GIBBS FREE ENERGY

81

0

0.05

0.1

0.15

0.2

-1

-0.8 -0.6 -0.4 -0.2

0

0.2

0.4

0.6

0.8

1

I(m)

m

β = 0.50

β = 1.00

β = 1.25

β = 1.50

0

0.05

0.1

0.15

0.2

-0.3

-0.2

-0.1

0

0.1

0.2

0.3

ψ(t)

t

β = 0.50

β = 1.00

β = 1.25

β = 1.50

Fig. 4.4. The rate function for large ﬂuctuations of the magnetization in the

Curie-Weiss model (left) and the corresponding generating function (right).

{fig:largedevCW}

Example 4.15 Consider the same problem as above and the family of trials

distributions:

Qa(x) =

1

√

2π e−(x−a)2/2 .

(4.48)

We leave as an exercise for the reader the determination of the optimal value

of aopt, and the corresponding upper bound on F(t), cf. Fig. 4.5. Notice the

peculiar phenomenon going on at tcr = −3. For t &gt; tcr, we have aopt(t) = 0,

while G[Qa] has two degenerate local minima a = ±aopt(t) for t ≤ tcr.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

82

PROBABILISTIC TOOLBOX

Example 4.16 Consider the Ising model on a d-dimensional lattice L of linear

size L (i.e. L = [L]d), cf. Sec. 2.5. The energy function is (notice the change of

normalization with respect to Sec. 2.5)

E(σ) = −

�

(ij)

σiσj − B

�

i∈L

σi .

(4.49)

For the sake of simplicity we assume periodic boundary conditions.

This means that two sites i = (i1, . . . , id) and j = (j1, . . . , jd) are considered

nearest neighbors if, for some l ∈ {1, . . . , d}, il−jl = ±1 ( mod L) and il′ = jl′

for any l′ ̸= l. The sum over (ij) in Eq. (4.49) runs over all nearest neighbors

pairs in L.

In order to obtain a variational estimate of the free energy F(β) at in-

verse temperature β, we evaluate the Gibbs free energy on the following trial

distribution:

Qm(σ) =

�

i∈L

qm(σi) ,

(4.50)

with qm(+) = (1 + m)/2 and qm(−) = (1 − m)/2 and m ∈ [−1, +1]. Notice

that, under Qm(σ), the σi’s are i.i.d. random variables with expectation m.

It is easy to evaluate the Gibbs free energy on this distribution. If we deﬁne

the per-site Gibbs free energy g(m; β, B) ≡ G[Qm]/Ld, we get

g(m; β, B) = −1

2 m2 − B m + 1

β H((1 + m)/2) .

(4.51)

Gibbs variational principle implies an upper bound on the free energy density

f(β) ≤ infm g(m; β, h). Notice that, apart from an additive constant, this ex-

pression (4.51) has the same form as the solution of the Curie-Weiss model, cf.

Eq. (2.79). We refer therefore to Sec. 2.5.2 for a discussion of the optimization

over m. This implies the following inequality:

fd(β, h) ≤ fCW(β, h) − 1

2 .

(4.52)

The relation between Gibbs free energy and Kullback-Leibler divergence in

Eq. (4.43) implies a simple probabilistic interpretation of Gibbs variational prin-

ciple. Imagine to prepare a large number N of copies of the same physical system.

Each copy is described by the same energy function E(x). Now consider the em-

pirical distribution P(x) of the N copies. Typically P(x) will be close to the

Bolzmann distribution Pβ(x). Sanov’s theorem implies that the probability of

an ‘atypical’ distribution is exponentially small in N:

P[P] .= exp[−N(G[P] − F(β))] .

(4.53)


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

THE MONTE CARLO METHOD

83

An illustration of this remark is provided by Exercise 4 of Sec. 4.2.

4.5

The Monte Carlo method

{sec:MonteCarlo}

The Monte Carlo method is an important generic tool which is common to

probability theory, statistical physics and combinatorial optimization. In all of

these ﬁelds, we are often confronted with the problem of sampling a conﬁguration

x ∈ X N (here we assume X to be a ﬁnite space) from a given distribution

P(x). This can be quite diﬃcult when N is large, because there are too many

conﬁgurations, because the typical conﬁgurations are exponentially rare and/or

because the distribution P(x) is speciﬁed by the Boltzmann formula with an

unknown normalization (the partition function).

A general approach consists in constructing a Markov chain which is guaran-

teed to converge to the desired P(x) and then simulating it on a computer. The

computer is of course assumed to have access to some source of randomness: in

practice pseudo-random number generators are used. If the chain is simulated

for a long enough time, the ﬁnal conﬁguration has a distribution ‘close’ to P(x).

In practice, the Markov chain is deﬁned by a set of transition rates w(x → y)

with x, y ∈ X N which satisfy the following conditions.

1. The chain is irreducible, i.e. for any couple of conﬁgurations x and y,

there exists a path (x0, x1, . . . xn) of length n, connecting x to y with non-

zero probability. This means that x0 = x, xn = y and w(xi → xi+1) &gt; 0

for i = 0 . . . n − 1.

2. The chain is aperiodic: for any couple x and y, there exists a positive

integer n(x, y) such that, for any n ≥ n(x, y) there exists a path of length

n connecting x to y with non-zero probability. Notice that, for an irre-

ducible chain, aperiodicity is easily enforced by allowing the conﬁguration

to remain unchanged with non-zero probability: w(x → x) &gt; 0.

3. The distribution P(x) is stationary with respect to the probabilities

w(x → y):

�

x

P(x) w(x → y) = P(y) .

(4.54)

Sometimes a stronger condition (implying stationarity) is satisﬁed by the

transition probabilities. For each couple of conﬁgurations x, y such that

either w(x → y) &gt; 0 or w(y → x) &gt; 0, one has

P(x) w(x → y) = P(y) w(y → x) .

(4.55)

This condition is referred to as reversibility or detailed balance.

The strategy of designing and simulating such a process in order to sample

from P(x) goes under the name of dynamic Monte Carlo method or Monte

Carlo Markov chain method (hereafter we shall refer to it simply as Monte

Carlo method). The theoretical basis for such an approach is provided by two

classic theorems which we collect below.


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

84

PROBABILISTIC TOOLBOX

{thm:AsymptoticMarkov}

Theorem 4.17 Assume the rates w(x → y) to satisfy the hypotheses 1-3 above.

Let X0, X1, . . . , Xt, . . . be random variables distributed according to the Markov

chain with rates w(x → y) and initial condition X0 = x0. Let f : X N → R be

any real valued function. Then

1. The probability distribution of Xt converges to the stationary one:

lim

t→∞ P[Xt = x] = P(x) .

(4.56)

2. Time averages converge to averages over the stationary distribution

lim

t→∞

1

t

t

�

s=1

f(Xs) =

�

x

P(x)f(x)

almost surely.

(4.57)

The proof of this Theorem can be found in any textbook on Markov processes.

Here we will illustrate it by considering two simple Monte Carlo algorithms which

are frequently used in statistical mechanics (although they are by no means the

most eﬃcient ones).


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

THE MONTE CARLO METHOD

85

Example 4.18 Consider a system of N Ising spins σ = (σ1 . . . σN) with en-

ergy function E(σ) and inverse temperature β. We are interested in sampling

the Boltzmann distribution Pβ. The Metropolis algorithm with random up-

datings is deﬁned as follows. Call σ(i) the conﬁguration which coincides with

σ but for the site i (σ(i)

i

= −σi), and let ∆Ei(σ) ≡ E(σ(i)) − E(σ). At each

step, an integer i ∈ [N] is chosen randomly with ﬂat probability distribution

and the spin σi is ﬂipped with probability

wi(σ) = exp{−β max[∆Ei(σ), 0]} .

(4.58)

In formulae, the transition probabilities are given by

w(σ → τ) = 1

N

N

�

i=1

wi(σ) δ(τ, σ(i)) +

�

1 − 1

N

N

�

i=1

wi(σ)

�

δ(τ, σ) , (4.59)

where δ(σ, τ) = 1 if σ ≡ τ, and = 0 otherwise. It is easy to check that this

deﬁnition satisﬁes both the irreducibility and the stationarity conditions for

any energy function E(σ) and inverse temperature β &lt; 1. Furthermore, the

chain satisﬁes the detailed balance condition:

Pβ(σ) wi(σ) = Pβ(σ(i)) wi(σ(i)) .

(4.60)

Whether the condition of aperiodicity is fulﬁlled depends on the energy. It is

easy to construct systems for which it does not hold. Take for instance a single

spin, N = 1, and let E(σ) = 0: the spin is ﬂipped at each step and there is no

way to have a transition from σ = +1 to σ = −1 in an even number of steps.

(But this kind of pathology is easily cured modifying the algorithm as follows.

At each step, with probability 1−ε a site i is chosen and a spin ﬂip is proposed

as above. With probability ε nothing is done, i.e. a null transition σ → σ is

realized.)

Exercise 4.3 Variants of this chain can be obtained by changing the ﬂipping

probabilities (4.58). A popular choice consists in the heath bath algorithm

(also referred to as Glauber dynamics):

wi(σ) = 1

2

�

1 − tanh

�β∆Ei(σ)

2

��

.

(4.61)

Prove irreducibility, aperiodicity and stationarity for these transition probabil-

ities.

One of the reason of interest of the heath bath algorithm is that it can be

easily generalized to any system whose conﬁguration space has the form X N. In

this algorithm one chooses a variable index i, ﬁxes all the others variables, and


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

86

PROBABILISTIC TOOLBOX

assign a new value to the i-th one according to its conditional distribution. A

more precise description is provided by the following pseudocode. Recall that,

given a vector x ∈ X N, we denote by x∼i, the N −1-dimensional vector obtained

by removing the i-th component of x.

Heat bath algorithm()

Input: A probability distribution P(x) on the configuration space X N,

and the number r of iterations.

Output: a sequence x(0), x(1), . . . , x(r)

1. Generate x(0) uniformly at random in X N.

2. For t = 1 to t = r:

2.1 Draw a uniformly random integer i ∈ {1, . . . , N}

2.2 For each z ∈ X, compute

P(Xi = z|X∼i = x(t−1)

∼i

y) =

P(Xi = z, X∼i = x(t−1)

∼i

)

P

z′∈X P(Xi = z′, X∼i = x(t−1)

∼i

)

.

(4.62)

2.3 Set x(t)

j

= x(t−1)

j

for each j ̸= i, and x(t)

i

= z where z is drawn

from the distribution P(Xi = z|X∼i = x(t−1)

∼i

y).

Let us stress that this algorithm does only require to compute the probability

P(x) up to a multiplicative constant. If, for instance, P(x) is given by Boltz-

mann law, cf. Sec. 2.1, it is enough to be able to compute the energy E(x) of

a conﬁguration, and is instead not necessary to compute the partition function

Z(β).

This is a very general method for deﬁning a Markov chain with the desired

property. The proof is left as exercise.

Exercise 4.4 Assuming for simplicity that ∀x, P(x) &gt; 0, prove irreducibility,

aperiodicity and stationarity for the heat bath algorithm.

Theorem 4.17 conﬁrms that the Monte Carlo method is indeed a viable

approach for sampling from a given probability distribution. However, it does

not provide any information concerning its computational eﬃciency. In order to

discuss such an issue, it is convenient to assume that simulating a single step

Xt → Xt+1 of the Markov chain has a unitary time-cost. This assumption is a

good one as long as sampling a new conﬁguration requires a ﬁnite (ﬁxed) number

of computations and updating a ﬁnite (and N-independent) number of variables.

This is the case in the two examples provided above, and we shall stick here to

this simple scenario.

Computational eﬃciency reduces therefore to the question: how many step

of the Markov chain should be simulated? Of course there is no unique answer

to such a generic question. We shall limit ourselves to introduce two important

ﬁgures of merit. The ﬁrst concerns the following problem: how many steps should

be simulated in order to produce a single conﬁguration x which is distributed


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

THE MONTE CARLO METHOD

87

approximately according to P(x)? In order to precise what is meant by “approx-

imately” we have to introduce a notion distance among distributions P1(·) and

P2(·) on X N. A widespread deﬁnition is given by the variation distance:

||P1 − P2|| = 1

2

�

x∈X N

|P1(x) − P2(x)| .

(4.63)

Consider now a Markov chain satisfying the hypotheses 1-3 above with respect to

a stationary distribution P(x) and call Pt(x|x0) the distribution of Xt conditional

to the initial condition X0 = x0. Let dx0(t) = ||Pt(·|x0) − P(·)|| be the distance

from the stationary distribution. The mixing time (or variation threshold

time) is deﬁned as

τeq(ε) = min{t &gt; 0 : sup

x0

dx0(t) ≤ ε} .

(4.64)

In this book we shall often refer informally to this quantity (or to some close

relative) as the equilibration time. The number ε can be chosen arbitrarily, a

change in ε implying usually a simple multiplicative change in in τeq(ε). Because

of this reason the convention ε = 1/e is sometimes adopted.

Rather than producing a single conﬁguration with the prescribed distribution,

one is often interested in computing the expectation value of some observable

O(x). In principle this can be done by averaging over many steps of the Markov

chain as suggested by Eq. (4.57). It is therefore natural to pose the following

question. Assume the initial condition X0 is distributed according to the sta-

tionary distribution P(x). This can be obtained by simulating τeq(ε) steps of the

chain in a preliminary (equilibration) phase. We shall denote by ⟨·⟩ the expec-

tation with respect to the Markov chain with this initial condition. How many

steps should we average over in order to get expectation values within some

prescribed accuracy? In other words, we estimate � P(x)O(x) ≡ EP O by

OT ≡ 1

T

T −1

�

t=0

O(Xt) .

(4.65)

It is clear that ⟨OT ⟩ = � P(x)O(x). Let us compute the variance of this esti-

mator:

Var(OT ) = 1

T 2

T −1

�

s,t=0

⟨Os; Ot⟩ = 1

T 2

T −1

�

t=0

(T − t)⟨O0; Ot⟩ ,

(4.66)

where we used the notation Ot ≡ O(Xt). Let us introduce the autocorrelation

function CO(t − s) ≡ ⟨Os;Ot⟩

⟨O0;O0⟩, so that Var(OT ) = ⟨O0;O0⟩

T 2

�T −1

t=0 (T − t) CO(t).

General results on Markov chain on ﬁnite state spaces imply that CO(t) decreases

exponentially as t → ∞. Therefore, for large T, we have


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

88

PROBABILISTIC TOOLBOX

-10

-8

-6

-4

-2

0

2

-6

-5

-4

-3

-2

-1

0

1

2

t

F(t)

G(t)

a(t)

-10

-8

-6

-4

-2

0

2

-6

-5

-4

-3

-2

-1

0

1

2

t

F(t)

G(t)

a(t)

Fig. 4.5. Variational estimates of the free energy of the model (4.44). We use

the trial distributions (4.46) on the left and (4.48) on the right.

{fig:variational_anh}

Var(OT ) = τ O

int

T

[EP O2 − (EP O)2] + O(T −2) .

(4.67)

The integrated autocorrelation time τ O

int is given by

τ O

int ≡

∞

�

t=0

CO(t) ,

(4.68)

and provides a reference for estimating how long the Monte Carlo simulation

should be run in order to get some prescribed accuracy. Equation (4.67) can

be interpreted by saying that one statistically independent estimate of EP O is

obtained every τ O

int iterations.

Example 4.19 Consider the Curie-Weiss model, cf. Sec. 2.5.2, at inverse tem-

perature β, and use the heath-bath algorithm of Example 2 in order to sample

from the Boltzmann distribution. In Fig. ?? we reproduce the evolution of the

global magnetization m(σ) during three diﬀerent simulations at inverse temper-

atures β = 0.8, 1.0, 1.2 for a model of N = 150 spin. In all cases we initialized

the Markov chain by extracting a random conﬁguration with ﬂat probability.

A spectacular eﬀect occurs at the lowest temperature, β = 1.2. Although

the Boltzmann average of the global magnetization vanishes, ⟨m(σ)⟩ = 0, the

sign of the magnetization remains unchanged over extremely long time scales.

It is clear that the equilibration time is at least as large as these scales. An

order-of-magnitude estimate would be τeq &gt; 105. Furthermore this equilibra-

tion time diverges exponentially at large N. Sampling from the Boltzmann

distribution using the present algorithm becomes exceedingly diﬃcult at low

temperature.

4.6

Simulated annealing

{sec:SimulAnn}

As we mentioned in Sec. 3.5, any optimization problem can be ‘embedded’ in a

statistical mechanics problem. The idea is to interpret the cost function E(x), x ∈


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

SIMULATED ANNEALING

89

X N as the energy of a statistical mechanics system and consider the Boltzmann

distribution pβ(x) = exp[−βE(x)]/Z. In the low temperature limit β → ∞, the

distribution concentrates over the minima of E(x), and the original optimization

setting is recovered.

Since the Monte Carlo method provides a general technique for sampling

from the Boltzmann distribution, one may wonder whether it can be used, in

the β → ∞ limit, as an optimization technique. A simple minded approach would

be to take β = ∞ at the outset. Such a straegy is generally referred to as quench

in statistical physics and greedy search in combinatorial optimization, and is

often bound to fail. Consider in fact the stationarity condition (4.54) and rewrite

it using the Boltzmann formula

�

x

e−β [E(x)−E(y)] w(x → y) = 1 .

(4.69)

Since all the terms on the left hand side are positive, any of them cannot be larger

than one. This implies 0 ≤ w(x → y) ≤ exp{−β [E(y) − E(x)]}. Therefore, for

any couple of conﬁgurations x, y, such that E(y) &gt; E(x) we have w(x → y) → 0

in the β → ∞ limit. In other words, the energy is always non-increasing along

the trajectories of a zero-temperature Monte Carlo algorithm. As a consequence,

the corresponding Markov chain is not irreducible, although it is irreducible at

any β &lt; ∞, and is not guaranteed to converge to the equilibrium distribution,

i.e. to ﬁnd a global minimum of E(x).

Another simple minded approach would be to set β to some large but ﬁnite

value. Although the Boltzmann distribution gives some weight to near-optimal

conﬁgurations, the algorithm will visit, from time to time, also optimal conﬁg-

uratons which are the most probable one. How large should be β? How much

time shall we wait before an optimal conﬁguration is visited? We can assume

without loss of generality that the minimum of the cost function (the ground

state energy) is zero: E0 = 0. A meaningful quantity to look at is the probability

for E(x) = 0 under the Boltzmann distribution at inverse temperature β. We

can easily compute the logarithmic moment generating function of the energy:

ψN(t) = 1

N log



�

x

pβ(x) etE(x)



 = 1

N log

��

x e−(β−t)E(x)

�

x e−βE(x)

�

.

(4.70)

This is given by ψN(t) = φN(β − t) − φN(β), where φN(β) is the free entropy

density at inverse temperature β. Clearly pβ[E(x) = 0] = exp[NψN(−∞)] =

exp{N[φN(∞)−φN(β)]}, and the average time to wait before visiting the optimal

conﬁguration is 1/pβ[E(x) = 0] = exp[−NψN(−∞)].


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

90

PROBABILISTIC TOOLBOX

Exercise 4.5 Assume that the cost function takes integer values E

=

0, 1, 2 . . . and call XE the set of coﬁgurations x such that E(x) = E. You

want the Monte Carlo trajectories to spend a fraction (1 − ε) of the time on

optimal solutions. Show that the temperature must be chosen such that

β = log

� |X1|

ε|X0|

�

+ Θ(ε) .

(4.71)

In Section 2.4 we argued that, for many statistical mechanics models, the free

entropy density has a ﬁnite thermodynamic limit φ(β) = limN→∞ φN(β). In the

following Chapters we will show that this is the case also for several interesting

optimization problems. This implies that pβ[E(x) = 0] vanishes in the N → ∞

limit. In order to have a non-negligibile probability of hitting a solution of the

optimization problem, β must be scaled with N in such a waythat β → ∞ as

N → ∞. On the other hand, letting β → ∞ we are going to face the reducibility

problem mentioned above. Althouch the Markov chain is formally irreducible,

its equilibration time will diverge as β → ∞.

The idea of simulated annealing consists in letting β vary with time. More

precisely one decides an annealing schedule {(β1, n1); (β2, n2); . . . (βL, nL)},

with inverse temperatures βi ∈ [0, ∞] and integers ni &gt; 0. The algorithm is ini-

tialized on a conﬁgutation x0 and executes n1 Monte Carlo steps at temperature

β1, n2 at temperature β2, . . . , nL at temperature βL. The ﬁnal conﬁguration of

each cycle i (with i = 1, . . . , L − 1) is used as initial conﬁguration of the next

cycle. Mathematically, such a process is a time-dependent Markov chain.

The common wisdom about the simulated annealing algorithm is that varying

the temperature with time should help avoiding the two problems encountered

above. Usually one takes the βi’s to be an increasing sequence. In the ﬁrst stages

a small β should help equilibrating across the space of conﬁgurations X N. As the

themperature is lowered the probability distribution concentrates on the lowest

energy regions of this space. Finally, in the late stages, a large β forces the sys-

tem to ﬁx the few wrong details, and to ﬁnd solution. Of course, this image is

very simplistic. In the following Chapter we shall try to reﬁne it by considering

the application of simulated annealing to a variety of problems.

4.7

Appendix: A physicist’s approach to Sanov’s theorem

{app_sanov_ft}

Let us show how the formulas of Sanov’s theorem can be obtained using the type

of ‘ﬁeld theoretic’ approach used in statistical physics. The theorem is easy to

prove, the aim of this section is not so much to give a proof, but rather to show

on a simple example a type of approach that is very common in physics, and

which can be powerful. We shall not aim at a rigorous derivation.

The probability that the type of the sequence x1, · · · , xN be equal to q(x)

can be written as:


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

APPENDIX: A PHYSICIST’S APPROACH TO SANOV’S THEOREM

91

P[q(x)] = E

� �

x∈X

I

�

q(x) = 1

N

N

�

i=1

δx,xi

��

=

�

x1···xN

p(x1) · · · p(xN) I

�

q(x) = 1

N

N

�

i=1

δx,xi

�

.

(4.72)

A typical approach in ﬁeld theory is to introduce some auxiliary variables in

order to enforce the constraint that q(x) =

1

N

�N

i=1 δx,xi. For each x ∈ X, one

introduces a variable λ(x), and uses the ‘integral representation’ of the constraint

in the form:

I

�

q(x) = 1

N

N

�

i=1

δx,xi

�

=

� 2π

0

dλ(x)

2π

exp

�

iλ(x)

�

Nq(x) −

N

�

i=1

δx,xi

��

.

(4.73)

Dropping q-independent factors, we get:

P[q(x)] = C

�

�

x∈X

dλ(x) exp{NS[λ]} ,

where C is a normalization constant, and the action S is given by:

S[λ] = i

�

x

λ(x)q(x) + log

��

x

p(x)e−iλ(x)

�

(4.74)

In the large N limit, the integral in (4.74) can be evaluated with a saddle point

method. The saddle point λ(x) = λ∗(x) is found by solving the stationarity

equations ∂S/∂λ(x) = 0 for any x ∈ X. One gets a family of solutions −iλ(x) =

C +log(q(x)/p(x)) with C arbitrary. The freedom in the choice of C comes from

the fact that �

x(�

i δx,xi) = N for any conﬁguration x1 . . . xN, and therefore

one of the constraints is in fact useless. This freedom can be ﬁxed arbitrarily:

regardless of this choice, the action on the saddle point is

S[λ∗] = S0 −

�

x

q(x) log q(x)

p(x) ,

(4.75)

where S0 is a q independent constant. One thus gets P[q(x)] .= exp[−ND(q||p)].

The reader who has never encountered this type of reasoning may wonder why

use such an indirect approach. It turns out that it is a very common formalism

in statistical physics, where similar methods are also applied, under the name

‘ﬁeld theory’, to continuous X spaces (some implicit discretization is then usually

assumed at intermediate steps, and the correct deﬁnition of a continuum limit is

often not obvious). In particular the reader interested in the statistical physics

approach to optimizations problems or information theory will often ﬁnd this

type of formalism in research papers. One of the advantages of this approach is


‘‘Info Phys Comp’’ Draft: November 9, 2007  --  ‘‘Info Phys 

92

PROBABILISTIC TOOLBOX

that it provides a formal solution to a large variety of problems. The quantity to

be computed is expressed in an integral form as in (4.74). In problems having a

‘mean ﬁeld’ structure, the dimension of the space over which the integration is

performed does not depend upon N. Therefore its leading exponential behavior

at large N can be obtained by saddle point methods. The reader who wants

to get some practice of this approach is invited to ‘derive’ in the same way the

various theorems and corollaries of this chapter.

Notes

The theory of large deviations is exposed in the book of Dembo and Zeitouni

(Dembo and Zeitouni, 1998), and its use in statistical physics can be found in

Ellis’s book (Ellis, 1985).

Markov chains on discrete state spaces are treated by Norris (Norris, 1997)

A nice introduction to Monte Carlo methods in statistical physics is given in the

lecture notes by Krauth (Krauth, 1998) and by Sokal (Sokal, 1996).

Simulated annealing was introduced by Kirkpatrick, Gelatt and Vecchi 1983

(Kirkpatrick, C. D. Gelatt and Vecchi, 1983). It is a completely “universal”

optimization algorithm: it can be deﬁned without reference to any particular

problem. Beacause of this reason it ofteen overlooks important structures that

may help solving the problem itself.

