


Published in

Towards Data Science



Apr 18, 2021

·

9 min read

Save

Introduction to The Structural Topic Model (STM)

A unique way to use topic modelling for social science research

Photo by Malin Strandvall on Unsplash

Motivating STM







T


The STM solution

Topic prevalence


Topic content


Full formula for βᵢ,�,ᵥ. βᵢ,�,ᵥ means: for a given document i and given topic k, what is the probability of a given word

v.

STM plate diagram. Recall z is the topic our θ generates. W is the word selected from that topic, based on β. M is

the number of documents in the corpus. N is the number of words in a document. Boxes are kind of like loops,

meaning we’re repeating the innermost process (z and w) for every word for every document.

Posterior distribution. Recall that η is essentially our topic prevalence before the logistic transformation that

converts it into a probability.

Super Brief Inference Sidebar

Conclusion


3



Follow

Your home for data science. A Medium publication sharing concepts, ideas and codes.



Read more from Towards Data Science



Topic Modeling

NLP

Unsupervised Learning




