
Conjugate prior

Toggle the table of contents



 6

languages

Article

Talk

Tools From Wikipedia, the free encyclopedia

Part of a series on

Bayesian statistics



Posterior = Likelihood × Prior ÷ Evidence

Background

Bayesian inference · Bayesian probability · Bayes' theorem · Bernstein–von Mises theorem · Coherence · Cox's theorem · Cromwell's rule · Principle of indifference ·

Principle of maximum entropy

Model building

Weak prior ... Strong prior · Conjugate prior · Linear regression · Empirical Bayes · Hierarchical model

Posterior approximation

Markov chain Monte Carlo · Laplace's approximation · Integrated nested Laplace approximations · Variational inference · Approximate Bayesian computation

Estimators

Bayesian estimator · Credible interval · Maximum a posteriori estimation

Evidence approximation

Evidence lower bound · Nested sampling

Model evaluation

Bayes factor · Model averaging · Posterior predictive



 Mathematics portal

v · t · e

In Bayesian probability theory, if the posterior distribution 

 is in the same probability distribution family as the prior probability distribution 

, the prior and

posterior are then called conjugate distributions, and the prior is called a conjugate prior for the likelihood function 

.

A conjugate prior is an algebraic convenience, giving a closed-form expression for the posterior; otherwise, numerical integration may be necessary. Further,

conjugate priors may give intuition by more transparently showing how a likelihood function updates a prior distribution.

The concept, as well as the term "conjugate prior", were introduced by Howard Raiffa and Robert Schlaifer in their work on Bayesian decision theory.[1] A similar

concept had been discovered independently by George Alfred Barnard.[2]

Example [edit]

The form of the conjugate prior can generally be determined by inspection of the probability density or probability mass function of a distribution. For example,

consider a random variable which consists of the number of successes  in  Bernoulli trials with unknown probability of success  in [0,1]. This random variable will

follow the binomial distribution, with a probability mass function of the form

The usual conjugate prior is the beta distribution with parameters ( , ):

where  and  are chosen to reflect any existing belief or information (

 and 

 would give a uniform distribution) and 

 is the Beta function acting as a

normalising constant.

In this context,  and  are called hyperparameters (parameters of the prior), to distinguish them from parameters of the underlying model (here ). A typical

characteristic of conjugate priors is that the dimensionality of the hyperparameters is one greater than that of the parameters of the original distribution. If all

parameters are scalar values, then there will be one more hyperparameter than parameter; but this also applies to vector-valued and matrix-valued parameters.

(See the general article on the exponential family, and also consider the Wishart distribution, conjugate prior of the covariance matrix of a multivariate normal

distribution, for an example where a large dimensionality is involved.)

If we sample this random variable and get  successes and 

 failures, then we have

which is another Beta distribution with parameters 

. This posterior distribution could then be used as the prior for more samples, with the hyperparameters

simply adding each extra piece of information as it comes.

Interpretations [edit]

Pseudo-observations [edit]








It is often useful to think of the hyperparameters of a conjugate prior distribution corresponding to having observed a certain number of pseudo-observations with

properties specified by the parameters. For example, the values  and  of a beta distribution can be thought of as corresponding to 

 successes and 

 failures if

the posterior mode is used to choose an optimal parameter setting, or  successes and  failures if the posterior mean is used to choose an optimal parameter

setting. In general, for nearly all conjugate prior distributions, the hyperparameters can be interpreted in terms of pseudo-observations. This can help provide

intuition behind the often messy update equations and help choose reasonable hyperparameters for a prior.

Dynamical system [edit]

One can think of conditioning on conjugate priors as defining a kind of (discrete time) dynamical system: from a given set of hyperparameters, incoming data

updates these hyperparameters, so one can see the change in hyperparameters as a kind of "time evolution" of the system, corresponding to "learning". Starting at

different points yields different flows over time. This is again analogous with the dynamical system defined by a linear operator, but note that since different samples

lead to different inferences, this is not simply dependent on time but rather on data over time. For related approaches, see Recursive Bayesian estimation and Data

assimilation.

Practical example [edit]

Suppose a rental car service operates in your city. Drivers can drop off and pick up cars anywhere inside the city limits. You can find and rent cars using an app.

Suppose you wish to find the probability that you can find a rental car within a short distance of your home address at any time of day.

Over three days you look at the app and find the following number of cars within a short distance of your home address: 

Suppose we assume the data comes from a Poisson distribution. In that case, we can compute the maximum likelihood estimate of the parameters of the model,

which is 

 Using this maximum likelihood estimate, we can compute the probability that there will be at least one car available on a given day: 

This is the Poisson distribution that is the most likely to have generated the observed data . But the data could also have come from another Poisson distribution,

e.g., one with 

, or 

, etc. In fact, there is an infinite number of Poisson distributions that could have generated the observed data. With relatively few data

points, we should be quite uncertain about which exact Poisson distribution generated this data. Intuitively we should instead take a weighted average of the

probability of 

 for each of those Poisson distributions, weighted by how likely they each are, given the data we've observed .

Generally, this quantity is known as the posterior predictive distribution 

 where  is a new data point,  is the observed data and  are the

parameters of the model. Using Bayes' theorem we can expand 

 therefore 

 Generally, this integral is hard to compute. However, if

you choose a conjugate prior distribution 

, a closed-form expression can be derived. This is the posterior predictive column in the tables below.

Returning to our example, if we pick the Gamma distribution as our prior distribution over the rate of the Poisson distributions, then the posterior predictive is the

negative binomial distribution, as can be seen from the table below. The Gamma distribution is parameterized by two hyperparameters 

, which we have to choose.

By looking at plots of the gamma distribution, we pick 

, which seems to be a reasonable prior for the average number of cars. The choice of prior

hyperparameters is inherently subjective and based on prior knowledge.

Given the prior hyperparameters  and  we can compute the posterior hyperparameters 

 and 

Given the posterior hyperparameters, we can finally compute the posterior predictive of 

This much more conservative estimate reflects the uncertainty in the model parameters, which the posterior predictive takes into account.

Table of conjugate distributions [edit]

Let n denote the number of observations. In all cases below, the data is assumed to consist of n points 

 (which will be random vectors in the multivariate

cases).

If the likelihood function belongs to the exponential family, then a conjugate prior exists, often also in the exponential family; see Exponential family: Conjugate

distributions.

When the likelihood function is a discrete distribution [edit]



This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section.

Unsourced material may be challenged and removed. (August 2020) (Learn how and when to remove this template message)

Likelihood

Model parameters

Conjugate

prior

distribution

Prior

hyperparameters

Posterior

hyperparameters[note 1]

Interpretation of

hyperparameters

Posterior

predictive[note 2]

Bernoulli

p (probability)

Beta

 successes,  failures[note 3]

Binomial

with known

number of

trials, m

p (probability)

Beta

 successes,  failures[note 3]

(beta-binomial)

Negative

binomial

with known

failure number,

r

p (probability)

Beta

 total successes, 

failures[note 3] (i.e., 

experiments, assuming  stays

fixed)

(beta-negative

binomial)

Poisson

λ (rate)

Gamma

 total occurrences in 

intervals

(negative

binomial)

 [note 4]

 total occurrences in  intervals (negative

binomial)


Categorical

p (probability vector), k

(number of categories; i.e.,

size of p)

Dirichlet

 where  is the

number of observations in

category i

 occurrences of category 

[note 3]

Multinomial

p (probability vector), k

(number of categories; i.e.,

size of p)

Dirichlet

 occurrences of category 

[note 3]

(Dirichlet-

multinomial)

Hypergeometric

with known total

population size,

N

M (number of target

members)

Beta-

binomial[3]

 successes,  failures[note 3]

Geometric

p0 (probability)

Beta

 experiments,  total

failures[note 3]

When likelihood function is a continuous distribution [edit]

Likelihood

Model

parameters

Conjugate

prior

distribution

Prior

hyperparameters

Posterior

hyperparameters[note 1]

Interpretation of hyperparameters Posterior predictive[note 5]

Normal

with known

variance σ2

μ (mean)

Normal

mean was estimated from

observations with total precision (sum

of all individual precisions) 

 and

with sample mean 

[4]

Normal

with known

precision τ

μ (mean)

Normal

mean was estimated from

observations with total precision (sum

of all individual precisions)  and with

sample mean 

[4]

Normal

with known

mean μ

σ2 (variance)

Inverse

gamma

 [note 6]

variance was estimated from 

observations with sample variance 

(i.e. with sum of squared deviations ,

where deviations are from known

mean )

[4]

Normal

with known

mean μ

σ2 (variance)

Scaled

inverse chi-

squared

variance was estimated from 

observations with sample variance 

[4]

Normal

with known

mean μ

τ (precision)

Gamma

[note 4]

precision was estimated from 

observations with sample variance 

(i.e. with sum of squared deviations ,

where deviations are from known

mean )

[4]

Normal[note 7]

μ and σ2

Assuming

exchangeability

Normal-

inverse

gamma

 is the sample mean

mean was estimated from 

observations with sample mean ;

variance was estimated from 

observations with sample mean  and

sum of squared deviations 

[4]

Normal

μ and τ

Assuming

exchangeability

Normal-

gamma

 is the sample mean

mean was estimated from 

observations with sample mean ,

and precision was estimated from 

observations with sample mean  and

sum of squared deviations 

[4]

Multivariate

normal with

known

covariance

matrix Σ

μ (mean

vector)

Multivariate

normal

 is the sample mean

mean was estimated from

observations with total precision (sum

of all individual precisions)

 and with

sample mean 

[4]

Multivariate

normal with

known

precision

matrix Λ

μ (mean

vector)

Multivariate

normal

 is the sample mean

mean was estimated from

observations with total precision (sum

of all individual precisions)  and with

sample mean 

[4]

Multivariate

normal with

known mean

μ

Σ (covariance

matrix)

Inverse-

Wishart

covariance matrix was estimated from 

 observations with sum of pairwise

deviation products 

[4]

Multivariate

normal with

known mean

μ

Λ (precision

matrix)

Wishart

covariance matrix was estimated from 

 observations with sum of pairwise

deviation products 

[4]


Multivariate

normal

μ (mean

vector) and Σ

(covariance

matrix)

normal-

inverse-

Wishart

 is the sample mean

mean was estimated from 

observations with sample mean ;

covariance matrix was estimated from 

 observations with sample mean 

and with sum of pairwise deviation

products 

[4]

Multivariate

normal

μ (mean

vector) and Λ

(precision

matrix)

normal-

Wishart

 is the sample mean

mean was estimated from 

observations with sample mean ;

covariance matrix was estimated from 

 observations with sample mean 

and with sum of pairwise deviation

products 

[4]

Uniform

Pareto

 observations with maximum value 

Pareto 

with known

minimum xm

k (shape)

Gamma

 observations with sum  of the order

of magnitude of each observation (i.e.

the logarithm of the ratio of each

observation to the minimum )

Weibull 

with known

shape β

θ (scale)

Inverse

gamma[3]

 observations with sum  of the β'th

power of each observation

Log-normal

Same as for the normal distribution after applying the natural logarithm to the data for the posterior hyperparameters. Please refer to Fink (1997,

pp. 21–22) to see the details.

Exponential

λ (rate)

Gamma

 [note 4]

 observations that sum to  [5]

(Lomax distribution)

Gamma 

with known

shape α

β (rate)

Gamma

 observations with sum 

[note 8]

Inverse

Gamma 

with known

shape α

β (inverse

scale)

Gamma

 observations with sum 

Gamma 

with known

rate β

α (shape)

 or  observations (  for estimating , 

for estimating ) with product 

Gamma[3]

α (shape), β

(inverse scale)

 was estimated from  observations

with product ;  was estimated from 

observations with sum 

Beta

α, β

 and  were estimated from 

observations with product  and

product of the complements 

See also [edit]

Beta-binomial distribution

Notes [edit]

1. ^ a b Denoted by the same symbols as the prior hyperparameters with primes added ('). For instance  is denoted 

2. ^ This is the posterior predictive distribution of a new data point  given the observed data points, with the parameters marginalized out. Variables with primes indicate the

posterior values of the parameters.

3. ^ a b c d e f g The exact interpretation of the parameters of a beta distribution in terms of number of successes and failures depends on what function is used to extract a

point estimate from the distribution. The mean of a beta distribution is 

 which corresponds to  successes and  failures, while the mode is 

 which corresponds to 

 successes and 

 failures. Bayesians generally prefer to use the posterior mean rather than the posterior mode as a point estimate, justified by a quadratic loss

function, and the use of  and  is more convenient mathematically, while the use of 

 and 

 has the advantage that a uniform 

 prior corresponds to 0 successes and

0 failures. The same issues apply to the Dirichlet distribution.

4. ^ a b c β is rate or inverse scale. In parameterization of gamma distribution,θ = 1/β and k = α.

5. ^ This is the posterior predictive distribution of a new data point  given the observed data points, with the parameters marginalized out. Variables with primes indicate the

posterior values of the parameters.  and  refer to the normal distribution and Student's t-distribution, respectively, or to the multivariate normal distribution and multivariate t-

distribution in the multivariate cases.

6. ^ In terms of the inverse gamma,  is a scale parameter

7. ^ A different conjugate prior for unknown mean and variance, but with a fixed, linear relationship between them, is found in the normal variance-mean mixture, with the

generalized inverse Gaussian as conjugate mixing distribution.

8. ^ 

 is a compound gamma distribution;  here is a generalized beta prime distribution.

References [edit]

1. ^ Howard Raiffa and Robert Schlaifer. Applied Statistical Decision Theory. Division of Research, Graduate School of Business Administration, Harvard University, 1961.

2. ^ Jeff Miller et al. Earliest Known Uses of Some of the Words of Mathematics , "conjugate prior distributions" . Electronic document, revision of November 13, 2005,

retrieved December 2, 2005.

3. ^ a b c Fink, Daniel (1997). 



"A Compendium of Conjugate Priors"

 (PDF). CiteSeerX 10.1.1.157.5540 . Archived from 



the original

 (PDF) on May 29, 2009.

4. ^ a b c d e f g h i j k l m Murphy, Kevin P. (2007), 



Conjugate Bayesian analysis of the Gaussian distribution

 (PDF)


Privacy policy About Wikipedia Disclaimers

Contact Wikipedia Mobile view Developers

Statistics

Cookie statement





This page was last edited on 29 January 2023, at 17:22 (UTC).

Text is available under the Creative Commons Attribution-ShareAlike License 3.0; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia®

is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.

5. ^ Liu, Han; Wasserman, Larry (2014). 



Statistical Machine Learning

 (PDF). p. 314.

Categories: Bayesian statistics

Conjugate prior distributions



