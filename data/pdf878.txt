
Ranking SVM

Toggle the table of contents



 1

language

Article

Talk

Tools From Wikipedia, the free encyclopedia

In machine learning, a Ranking SVM is a variant of the support vector machine algorithm, which is used to solve certain ranking

problems (via learning to rank). The ranking SVM algorithm was published by Thorsten Joachims in 2002.[1] The original purpose of

the algorithm was to improve the performance of an internet search engine. However, it was found that Ranking SVM also can be used

to solve other problems such as Rank SIFT.[2]

Description [edit]

The Ranking SVM algorithm is a learning retrieval function that employs pair-wise ranking methods to adaptively sort results based on

how 'relevant' they are for a specific query. The Ranking SVM function uses a mapping function to describe the match between a

search query and the features of each of the possible results. This mapping function projects each data pair (such as a search query

and clicked web-page, for example) onto a feature space. These features are combined with the corresponding click-through data

(which can act as a proxy for how relevant a page is for a specific query) and can then be used as the training data for the Ranking

SVM algorithm.

Generally, Ranking SVM includes three steps in the training period:

1. It maps the similarities between queries and the clicked pages onto a certain feature space.

2. It calculates the distances between any two of the vectors obtained in step 1.

3. It forms an optimization problem which is similar to a standard SVM classification and solves this problem with the regular SVM

solver.

Background [edit]

Ranking Method [edit]

Suppose  is a data set containing  elements .  is a ranking method applied to . Then the  in  can be represented as a 

 binary

matrix. If the rank of  is higher than the rank of , i.e. 

, the corresponding position of this matrix is set to value of "1". Otherwise

the element in that position will be set as the value "0".

Kendall's Tau[3][4]

[edit]

Kendall's Tau also refers to Kendall tau rank correlation coefficient, which is commonly used to compare two ranking methods for the

same data set.

Suppose  and  are two ranking method applied to data set , the Kendall's Tau between  and  can be represented as follows:

where  is the number of concordant pairs and  is the number of discordant pairs (inversions). A pair  and  is concordant if both 

and  agree in how they order  and  . It is discordant if they disagree.

Information Retrieval Quality[5][6][7]

[edit]

Information retrieval quality is usually evaluated by the following three measurements:

1. Precision

2. Recall

3. Average Precision

For a specific query to a database, let 

 be the set of relevant information elements in the database and 

 be the set of the

retrieved information elements. Then the above three measurements can be represented as follows:










Labelled points in feature space

where 

 is the 

 of 

.

Let  and 

 be the expected and proposed ranking methods of a database respectively, the lower bound of Average Precision of

method 

 can be represented as follows:

where  is the number of different elements in the upper triangular parts of matrices of  and 

 and  is the number of relevant

elements in the data set.

SVM Classifier[8]

[edit]

Suppose 

 is the element of a training data set, where  is the feature vector and  is the label (which classifies the category of ).

A typical SVM classifier for such data set can be defined as the solution of the following optimization problem.

The solution of the above optimization problem can be represented as a linear combination of the feature vectors s.

where  is the coefficients to be determined.

Ranking SVM algorithm [edit]

Loss Function [edit]

Let 

 be the Kendall's tau between expected ranking method  and proposed method 

, it can be proved that maximizing 

 helps

to minimize the lower bound of the Average Precision of 

.

Expected Loss Function[9]

The negative 

 can be selected as the loss function to minimize the lower bound of Average Precision of 

 

where 

 is the statistical distribution of  to certain query .

Empirical Loss Function

Since the expected loss function is not applicable, the following empirical loss function is selected for the training data in practice.

Collecting training data [edit]

 i.i.d. queries are applied to a database and each query corresponds to a ranking method. The training data set has  elements. Each

element contains a query and the corresponding ranking method.

Feature Space [edit]

A mapping function 

[10][11] is required to map each query and the element of database to a

feature space. Then each point in the feature space is labelled with certain rank by ranking

method.

Optimization problem [edit]

The points generated by the training data are in the feature space, which also carry the rank

information (the labels). These labeled points can be used to find the boundary (classifier) that

specifies the order of them. In the linear case, such boundary (classifier) is a vector.

Suppose  and  are two elements in the database and denote 

 if the rank of  is higher

than  in certain ranking method . Let vector  be the linear classifier candidate in the feature

space. Then the ranking problem can be translated to the following SVM classification problem.




W candidate



Not a w candidate

Note that one ranking method corresponds to one query.

The above optimization problem is identical to the classical SVM classification problem, which is the reason why this algorithm is called

Ranking-SVM.

Retrieval Function [edit]

The optimal vector  obtained by the training sample is

So the retrieval function could be formed based on such optimal classifier. 

For new query , the retrieval function first projects all elements of the database to the feature

space. Then it orders these feature points by the values of their inner products with the optimal

vector. And the rank of each feature point is the rank of the corresponding element of

database for the query .

Application of Ranking SVM [edit]

Ranking SVM can be applied to rank the pages according to the query. The algorithm can be

trained using click-through data, where consists of the following three parts:

1. Query.

2. Present ranking of search results

3. Search results clicked on by user

The combination of 2 and 3 cannot provide full training data order which is needed to apply the

full SVM algorithm. Instead, it provides a part of the ranking information of the training data. So

the algorithm can be slightly revised as follows.

The method  does not provide ranking information of the whole dataset, it's a subset of the full ranking method. So the condition of

optimization problem becomes more relax compared with the original Ranking-SVM.

References [edit]

1. ^ Joachims, T. (2002), "Optimizing Search Engines using Clickthrough Data", Proceedings of the ACM Conference on Knowledge Discovery

and Data Mining

2. ^ Bing Li; Rong Xiao; Zhiwei Li; Rui Cai; Bao-Liang Lu; Lei Zhang; "Rank-SIFT: Learning to rank repeatable local interest points", Computer

Vision and Pattern Recognition (CVPR), 2011

3. ^ M.Kemeny . Rank Correlation Methods, Hafner, 1955

4. ^ A.Mood, F. Graybill, and D. Boes. Introduction to the Theory of Statistics. McGraw-Hill, 3rd edition, 1974

5. ^ J. Kemeny and L. Snell. Mathematical Models in THE Social Sciences. Ginn &amp; Co. 1962

6. ^ Y. Yao. Measuring retrieval effectiveness based on user preference of documents. Journal of the American Society for Information

Science, 46(2): 133-145, 1995.

7. ^ R.Baeza- Yates and B. Ribeiro-Neto. Modern Information Retrieval. Addison- Wesley-Longman, Harlow, UK, May 1999

8. ^ C. Cortes and V.N Vapnik. Support-vector networks. Machine Learning Journal, 20: 273-297,1995

9. ^ V.Vapnik. Statistical Learning Theory. WILEY, Chichester, GB, 1998

10. ^ N.Fuhr. Optimum polynomial retrieval functions based on the probability ranking principle. ACM TRANSACTIONS on Information Systems,

7(3): 183-204

11. ^ N.Fuhr, S. Hartmann, G. Lustig, M. Schwantner, K. Tzeras, and G. Knorz. Air/x - a rule-based multistage indexing system for large

subject fields. In RIAO,1991

Category: Support vector machines


Privacy policy About Wikipedia Disclaimers

Contact Wikipedia Mobile view Developers

Statistics

Cookie statement





This page was last edited on 23 June 2022, at 06:06 (UTC).

Text is available under the Creative Commons Attribution-ShareAlike License 3.0; additional terms may apply. By using this site, you agree to the Terms of

Use and Privacy Policy. WikipediaÂ® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.



