
Biomedical Knowledge Graph Reﬁnement with Embedding and Logic Rules

Sendong Zhao1 , Bing Qin1 , Ting Liu1 , Fei Wang2

1Faculty of Computing, Harbin Institute of Technology

2Weill Cornell Medical College, Cornell University

{sdzhao, bqin, tliu}@ir.hit.edu.cn, few2001@med.cornell.edu

Abstract

Currently, there is a rapidly increasing need

for high-quality biomedical knowledge graphs

(BioKG) that provide direct and precise biomedical

knowledge. In the context of COVID-19, this issue

is even more necessary to be highlighted. However,

most

BioKG

construction

inevitably

includes

numerous conﬂicts and noises deriving from

incorrect knowledge descriptions in literature and

defective information extraction techniques. Many

studies have demonstrated that reasoning upon the

knowledge graph is effective in eliminating such

conﬂicts and noises. This paper proposes a method

BioGRER to improve the BioKG’s quality, which

comprehensively combines the knowledge graph

embedding and logic rules that support and negate

triplets in the BioKG. In the proposed model,

the BioKG reﬁnement problem is formulated

as the probability estimation for triplets in the

BioKG. We employ the variational EM algorithm

to optimize knowledge graph embedding and logic

rule inference alternately. In this way, our model

could combine efforts from both the knowledge

graph embedding and logic rules, leading to better

results than using them alone. We evaluate our

model over a COVID-19 knowledge graph and

obtain competitive results.

Introduction

Collecting structured biomedical knowledge has become a

crucial task to provide physicians and doctors with direct

and precise biomedical knowledge for decision-making, es-

pecially for some new dangerous diseases like COVID-19.

By the end of July 2020, there had been 646,949 deaths

worldwide because of COVID-19, and this number is still in-

creasing Viglione [2020]. In the face of this global pandemic,

great research interest has been attracted, and the literature

of COVID-19 is very dynamics and being updated very fast

Xiang et al. [2020]. According to LitCOVID Chen et al.

[2020b], there have already been more than 47,758 research

articles about COVID-19 until Aug. 2020. In reality, it is

almost impossible for the readers to keep up with all the arti-

cles they are interested in. This makes automatic knowledge

graph curation from COVID-9 articles highly demanding.

Such knowledge graphs can accelerate the understanding of

the transmission and prevention of COVID-19 and help with

the battle of COVID-19.

However, the majority of BioKGs curated with information

extraction techniques tend to suffer from low-quality. These

BioKGs, which comprise biomedical entities and relations,

can be built with NLP techniques including biomedical re-

lation extraction and biomedical named entity recognition.

These NLP techniques might bring noises due to their inher-

ent defects. In particular, some non-existing relations might

be extracted from biomedical literature. Some biomedical

named entities might not be recognized precisely. The correct

knowledge described in literature can be misextracted by

the NLP models, let alone the incorrect descriptions. There

is usually unreliable knowledge in biomedical literature.

Unreliable knowledge could be incorrect conclusions, incon-

sistent and even conﬂicting answers for the same question

in different articles. For example, “Young adults have a

very low risk of COVID-19Adams et al. [2020]” has been

proved to be seriously misleading Viglione [2020]. Besides,

there is another example. The evidence in Cardwell et al.

[2010] indicates that oral bisphosphonates are not associated

with esophageal cancer. However, Green et al. Green et al.

[2010] reached a completely contradictory conclusion that

bisphosphonates are associated with esophageal cancer.

Noises from different ways mentioned above severely

diminish the utility of the BioKG. Therefore, it encourages

more and more interest in BioKG reﬁnement. However,

related studies are all conducted on general knowledge graph

like Freebase, Wikidata, and YAGO. These studies can be

generally summarized into three categories that are 1) the

web-search based knowledge veriﬁcation models, 2) fact

check models with pattern matching, and 3) hybrid models

by combining different resources to verify the knowledge

graph. Fionda et al. Fionda and Pirr`o [2018] leveraged the

knowledge schema to generate evidence patterns and check

facts in a knowledge graph with patterns. Chen et al. Chen et

al. [2020a] proposed a knowledge graph reﬁnement model,

which combines lexical matching, graph embedding, soft

rule patterns, and semantic consistency checking. The above

studies have proved that it is effective to verify general

knowledge graphs with links of knowledge graph and logic

rules.

arXiv:2012.01031v1  [cs.AI]  2 Dec 2020


In a BioKG, each triplet with form (head, relation, tail),

denoted as (h, r, t), is composed of a link r and two nodes

(h,t). BioKG reﬁnement is to quantize the plausibility of

each triplet (h, r, t). Knowledge graph embedding has been

developed as a promising method for this purpose. This

method can learn continuous representations for links and

nodes in the knowledge graph to effectively measure the

plausibility of triplets with a score function Bordes et al.

[2013]. However, one limitation is that they do not consider

logic rules which can directly infer knowledge.

In another line of this topic, rule-based approaches Lin et

al. [2018]; Fionda and Pirr`o [2018]; Lin et al. [2019] are

utilized for knowledge graph reﬁnement. Logic rules can be

either manually generated by domain experts or mined from

the knowledge graph itself. They are used as triplet checking

patterns and suggest the correctness of triplets. However,

logic rules can only cover a small portion of triplets, thus

limiting the effectiveness of methods that are purely based

on logic rules.

In this paper, we introduce a model for BioKG reﬁne-

ment, which leverages the best of both worlds by combining

two clues: 1) knowledge graph embedding which encodes

underlying semantics of BioKG; 2) supporting rules and

negating-like rules that can be directly applied to support

and negate triplets in the BioKG. In the proposed model,

the BioKG reﬁnement is formulated as the plausibility es-

timation for each triplet. A variational EM algorithm is

utilized for training knowledge graph embedding and logic

rule inference alternately. Both efforts from the underlying

knowledge graph and logic rules can be combined with this

alternating process of learning. Experimental results over a

COVID-19 knowledge graph demonstrate that our model can

signiﬁcantly outperform competitive baselines.

Related Work

It is critical to verify the correctness of the collected struc-

tured knowledge, claim, and statement for real-world usage.

Therefore, this topic has drawn extensive attention from

both the research and industrial community. In general, there

are two types of knowledge veriﬁcation, including fact-

checking in free text and fact-checking in the knowledge

graph. Speciﬁcally, fact-checking in free text is to verify

textual contents such as claims and statements. Fact-checking

in the knowledge graph is to check the correctness of triplets

in a given knowledge graph. Here, we survey related work of

knowledge veriﬁcation in the context of knowledge graphs.

There exist three types of approaches for knowledge veriﬁca-

tion in the knowledge graph.

Knowledge graph embedding models can learn represen-

tations of links and nodes in knowledge graph and compute

plausibility of triplet candidates with a score function. For

the knowledge graph embedding models, we choose ﬁve

representative models to compare with, including ConvE

Dettmers et al. [2018], ComplEx Trouillon et al. [2016],

HolE Nickel et al. [2015b], DistMult Yang et al. [2015] and

TransE Bordes et al. [2013].

Another solution is to apply knowledge graph schema,

patterns, or rules to measure the correctness of triplets Lin

et al. [2018]; Fionda and Pirr`o [2018]; Lin et al. [2019]. Lin

et al. Lin et al. [2018] introduced a fact-checking method

for knowledge graph with graph fact-checking rules. These

rules incorporate expressive subgraph patterns to describe

constraints in the knowledge graph. Likewise, Fionda et al.

Fionda and Pirr`o [2018] leveraged the knowledge schema

to generate schema-level paths as patterns and check facts

in a knowledge graph with patterns. Lin et al. Lin et al.

[2019] further extended their method in Lin et al. [2018]

for identifying and exploiting similar facts. Therefore, their

method is able to check the fact that may not exactly match

any known patterns.

There is a third line of researches which apply multiple

resources for fact-checking in knowledge graph Li et al.

[2017]; Chen et al. [2020a]; Gad-Elrab et al. [2019b,a];

Cao et al. [2020]. Li et al. Li et al. [2017] used various

evidence collection techniques to collect evidence from the

knowledge graph, the web, and query logs and checked

triplets with knowledge fusion. A tool was designed to in-

corporate both evidence in textual sources and the underlying

knowledge graph Gad-Elrab et al. [2019b]. Similarly, another

tool ExFaKT Gad-Elrab et al. [2019a] was proposed to

compute explanations over the content of knowledge graphs

and textual resources. Cao et al. Cao et al. [2020] proposed

a probabilistic graphical model to infer the truthfulness of

extracted facts from different evidence sources.

Problem Statement

A BioKG is a collection of biomedical relational facts, each

of which is represented as a triplet (h, r, t). The problem

of noises in BioKG could cause undesired impacts in both

research and clinical decision-making process. Therefore, a

critical problem of BioKGs is to verify the correctness of

triplets.

Formally, given a BioKG G = (E, R, T, M), where E is a

set of biomedical entities, R is a set of biomedical relations,

T is a set of true triplets (h, r, t) in the BioKG, M is a set

of triplets (h, r, t) whose correctness is uncertain in BioKG,

the goal is to verify the correctness of each triplet candidate

τ ∈ M

Deﬁnition 1 (Biomeical

Knowledge

Graph

Reﬁnement).

Given

a

BioKG

G

consists

of

triplets

(h, r, t),

biomedical knowledge graph reﬁnement

decides

if

each

triplet in M is true.

Thus, it is natural to consider this task as a binary classiﬁca-

tion task that takes as input BioKG G and the triplet candidate

(h, r, t) to be veriﬁed. Following a previous study Nickel et

al. [2015a], we can formulate this problem in a probabilistic

way. We take the indicator V(h,r,t) of each triplet (h, r, t) as

a probabilistic variable. V(h,r,t) = 1 represents (h, r, t) is a

true triplet, and V(h,r,t) = 0 otherwise. Given the BioKG

comprise triplets (h, r, t), we aim to estimate the probability

of V(h,r,t) for (h, r, t) ∈ M, i.e., p(V(h,r,t)∈M).

Method

In this section, we introduce our proposed approach of

Biomedical knowledge Graph Reﬁnement with knowledge


graph

Embedding

and

logic

Rules

(BioGRER).

This

approach incorporates logic rules and the knowledge graph

embedding with underlying semantics. To better use the

logic rules driving from knowledge graph schema, BioGRER

considers supporting rules and negating-like rules with a

logistic regression model and quantiﬁes the plausibility of

given triplets. The knowledge graph embedding model can

learn embeddings of entities and relations with triplets in the

knowledge graph. BioGRER incorporates a knowledge graph

embedding model to predict the correctness of given triplets

with the learned entity and relation embeddings. These two

components are not independent and should augment each

other’s capability. Therefore, we jointly train these two

components with the variational EM algorithm and allow

them alternating between a variational E-step and an M-step.

In the E step, we use knowledge graph embeddings to predict

given triplets to be veriﬁed. In the M step, the weights of

rules in the logistic regression model are updated based on

the true and veriﬁed true triplets in BioKG. An overview of

our model BioGRER is given in Figure 1.

Supporting and Negating-like Rules Modeling

We apply a logic regression model to incorporate supporting

rules and negating-like rules. The supporting logic rules

enhance the triplet that can be inferred from them. Domain

knowledge can be directly encoded in these supporting rules.

These supporting logic rules include:

• Transitive Rules. A relation rk is a transitive equiva-

lence of ri and rj means that for any three entities x, y,

z, if x has relation ri with y, and y has relation rj with

z, then x has relation rk with z. We formally deﬁne this

rule as ∀x, y, z ∈ E, V (x, ri, y) = 1 ∧ V (y, rj, z) =

1 ⇒ V (x, rk, z) = 1.

• Symmetric Rules. A relation r is symmetric means that

for any entity pair x and y, if x has relation r with y,

then y also has relation r with x. We formally deﬁne this

rule as ∀x, y ∈ E, V (x, r, y) = 1 ⇒ V (y, r, x) = 1.

The negating-like rules negate the triplets that are denied

by them. In particular, links in the BioKG can be blocked by

negating-like rules. These negating-like rules include:

• Block Rules. A relation rk is a block of ri and rj means

that for any three entities x, y, z, if x has relation ri

with y, and y has relation rj with z, then x may not have

relation rk with z with a high rate. We formally deﬁne

this rule as ∀x, y, z ∈ E, V (x, ri, y) = 1∧V (y, rj, z) =

1 ⇒ V (x, rk, z) = 0.

• Conﬂict Rules. A relation rj is a conﬂict of ri indicates

that for any entity pair x and y, if x and y have relation

ri, then x may not have have relation rj. We formally

deﬁne this rule as ∀x, y ∈ E, V (x, ri, y) = 1 ⇒

V (x, rj, y) = 0.

In this study, we use logistic regression to model these

above supporting and negating-like rules. The supporting

rules should increase the plausibility of triplets. Otherwise,

the negating-like rules should decrease the plausibility of

triplets. Therefore, we design a positive indicator for support-

ing rules and a negative indicator for negating-like rules. We

have the logistic regression model to quantize the plausibility

of each triplet as follows:

Prule(τ) =

1

e−f(τ,T ) + 1,

(1)

where τ is a given triplet which needs to be veriﬁed, T is

the set of true triplets in BioKG. f() is the linear function to

combine logic rules which can be directly applied to the given

triplet, which is deﬁned as

f(τ, T) =

�

l∈L

IlwlN(l, τ, T),

(2)

where l is logic rule, L is a set of logic rules L = {l|L|

1 }, wl

is the weight of the rule l, Il is the indicator for the rule l

Il =

�+1

when l is a supporting rule

−1

when l is a negating-like rule

(3)

and N(l, τ, T) is the number of true groundings of the logic

rule l according to the speciﬁc rule l, the given triplet τ and

neighboring triplets in T. Figure 2 shows an example of

true groundings of logic rule for triplet candidate (MKRN3,

has gene product, nptx1 human). To negate this triplet, the

block rule pattern “has gene product ∧ interacts with ⇒

has gene product is invalid” can be applied with the true

grounding V (MKRN3, has gene product, mkrn3 human)=1

∧ V (mkrn3 human, interacts with, nptx1 human)=1 ⇒

V (MKRN3, has gene product, nptx1 human)=0.

We assume the network consists of all triplets in BioKG

as a Markov logic network because a triplet’s correctness

depends on its neighboring triplets with a certain degree.

Therefore, a triplet is conditionally independent of all other

triplets given its Markov blanket in the network. We deﬁne

the probabilistic joint distribution of all true triplets T and

triplet candidates M as

P(VT , VM) ≥

�

τ∈T ∪M

Prule(τ),

(4)

since Prule(τ) and Prule(ς) are not independent if triplet τ

and triplet ς share the same neighbor(s). In following sec-

tions, we will discuss the estimation of this joint distribution.

Knowledge Graph Embedding

Different from the logic rule-based model, the knowledge

graph embedding methods learn embeddings of entities and

relations with the true triplets T in knowledge graph, and

then predict the the correctness of a given triplet τ with the

learned entity and relation embeddings. Formally, head entity

h ∈ E, tail entity t ∈ E and relation r ∈ R are associated

with embeddings xh, xt and xr. Then the distribution of the

given triplet is deﬁned as:

Pembedding(τ) = Ber(V (τ)|f(xh, xr, xt)).

(5)

where Ber stands for the Bernoulli distribution, f(xh, xr, xt)

computes the probability that the triplet τ

= (h, r, t) is

true, with f(., ., .) being a scoring function on the entity and

relation embeddings. For example in the knowledge graph

embedding model TransE Bordes et al. [2013], the score


MKRN3

Gene

mkrn3_human

Protein

has_gene_product

Protein

nptx1_human

interacts_with

has_gene_product

?

CCP

related_to

GnRH

Disease

Chemical

related_to

?

related_to

Biomedical Knowledge Graph

Logic Rules Modeling

Block Rule: has_gene_product ∧ interacts_with

⇏ has_gene_product

Transitive Rule: related_to ∧ related_to

⇒ related_to

𝑃 =

1

1 + 𝑒!(#$%&amp;')

increase

decrease

E-Step:

Update distribution of triplets

which need to be verified.

M-Step:

Update weight of each logic

rule pattern.

Variational EM

Figure 1: Overview of the BioGRER for combining logic rules and knowledge graph embedding using the variational EM

framework.

MKRN3

Gene

mkrn3_human

Protein

has_gene_product

Protein

nptx1_human

interacts_with

has_gene_product

Figure 2: True groundings of block rule for negating triplet

candidate (MKRN3, has gene product, nptx1 human).

function f can be formulated as σ(γ − ||xh + xr − xt)||)

according to Sun et al. [2019], where σ is the sigmoid

function and γ is a ﬁxed bias. To learn the entity and

relation embeddings, these methods typically treat observed

ture triplets and veriﬁed triplets as positive examples and

the hidden triplets as negative ones. In other words, these

methods seek to maximize

Q(VT , VM) =

�

τ∈T ∪M

Pembedding(τ).

(6)

The whole framework can be efﬁciently optimized with the

stochastic gradient descent algorithm.

Variational EM

We introduce the variational EM framework to combine logic

rule modeling and knowledge graph embedding together.

The logistic regression model in Equation (1) models the

probabilistic joint distribution of all triplets as in Equation (4).

We can optimize this model by maximizing the log-likelihood

of all triplets, no matter true or false in a BioKG. However,

it is intractable to maximize the objective directly, since it

requires integrating over all variables VM and VT . We instead

optimize the variational evidence lower bound (ELBO) of the

data log-likelihood, as follows:

log P(VT ) ≥ log P(VT ) − KL[Q(VM)||P(VM|VT )]

=

�

(Q(VM) log P(VT , VM) − Q(VM) log Q(VM))dVM,

where KL denotes the KL divergence, and Q represents

the variational distribution of triplet candidates to be

veriﬁed. Equality in the above equation holds when

Q(VM) = P(VM|VT ). We then use the variational EM

algorithm Ghahramani et al. [2000] to effectively optimize

the ELBO. The variational EM algorithm consists of an

expectation step (E-step) and a maximization step (M-step),

which will be called in an alternating fashion to train the

model: 1) In the E-step, we infer the posterior distribution

of the latent variables, where P is ﬁxed, and Q is optimized

to minimize the KL divergence between Q(VM) and

P(VM|VT ); 2) In the M-step, we learn the weights of the

logic rules wl in logistic region model, where Q is ﬁxed, and

P is optimized to maximize the log-likelihood.

E-step: Inference Procedure

In the variational E-step, we ﬁx P and update Q by infer-

ring the posterior distribution with mean-ﬁeld approximation,

which is based on the learned embeddings of the knowledge

embedding model we have trained,

Q(VM) =

�

τ∈M

Pembedding(τ).

(7)

Through minimizing the KL divergence between Q(VM)

and the true posterior distribution P(VM|VT ), the optimal

Q(VM) is computed as

log Q(VM) = EQ(VMB)[log P(VM|VMB)] + const,


where VMB is the Markov blanket of VM, which contains

the triplets that appear together with VM in any grounding of

the logic rules. If there exists any triplet candidate that is not

veriﬁed yet in VMB, we replace it with a candidate which is

predicted as a true triplet by the knowledge graph embedding

model. With the equation above, our goal becomes ﬁnding a

distribution Q that satisﬁes the condition. To further optimize

the objective, we enhance the knowledge embedding model

by updating its training dataset with added veriﬁed triples,

which are predicted by the logistic regression model. In

particular, we ﬁrst compute Prule(Vτ|VMB) for each triplet

candidate τ. If P(Vτ

= 1|VMB) ≥ δ with δ being a

hyperparameter, then we treat τ as a true triplet and train

the knowledge graph embedding model to maximize the log-

likelihood log Pembedding(Vτ = 1). Otherwise, the triplet is

treated as a negative example. In this way, the knowledge

captured by logic rules can be effectively distilled into the

knowledge graph embedding model.

M-step: Learning Procedure

In the M-step, which is also known as the learning step,

we learn the weights of logic rules in the logistic regres-

sion model. We ﬁx Q and update the weights of logic

rules wl by maximizing the pseudo-likelihood function, i.e.,

EQ(VM)[log P(VT , VM)].

EQ(VM)[log P(VT , VM)]

= EQ(VM)[

�

τM∈M,τT ∈T

log Prule(VτM , VτT )]

= EQ(VM)[

�

τ∈M∪T

log Prule(Vτ|VMB)],

where Vτ is the indicator of triplet τ. Vτ = 1 represents τ

being a true triplet. Otherwise, Vτ = 0 represents τ being a

false triplet.

In particular, for each true triplet τ

∈ T, we seek to

maximize Prule(Vτ = 1|VMB). For each triplet candidate

τ ∈ M which needs to be veriﬁed, we treat Pembedding(Vτ =

1) as target for updating the probability Prule(Vτ = 1|VMB)

to minimize the difference between these two. In this way, the

knowledge graph embedding model essentially provides extra

supervision to beneﬁt in learning the weights of logic rules.

Besides, triplets candidates distinguished by the knowledge

embedding model in E-step are ﬁlled into the Markov blanket.

Therefore, by alternating between the variational E-step and

an M-step, BioGRER allows information sharing between

the knowledge graph embedding model and the logistic

regression model, thus combines efforts from both sides, as

shown in Figure 1.

Experiments

Dataset

We evaluate the BioGRER on a open available COVID-19

knowledge graph (kg-covid-19)1. This knowledge graph

incorporates up-to-date data extracted from biomedical

databases and literature, including drug, protein-protein

1https://github.com/Knowledge-Graph-Hub/kg-covid-19/wiki

interactions, SARS-CoV-2 gene annotations, concept and

publication data from the CORD19 Wang et al. [2020]

data set. Since the entire graph of this kg-covid-19 is

super large, we sample a sub-graph (sub-kg-covid-19) for

experiments. Table 1 shows the detailed statistics of the

extracted sub-graph of kg-covid-19.

Data Set

#Node

#Link

#Relation

sub-kg-covid-19

3,000

376,505

107

Table 1: The statistics of the sub-kg-covid-19.

Evaluation Metrics and Settings

Poisoning Triplet Detection (PTD)

We deﬁne a task named poisoning triplet detection for

BioKG. Speciﬁcally, we put new false links to a given

knowledge graph and generate new false triplets accordingly.

This task is to identify all these new added false triplets.

However, annotating these false triplets is tedious for

checkers to make sure triplets are genuinely false. Therefore,

how to generate false triplets becomes a big concern. To

this end, we randomly generate new links and develop new

triplets for sub-kg-covid-19. In this process, we check the

entire knowledge graph to ensure that these new triplets do

not exist in kg-covid-19. We take these randomly generated

triplets as false triplets and get 10,000 at last. We take

5,000 of these false triplets and 5000 existing true triplets to

compose the validation set. We take the rest 5,000 of false

triplets and other 5,000 existing true triplets to compose the

testing set. We call this testing set as the “Large” testing set.

Some of new generated false triples may be missing true

triplets. However, the number of these cases is relatively

small in such a dense graph like kg-covid-19. We sample 100

triplets from 10,000 generated false triplets and manually

check them via searching in PubMed and Google. The result

is 97% of them cannot be supported by any evidence from

PubMed and Google. In other words, 97% of them are true

false triplets. We take these 97 manually labeled false triplets

and other 103 true triplets to compose a testing set of 200

samples. We call it the “Small” testing set.

Missing Triplet Prediction (MTP)

Missing triplets prediction is a knowledge graph completion

task, which is targeted at assessing the plausibility of triples

not present in a knowledge graph. For this task, we randomly

take out 10,000 triplets from sub-kg-covid-19 as the valida-

tion set and take out the other 10,000 triplets as the testing

set.

Metrics

We compare different methods on the tasks of poisoning

triplet detection and missing triplet prediction. We formulate

poisoning triplet detection as a triplet classiﬁcation task. For

each triplet in the testing set, our model predicts whether it

is true or false. Therefore, we follow the standard evaluation

metrics for the classiﬁcation task, i.e., Precision (P), Recall

(R) and F-score (F). We formulate missing triplets prediction

as a ranking task. For each triplet in the testing set, we mask

the head or the tail entity, and let each compared method

predict the masked entity. Following existing studies Bordes

et al. [2013], we apply the ﬁltered setting during evaluation.


The Mean Rank (MR), Mean Reciprocal Rank (MRR) and

Hit@K (H@K) are treated as the evaluation metrics.

Settings

We search for all the possible supporting rules and negating-

like rules from the observed triplets to generate the candidate

logic rules. We compute the empirical precision of each rule

for supporting rules, i.e., pl = |R∩T |

|R| . R is the set of triplets

generated with logic rule l in the knowledge graph. They

may or may not exist in the knowledge graph. T is the

set of true triplets that do exist in knowledge graph. In our

study, we assume all triplets in the sub-kg-covid-19 are true.

We only select supporting rules whose empirical precision is

larger than a threshold β. Besides, we compute the empirical

precision of each negating-like rule as pl =

|D∩T |

|D| . D is

the set of triplets that should be negated with logic rule

l in the knowledge graph. However, some of them might

exist in the knowledge graph. We only keep supporting rules

whose empirical precision is 1. We consider two variants

for our approach, where BioGRER uses only Q to infer

the plausibility of triplet candidates during the evaluation.

In contrast, BioGRER* uses a weighted-sum of Q and P,

i.e., Q + λP. We use TransE Bordes et al. [2013] as the

default knowledge graph embedding model to optimize Q.

We update the weights of logic rules with gradient descent.

We select the learning rate λ for stochastic gradient descent

among {0.001, 0.01, 0.1}, the margin γ among {1, 2, 10},

and the dimension of embedding d in {10, 20, 30, 40, 50} on

the validation set. The optimal conﬁgurations are d = 30, γ

= 1, β = 0.3, λ = 1.

Compared Models

For BioKG reﬁnement tasks, we compare with the following

three types of baselines to evaluate BioGRER.

Rule-based models apply rules to measure the correct-

ness of triplet candidates. For the rule-based methods, we

compare with the Markov logic network (MLN) Richardson

and Domingos [2006] and the Bayesian logic programming

(BLP) method De Raedt and Kersting [2008], which model

logic rules with Markov networks and Bayesian networks

respectively. Besides, we compare with CHEEP Fionda and

Pirr`o [2018] which leveraged the knowledge schema to gen-

erate schema-level patterns and verify the knowledge graph

with patterns.

Knowledge graph embedding models can learn represen-

tations of links and nodes in knowledge graph and compute

plausibility of triplet candidates with a score function. For

the knowledge graph embedding models, we choose ﬁve

representative models to compare with, including ConvE

Dettmers et al. [2018], ComplEx Trouillon et al. [2016],

HolE Nickel et al. [2015b], DistMult Yang et al. [2015] and

TransE Bordes et al. [2013].

Hybrid models combine different resources to verify the

correctness of triplet candidates. We compare with pLogicNet

Qu and Tang [2019], RUGE Guo et al. [2018] and NNE-AER

Ding et al. [2018], which are hybrid methods that combine

knowledge graph embedding and logic rules. We also com-

pare Node+Path Chen et al. [2020a], which combines lexical

matching, semantic embedding, soft constraint mining, and

semantic consistency checking.

Main Results

We conduct experiments for poisoning triplet detection task

and missing triplet prediction task with different models. A

summary of the results is displayed in table 2. The “P@L”,

“R@L” and “F@L” columns show the results on the large

testing set for the poisoning triplet detection task. The

“P@S”, “R@S” and “F@S” columns show the results on the

manually labeled small testing set for the poisoning triplet

detection task. It is apparent that BioGRER signiﬁcantly

outperforms

all

baseline

models,

including

rule-based

models, knowledge graph embedding models, and hybrid

models on poisoning triplets detection. Compared with

rule-based models, BioGRER applies the knowledge graph

embedding technique to improve detection performance.

In addition to those rules that support triplets, our model

encodes all possible rules that negate triplets. This is a

different way of encoding logic rules compared with existing

rule-based studies. BioGRER outperforms knowledge graph

embedding models, as it exploits the knowledge encoded

within the logic rules. Moreover, BioGRER consistently

performs better than hybrid methods, which shows the

superiority of negating-like rules for poisoning triplet

detection. BioGRER* slightly outperforms BioGRER due to

the complementary information captured by Q and P. It is

reasonable that combining them is better than using single

alone. For the missing triplet prediction, BioGRER shares a

similar trend with the poisoning triplet detection task but the

improvements are limited, indicating that negating-like rules

for the missing triplet prediction task are not as effective as

for the poisoning triplet detection task.

Analysis of Different Rule Patterns

We consider four rule patterns, including two supporting rule

patterns and two negating-like rule patterns in our model.

To deep understand these rule patterns, we systematically

investigate the effect of each rule pattern. The results of vary-

ing combinations are presented in table 3. The results show

that most rule patterns can lead to improvement compared

to the model without logic rules. Moreover, the effects of

different rule patterns are quite different. Negating-like rule

patterns are more effective than supporting rule patterns. In

negating-like rule patterns, the “Block” rule achieves better

performances than the “Conﬂict” rule.

Effect of Knowledge Graph Embedding Models

Different knowledge graph embedding models might affect

the BioGRER differently. Thus, we compare the performance

of BioGRER* with representative knowledge graph embed-

ding models for both tasks. The results are displayed in

table 4. “PTD@L” and “PTD@S” columns report the F-score

of poisoning triplet detection over the large and small testing

set. The “MTP” column presents the H@1 of missing triplet

prediction task. The results indicate that our model is stable

for different knowledge graph embedding models.


Model Type

Model

Poisoning Triplet Detection

Missing Triplet Prediction

P@L

R@L

F@L

P@S

R@S

F@S

H@1

MRR

MR

Rule-based

BLP

1.07

1.22

1.14

0.55

1.03

0.71

0.03

0.007

4765

MLN

1.46

1.87

1.63

1.06

2.06

1.39

0.03

0.009

4431

CHEEP

99.73

2.67

5.20

100

3.09

5.99

0.03

0.011

4167

KG Embedding

TransE

6.79

8.14

7.40

6.06

6.18

6.12

3.83

0.082

820

DistMult

6.43

7.36

6.86

6

5.15

5.54

1.26

0.037

1125

HolE

4.31

4.73

4.51

4.08

4.12

4.09

0.07

0.016

2763

ComplEx

5.07

5.74

5.38

4.95

5.15

5.05

0.12

0.031

1638

ConvE

5.11

5.33

5.21

4.9

5.15

5.02

0.10

0.027

1869

Hybrid

RUGE

9.31

8.76

9.02

8.43

7.21

7.77

3.92

0.082

816

NNE-AER

8.63

7.87

8.23

7.14

6.18

6.62

5.64

0.103

567

pLogicNet

9.77

8.63

9.16

8.86

7.21

7.95

4.17

0.084

817

Node+Path

16.16

10.21

12.51

15.71

11.34

13.17

5.37

0.096

779

Our Model

BioGRER

67.21

28.32

39.85

65.85

27.83

39.12

6.31

0.115

579

BioGRER*

75.13

29.21

42.06

72.5

29.89

42.32

6.46

0.117

564

Table 2: The overall performance of two tasks over COVID-19 knowledge graph. H@1, P, R and F are %. (p-value ≤ 0.05)

Logic Rule

Poisoning Triplet Detection

Missing Triplet Prediction

P@L

R@L

F@L

P@S

R@S

F@S

H@1

MRR

MR

Without All

6.79

8.14

7.40

6.06

6.18

6.12

3.83

0.082

820

Without Support

71.34

29.21

41.45

69.04

29.89

13.06

6.13

0.115

571

Without Negate

9.79

8.62

9.17

9.33

7.21

8.13

4.17

0.085

812

Symmetric

9.71

8.62

9.13

8.43

7.21

7.77

4.13

0.077

817

Transitive

8.84

8.62

8.73

8.23

7.21

7.69

4.15

0.081

813

Conﬂict

17.16

8.93

11.75

15.68

8.24

10.80

4.66

0.101

764

Block

70.23

28.89

40.94

67.5

27.83

39.41

5.87

0.114

581

Table 3: The overall performance of two tasks over COVID-19 knowledge graph. H@1, P, R and F are %. (p-value ≤ 0.05)

KGE

PTD@L

PTD@S

MTP

TransE

42.06

42.32

6.46

DistMult

41.66

41.07

6.46

ComplEx

40.91

40.31

6.14

Table 4: The performance of the BioGRER* with different

knowledge graph embedding models.

Case Study of Logic Rules

Last but not least, we conduct case studies to better

understand the extracted logic rule patterns and speciﬁc logic

rules. Transitive Rule The transitive rule “tributary of(x,y)

∧

drains(y,z)

⇒

part of(x,z)”

has

an

example,

i.e.,

V(facial vein, tributary of, internal jugular vein)=1 ∧

V(internal jugular vein, drains, face)=1 ⇒ V(facial vein,

part of, face)=1. Given facial vein being a tributary of

internal jugular vein, and internal jugular vein draining

from face, we have facial vein being a part of face.

This example shows that the transitive rule is reasonable

and beneﬁt the veriﬁcation of “part of” links in BioKG.

Symmetric Rule. The symmetric rule “interacts with(x,y)

⇒ interacts with(y,x)” has an example, i.e., V(CASP1

gene, interacts with, IFITM2 protein)=1 ⇒ V(IFITM2

protein, interacts with, CASP1 gene)=1. Given CASP1

gene interacting with IFITM2 protein, we have IFITM2

protein interacting with CASP1 gene. This rule could

increase the plausibility of interacts with(A,B) links with

the existence of interacts with(B,A). Block Rule. The

block rule “has gene product(x,y) ∧ interacts with(y,z) ⇒

has gene produc(x,z)=0” has an example, i.e., V(MKRN3

gene,

has gene product,

MKRN3

human

protein)=1

∧

V(MKRN3 human protein, interacts with, NPTX1 human

protein)=1 ⇒ V(MKRN3 gene, has gene product, NPTX1

human protein)=0. Given MKRN3 gene, located at the

15th

human

chromosome,

producing

MKRN3

human

protein and MKRN3 human protein interacting with NPTX1

human protein, it is impossible to have MKRN3 gene

producing NPTX1 human protein, which is produced by

NPTX1 gene, located at the 17th human chromosome.

This block rule is very effective for negating the triplet

(MKRN3 gene, has gene product, NPTX1 human protein).

All knowledge graph embedding baselines predict this triplet

as true, while BioGRER predicts it as false because of

incorporating this block rule. Conﬂict Rule. The conﬂict

rule “has primary input(x,y) ⇒ has primary output(x,y)=0”

has

an

example,

i.e.,

V(morphine

catabolic

process,

has primary input, morphine)=1 ⇒ V(morphine catabolic

process, has primary output, morphine)=0. The morphine

catabolic process, which is a biological process, takes

the morphine as input resulting in the breakdown of

morphine.

Therefore,

morphine

catabolic

process

is

not

able

to

have

“has primary output”

relation

with

morphine. This conﬂict rule is very effective to negate

the

triplet

has primary output(x,y)

with

the

valid

has primary input(x,y).

Conclusions

This paper studied the knowledge graph reﬁnement problem

and proposed BioGRER to combine the advantages of sup-

porting and negating-like logic rules and graph embedding

for triplet veriﬁcation. To jointly model these two clues, we

trained them alternatively with the variational EM algorithm.

To evaluate the effectiveness of BioGRER, we deﬁned the


poisoning triplet detection task and conducted experiments

for this task. Besides, we conducted experiments on a stan-

dard knowledge graph completion task. Experimental results

on both tasks demonstrated that our model could signiﬁcantly

outperform competitive baselines. Furthermore, BioGRER

only utilized the information of the BioKG itself instead of

external evidence resources. Therefore, our model can be

incremented by adding external evidence resources for better

performance.

References

Sally H Adams, M Jane Park, Jason P Schaub, Claire D

Brindis, and Charles E Irwin Jr.

Medical vulnerability

of young adults to severe covid-19 illness—data from the

national health interview survey.

Journal of Adolescent

Health, 2020.

Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran,

Jason Weston, and Oksana Yakhnenko.

Translating

embeddings for modeling multi-relational data.

In

Advances in neural information processing systems, pages

2787–2795, 2013.

Ermei Cao, Difeng Wang, Jiacheng Huang, and Wei Hu.

Open knowledge enrichment for long-tail entities.

In

Proceedings of The Web Conference 2020, pages 384–394,

2020.

Chris R Cardwell, Christian C Abnet, Marie M Cantwell, and

Liam J Murray. Exposure to oral bisphosphonates and risk

of esophageal cancer. JAMA, 304(6):657–663, 2010.

Jiaoyan Chen, Xi Chen, Ian Horrocks, Erik B. Myklebust,

and Ernesto Jimenez-Ruiz.

Correcting knowledge base

assertions. In Proceedings of The Web Conference 2020,

pages 1537–1547, 2020.

Q Chen, A Allot, and Z Lu.

Keep up with the latest

coronavirus research. Nature, 579(7798):193, 2020.

Luc De Raedt and Kristian Kersting. Probabilistic inductive

logic programming.

In Probabilistic Inductive Logic

Programming, pages 1–27. Springer, 2008.

Tim Dettmers, Minervini Pasquale, Stenetorp Pontus, and

Sebastian Riedel.

Convolutional 2d knowledge graph

embeddings. In Proceedings of the 32th AAAI Conference

on Artiﬁcial Intelligence, pages 1811–1818, February

2018.

Boyang Ding, Quan Wang, Bin Wang, and Li Guo.

Improving knowledge graph embedding using simple

constraints. In Proceedings of the 56th Annual Meeting

of the Association for Computational Linguistics, pages

110–121, Melbourne, Australia, 2018. Association for

Computational Linguistics.

Valeria Fionda and Giuseppe Pirr`o.

Fact checking via

evidence patterns. In Proceedings of the 27th International

Joint Conference on Artiﬁcial Intelligence, pages 3755–

3761, 2018.

Mohamed H Gad-Elrab, Daria Stepanova, Jacopo Urbani, and

Gerhard Weikum.

Exfakt: A framework for explaining

facts over knowledge graphs and text. In Proceedings of

the Twelfth ACM International Conference on Web Search

and Data Mining, pages 87–95, 2019.

Mohamed H Gad-Elrab, Daria Stepanova, Jacopo Urbani, and

Gerhard Weikum.

Tracy: Tracing facts over knowledge

graphs and text. In The World Wide Web Conference, pages

3516–3520, 2019.

Zoubin Ghahramani, Matthew J Beal, et al. Graphical models

and variational methods. Advanced mean ﬁeld methods-

theory and practice. MIT Press, 2000.

Jane Green, Gabriela Czanner, Gillian Reeves, Joanna

Watson, Lesley Wise, and Valerie Beral.

Oral bisphos-

phonates and risk of cancer of oesophagus, stomach, and

colorectum: case-control analysis within a uk primary care

cohort. BMJ, 341, 2010.

Shu Guo, Quan Wang, Lihong Wang, Bin Wang, and Li Guo.

Knowledge graph embedding with iterative guidance from

soft rules.

In Proceedings of the Thirty-Second AAAI

Conference on Artiﬁcial Intelligence, 2018.

Furong Li, Xin Luna Dong, Anno Langen, and Yang Li.

Knowledge veriﬁcation for long-tail verticals. Proceedings

of the VLDB Endowment, 10(11):1370–1381, 2017.

Peng Lin, Qi Song, and Yinghui Wu.

Fact checking in

knowledge graphs with ontological subgraph patterns.

Data Science and Engineering, 3(4):341–358, 2018.

Peng Lin, Qi Song, Yinghui Wu, and Jiaxing Pi. Discovering

patterns for fact checking in knowledge graphs. Journal of

Data and Information Quality (JDIQ), 11(3):1–27, 2019.

Maximilian Nickel, Kevin Murphy, Volker Tresp, and

Evgeniy Gabrilovich.

A review of relational machine

learning for knowledge graphs. Proceedings of the IEEE,

104(1):11–33, 2015.

Maximilian Nickel, Lorenzo Rosasco, and Tomaso Poggio.

Holographic embeddings of knowledge graphs.

In

Proceedings of the Thirtieth AAAI Conference on Artiﬁcial

Intelligence, February 12-17, 2016, Phoenix, Arizona,

USA, pages 1955–1961. AAAI Press, 2015.

Meng Qu and Jian Tang. Probabilistic logic neural networks

for reasoning.

In Advances in Neural Information

Processing Systems, pages 7712–7722, 2019.

Matthew Richardson and Pedro Domingos.

Markov logic

networks. Machine learning, 62(1-2):107–136, 2006.

Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, and Jian Tang.

Rotate: Knowledge graph embedding by relational rotation

in complex space.

In 7th International Conference on

Learning Representations, ICLR 2019, New Orleans, LA,

USA, May 6-9, 2019, 2019.

Th´eo Trouillon, Johannes Welbl, Sebastian Riedel, ´Eric

Gaussier, and Guillaume Bouchard. Complex embeddings

for simple link prediction.

In Proceedings of the

33nd International Conference on Machine Learning,

ICML 2016, New York City, NY, USA, June 19-24,

2016, volume 48 of JMLR Workshop and Conference

Proceedings, pages 2071–2080. JMLR.org, 2016.


Giuliana Viglione.

How many people has the coronavirus

killed? Nature, 585(7823):22–24, 2020.

Lucy Lu Wang, Kyle Lo, Yoganand Chandrasekhar, Russell

Reas, Jiangjiang Yang, Darrin Eide, Kathryn Funk, Rodney

Kinney, Ziyang Liu, William Merrill, et al. Cord-19: The

covid-19 open research dataset. ArXiv, 2020.

Yu-Tao Xiang, Wen Li, Qinge Zhang, Yu Jin, Wen-Wang

Rao, Liang-Nan Zeng, Grace KI Lok, Ines HI Chow, Teris

Cheung, and Brian J Hall. Timely research papers about

covid-19 in china. The Lancet, 2020.

Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and

Li Deng.

Embedding entities and relations for learning

and inference in knowledge bases.

In 3rd International

Conference on Learning Representations, ICLR 2015,

San Diego, CA, USA, May 7-9, 2015, Conference Track

Proceedings, 2015.

