


Published in

Towards Data Science



Aug 18, 2020

·

8 min read

Save

Markov and Hidden Markov Model

Elaborated with examples

Fig.1. Stochastic Process — Image by Author

stochastic process

stochastic process

index set 

state space

stochastic process 

stochastic process 

Discrete Time.

Stochastic Model

discrete-time process

states

(S) ={hot , cold }

z� S_T

{z1=hot, z2 =cold, z3 =cold, z4 =hot}








Markov Assumptions

Limited Horizon assumption

Eq.1. Limited Horizon Assumption

t

Stationary Process Assumption

Eq.2. Stationary Process Assumption

Notation Convention

State Transition Matrix


Fig.2. State Transition Matrix —Image by Author

Two Main Questions in Markov-model

Probability of particular sequences

Eq.4. Finding probability of particular sequence

above(Fig.2.) 

Hidden Markov Model (HMM)

Markov model

Markov process

hidden

Markov Model

Hidden Markov Model

Assumptions of HMM

Output independence assumption

Eq.5.

Emission Probability Matrix

Hidden Markov Model as a finite state machine


Fig.3. Markov Model as Finite State Machine — Image by Author

observations

 hidden state 

Emission probabilities

Happy

Grumpy 

Emission probabilities

Transition probabilities

Transition probabilities.

Three important questions in HMM are

1. Probability of Observed Sequence

O(|S|)^T. 

Forward Procedure

Backward Procedure


Example using forward procedure

Fig.4. Given data as matrices — Image by Author

Fig.5. Generated Finite state machines for HMM — Image by Author

We first need to calculate the prior probabilities 

prior probabilities. 

1. For first observed output x1=v2

Fig.6. Step 1 — Image by Author

2. for observed output x2=v3

Fig.7. Step 2 — Image by Author

3. for observed output x3 and x4

Fig.8. Step 3 and 4 —Image by Author

2. Maximum likelihood assignment

Fig.9. Data for example 2 — Image by Author


Fig.10. Markov Model as a Finite State Machine from Fig.9. data —Image by Author

Viterbi algorithm

Fig.11. The Viterbi algorithm requires to choose the best path —Image by Author

Fig.12. Step-1 — Image by Author

Fig.13. Step-2 — Image by Author

Fig.14. Iterate the algorithm to choose the best path — Image by Author

3. Learn the values for the HMMs parameters A and B

Baum-Welch algorithm

Machine Learning


4



Follow

Your home for data science. A Medium publication sharing concepts, ideas and codes.



Read more from Towards Data Science





Computer Science

Time Series Model

Sequence Model

Hidden Markov Models

