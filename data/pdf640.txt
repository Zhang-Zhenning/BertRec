


Published in

Towards Data Science



Nov 4, 2020

·

7 min read

·

Save

LSTM vs BERT — a step-by-step guide for tweet

sentiment analysis

Can the state-of-the-art NLP model predict stock traders sentiment better than RNN?

Image by Author

Note from Towards Data Science’s editors:

Background








Tweet as input text

messages

sentiments

1. Preprocess


Preprocess an input message

2. Tokenize


3. Corpus and Vocab


Word Cloud image (Created by Author)

Most frequent words in the corpus (Created by Author)

Distribution of labels, letters and words (Created by Author)

Classification Model

4. LSTM

→

→

→

→


5. BERT


Training Process

6. Dataset


7. Sampling Cycle


8. Training the Neural Net Model


Train!

9. Run the LSTM model


Confusion Matrix (n=1,000, epoch=1) (Created by Author)

Evaluation result (n=1,000, epoch=5) (Created by Author)

Evaluation result (n=500,000, epoch=5) (Created by Author)

10. Run the BERT model


Evaluation result (n=500,000, epoch=5) (Created by Author)

11. Compare the result


Comparison of the performance between LSTM and BERT (Created by Author)

Conclusion

(Optional) Inference on Tweet Stream



1



Follow

Your home for data science. A Medium publication sharing concepts, ideas and codes.



Read more from Towards Data Science





NLP

AI

Machine Learning

Bert

Finance

