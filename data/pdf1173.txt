








Log in

Sign up

user53259



NLK511

101

1

6



anon

148k

12

220

382

Intuitively, why does Bayes' theorem work?

Asked 8 years, 1 month ago

Modified 3 years ago

Viewed 3k times

9

 

 

I'm not looking for a cryptic math demonstration. Rather, I'm interested in the intuition behind the theorem that reveals the a posteriori probability, given the prior probability × the likelihood.

Share

edited Dec 25, 2017 at 23:07

asked Mar 28, 2015 at 14:58

1

Would be helpful if you could be a little more "down to earth" here and give a concrete example rather than just "throwing questions in the air" (i.e., "Why does Bayes' theorem work in the following case...").

– barak manos

Mar 28, 2015 at 15:14

8 Answers

Sorted by:

11

 

Draw a Venn diagram to help you understand P(A|B) =P(A∩B)/P(B). Then use this to relate the quantities P(A|B) and P(B|A) algebraically. Let's discuss the first point.

Suppose we have a finite sample space so we can count the number outcomes in each possible "event." To determine P(A|B), we're essentially asking what the probability of getting an outcome in A is if we uniformly at random (for

simplicity) pick an outcome in event B.

For example, consider a collection of 100 objects. Say 64 are balls and 36 are blocks. Suppose further that among the balls, 24 are red balls and 40 are blue balls. If A is the event of being a red object (we don't know how many red

blocks there are, but it won't matter) and B is the event of being a ball, then P(A|B) is the probability of picking a red object given the fact that the object you picked was a ball, or equivalently of picking a red ball out of all of the

balls, which will equal the number of red balls divided by the number of balls, or P(A∩B)/P(B) =

24

64.

Now, given P(A|B)P(B) =P(A∩B) =P(B|A)P(A) it shouldn't be hard to finish.

Share

answered Mar 28, 2015 at 15:16

Thank you, this is very useful!

– NLK511

Mar 28, 2015 at 15:23

@NLK511: It also helps to draw the Venn diagram in a rectangular fashion, as one can see depicted in the answer of user2023861 below.

– Lee Mosher

Sep 16, 2015 at 15:29

4

 

 

The answers here are good, but if you're like me, you learn better with visual aids and actual numbers. I have one for Bayes's Theorem using the same testing idea. Here's the setup:

You have a population of 100,000 people

0.5% of this population use a drug

We have a test that tells us with 99% accuracy if a person is or is not a drug user

You tested positive for this drug. What are the odds that you're a user given this information?

Let's set this up in a simple grid:



In the columns, I show counts of users and non-users. We are told that 0.5% of the population of 100,000 use this drug, so there are 500 users and 99,500 non-users.

In the rows, I show counts of test results. I will fill in these values in a moment.

I've highlighted cells inside the table in a certain way:

Green cells are accurate test results. If a person is a user and the test result is positive, the test is accurate and the cell is green. Likewise, if a person is not a user and the test result is negative, the test is accurate and the cell is

green.

Red cells are inaccurate test results. If a person is a user but the test is negative, this is a false-negative and the cell is red. Likewise, if a person is not a user but the test is positive, this is a false-positive and the cell is red.

Ask Question

probability

intuition

bayes-theorem

Cite

Follow





Highest score (default)

Cite

Follow








user2023861

579

3

9



BruceET

50.7k

8

31

62

Let's start filling in the table. Given that we have 500 users, how many positive and negative test results will we have among this subset of the population? We're told the test is 99% accurate, so that's 495 positive results and 5 false-

negatives:



Following the same process for the non-users: given that we have 99,500 non-users, how many positive and negative results will we have among this subset of the population? Again, the test is 99% accurate, so that's 98,505

negative results and 995 false-positives.



Time to analyze the results. We're told that you tested positive for the drug, so let's throw out the results pertaining to negative test results and look at only the "Positive" row in the grid. 1,490 people tested positive for the drug, of

which 495 actually are users, and 995 are false-positives. From here it's easy, the probability that you're actually a user given that you're in the "Positive" row is 

495

1490 =33.2%

Turning this into a formula:

P(DrugUserGivenPositiveResult) =

P(DrugUser) ∗ N∗ TestAccuracy

P(DrugUser) ∗ N∗ TestAccuracy+P(NotDrugUser) ∗ N∗ (1−TestAccuracy)

This is exactly the formula I calculated to get 33.2%. Here, N is the 100,000 number that I made up. N cancels out and thus my 100,000 is extraneous information, but I thought it'd be helpful to include it.

With this grid I hope it's clear why, even with a test accuracy so high, your chances of actually being a drug user given a positive test result are so much lower. The number of false-positives is large enough to skew the naive intuition

of the result.

Share

edited Dec 29, 2017 at 14:14

answered Sep 16, 2015 at 15:14

@Canada-Area51Proposal, Thanks. Why did you make a recent edit to my answer? Your edits don't add or elucidate any parts of it. After your edits, we're left with some awkward sentences like In the rows, I show counts of test 

results that I will fill, after I explain how I highlighted the cells in a certain way  There are inconsistencies with how you refer to the four setup steps. And what's the point of changing Turning this into a formula  to This can be 

turned into a formula ? All that does is make the sentence passive. A highschool English teacher would scold you for that.

– user2023861

Dec 27, 2017 at 15:29

Sorry for any mistake. I corrected the 2 sentences in the blockquotes. I edited because some sentences appear redundant and repeated?

– user53259

Dec 28, 2017 at 1:08

4

@Canada Ultimately it's between you and the answerer, but I think you're well overstepping the norm of reasonable editing of someone else's answer.

– user856

Dec 28, 2017 at 1:12

3

 

 

The prior distribution and the likelihood function (based on data) both contain information about a parameter. Bayes' theorem allows these two kinds and sources of information to put together into a posterior distribution. The

combined information from the posterior distribution can be used make inferences about the parameter. A couple of examples illustrate this process.

Screening test for a disease. Suppose we wonder whether a particular person has a disease. The prevalence in the population to which the subject belongs is 2%, so this can be considered as our prior information about the subject.

P(Subj has Disease) = .02. A quick and inexpensive,, but imperfect, screening test for the disease is available. Its characteristics are described in conditional probabilities: P(Pos test | Dis) = .99, P(Neg test | No Dis) = .97. Suppose our

data is that the subject tests positive.

Then using the elementary form of Bayes' Theorem we can find the posterior probability P(Dis | Pos test) = 0.4024. Some people, focusing on P{Pos test | Dis} = .99) are surprised the posterior probability is so small.

However, the appropriate focus for our purposes is that the data (positive test result) has gone together with the prior probability of 0.02 to give us a posterior probability about 0.40. The screening test is imperfect, but data from it

has made a considerable change in our assessment of the subject's probability of disease. A subject with a 40% chance of having a serious disease should be evaluated with further and perhaps more time consuming and expensive tests.

Public Opinion Poll. A newly hired consultant for a political campaign to elect Candidate A feels that the candidate will win, but not overwhelmingly. Suppose her prior distribution on the probability ψ of winning is 

Beta(330,270), which has mean 0.55 and 95% of its probability in the interval (0.51,0.59). Then a poll of 1000 randomly selected potential voters shows 620 of them in favor of Candidate A. This is our data and it is reflected in

the binomial likelihood function with kernel ψ620(1−ψ)380.

Bayes' Theorem melds the prior distribution with the likelihood function encoding the data to give the posterior distribution Beta(950,650), where multiplying the prior by the likelihood gives the posterior beta parameters 

330+620 =950 and 270+380 =650. The posterior beta distribution has mean about 0.59 and puts about 95% of its probability in the interval (0.57,0.62), which we take as our posterior probability interval for ψ, a somewhat

more optimistic outlook for the candidate than given by the prior.

Here again, the information in the prior distribution and the data (as reflected in the likelihood function) have been combined to give a posterior distribution. Very roughly speaking, it is as if the consultant's prior distribution

contributed information equivalent to that in a poll of 600 prospective voters of whom 330 favored the candidate.

Note: I have chosen these two examples, so that the math (if you care to carry it through) is quite simple. In some cases, much more computational effort is required to find and use the posterior distribution. But the computation

needs to be viewed as a means to an end: to combine the information in the prior with the information in the data in order to make inferences based on both.

Acknowledgment: Numbers and distributions in these examples are the same as for ones in Ch 5 &amp; 8, respectively, of Suess and Trumbo (2010), Springer.

Share

edited Mar 28, 2015 at 16:35

answered Mar 28, 2015 at 16:29

2

 

 

Start with an example. Say you have a test that discovers some disease. Even if a person tests positive for the disease, all is not lost, since the test may not be accurate.

What are the person's chances of actually having the disease? There are three factors involved:

1. What are the overall chances of contracting the disease? It would be very unlikely for townsfolk of some small town in Europe who never left it to contract Ebola for instance, irrespective of the test results.

2. What is the test accuracy: Given that a person has the disease, what are the chances that you test positive?

3. What is the test accuracy II: How often does the test give positive results? If it almost always gives a negative result, but in your patient's case it gave a positive result, maybe you should be worried.

Combining these factors gives us Bayes's theorem - Factors 1 and 2 increase the probability and should therefore be multiplied, while Factor 3 decreases the probability, and should be divided:

Cite

Follow



Cite

Follow






user53259



nbubis

32.4k

10

80

138

user53259

P(Is Sick|Pos. Test) =

P(Pos. Test|Is Sick) ⋅ P(Is Sick)

P(Pos. Test)

Share

edited May 29, 2017 at 5:16

answered Mar 28, 2015 at 15:27

nice explanation, thanks a lot :)

– NLK511

Mar 28, 2015 at 15:31

2

 

 

It helps to disambiguate the meaning of "accuracy" more precisely like this Reddit comment, in which there's a typo: "1485" (in "out of 1485 people who test positive") ought be "1495". I rewrote it with whole numbers (rather than

0.5% as the disease rate).

To understand the theorem, you need to understand the vocabulary. "99% accurate" doesn't really give us information about the disease. We ought use the following terms:

Sensitivity - the odds that the test will be positive if you have the disease.

Specificity - the odds that the test will be negative if you lack the disease.

Positive predictive value - the odds that the test will correctly predict you have the disease, if you test positive.

Negative predictive value - the odds that the test will correctly predict you lack the disease, if you test negative.

Our population of 10,000 people has a 1% disease rate. So 1000 people have the disease, and 99,000 don't.

We introduce a test that is 98% sensitive and 99% specific. It will correctly identify 980 of 1000 people with the disease and 98,010 of 99,000 without the disease. It will incorrectly claim 20 people ( =1000−980) with the disease

don't have it, and 990 people ( =99,000−98,010) without the disease have it.

So out of 1970 ( =980+990) people who test positive, 980 have the disease. Thus, our positive predictive value is 

1000

1970 =50.76%.

Out of 98,030 ( =98,010+20) who test negative, 99,000 do not have the disease. Thus, our negative predictive value is 

98,030

99,000 =99.02%.

In this case, this test is first-rate for determining who lacks the disease. The 1970 who test positive can be tested to confirm they do have the disease, whereas those who tested negative need no further tests.

Share

answered Jan 22, 2019 at 1:25

1

 

 

Medium Aug 7 2015 article explains with many pictures! 1 in 10 people are sick.



To simplify the example, we assume we know which ones are sick and which ones are healthy, but in a real test you don’t know that information. Now we test everybody for the disease:

Cite

Follow



Cite

Follow






user53259



The true positives = number of positive results among the sick population = #(Positive | Sick) = 9.

Now the interesting question, what's probability of being sick if you test positive? In math, Pr (Sick|Positive)?



Share

edited Apr 16, 2020 at 14:47

answered Apr 16, 2020 at 14:40

1

 

 

This Jan 10 2020 article on Medium can explain with just one picture!

A rare disease infects only 1/1000 people.

Tests identify the disease with 99% accuracy.

Cite

Follow






user53259



CopyPasteIt

11k

1

20

43



If there are 100,000 people, 100 people who have the rare disease and the rest 99,900 don’t have it. If these 100 diseased people get tested, 99 would test positive and 1 test negative. But what we generally overlook is that if the

99,900 healthy get tested, 1% of those (that is 999) will test false positive.

Now, if you test positive, for you to have the disease, you must be 1 of the 99 diseased people who tested positive. The total number of persons who tested positive is 99+999. So the probability that you have the disease when you

tested positive is 

99

99+999 =0.0901.

Share

answered Apr 16, 2020 at 14:53

0

 

 

There are many professions where useful probability estimates are made without explicitly employing Bayes's formula, although the 'calculations' are still all about changing estimates given new information. If you believe in this,

then you can accept that a math model can also accurately be employed in some situations.

Example 1: A specialist has been working for almost a year with a patient that has a serious form of cancer. The doctor now estimates that the patient has only a 10% chance of living more than a month. He shares the diagnosis

and advises the patient that he can't recommend any further aggressive treatments. So, throughout his interactions with his patient, the specialist observed how events unfolded and was able to make 'soft assessment/estimates' while

trying several treatments.

Example 2: A detective is meeting with a murder suspect. From his experience, he asks the suspect an indirect question that could shed light on the investigation. He knows that certain 'weird' responses will bring things into sharper

focus. The suspect comes up with an offbeat response that the detective figures an innocent person couldn't even come up with. Yes, just circumstantial evidence, but the detective now has a prime suspect.

Share

answered Dec 26, 2017 at 1:39

You must log in to answer this question.

Not the answer you're looking for? Browse other questions tagged probability

intuition

bayes-theorem .

Linked

9

Why do knowers of Bayes's Theorem still commit the Base Rate Fallacy?

3

What is the intuition or proof behind the conditional Bayes' theorem?

0

Intuition behind Bayes' Theorem

0

For the same Conditional Probability, why does Bayes's Theorem differ from a direct calculation?

Related

1

Bayes theorem with infinitesimal evidence

11

Why do we refer to the denominator of Bayes' theorem as "marginal probability"?

0

Bayes Theorem: what is wrong in using counts instead, intuitively.

0

Help simplifying Bayes' theorem for multiple conditions

0

Bayes theorem, confusion between P(X|Z) and P(Z|X)

0

Cite

Follow



Cite

Follow



Featured on Meta



Improving the copy in the close modal and post notices - 2023 edition



New blog post from our CEO Prashanth: Community is the future of AI




MATHEMATICS

Tour

Help

Chat

Contact

Feedback

COMPANY

Stack Overflow

Teams

Advertising

Collectives

Talent

About

Press

Legal

Privacy Policy

Terms of Service

Cookie Settings

Cookie Policy

STACK EXCHANGE NETWORK

Technology

Culture &amp; recreation

Life &amp; arts

Science

Professional

Business

API

Data

Blog

Facebook

Twitter

LinkedIn

Instagram

Site design / logo © 2023 Stack Exchange Inc; user contributions licensed under CC BY-SA. rev 2023.4.21.43403

Bayes' Theorem Application Question

Hot Network Questions



What does the power set mean in the construction of Von Neumann universe?



Can someone explain why this point is giving me 8.3V?



What was the actual cockpit layout and crew of the Mi-24A?



If total energies differ across different software, how do I decide which software to use?



Led bulb wattage for ikea lamp

more hot questions

 Question feed

Your privacy

By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.

 

Accept all cookies

Necessary cookies only

Customize settings

