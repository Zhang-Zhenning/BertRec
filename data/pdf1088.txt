
Background

Contour maps

Gradient

Local maxima and minima

What we're building to:

The Lagrange multiplier technique lets you find the maximum or minimum of a multiva

when there is some constraint on the input values you are allowed to use.

This technique only applies to constraints that look something like this:

g(x,y,… )=c \redE{g(x, y, \dots) = c} g(x,y,…) = c

Here, g\redE{g}g is another multivariable function with the same input space as 

The core idea is to look for points where the contour lines of f\blueE{f}f and g

This is the same as finding points where the gradient vectors of f\blueE{f}f and 

The entire process can be boiled down into setting the gradient of a certain function

Motivating example

Suppose you want to maximize this function:

f(x,y)=2x+y \blueE{f(x, y) = 2x + y} f(x,y) = 2x+ y

Lagrange multipliers, int

Google Classroom

The "Lagrange multipliers" technique is a way to solve co

 Super useful!

[Picture]

[Specifically...]



Multivariable calculus



COURSE: MULTIVARIABLE CALCULUS &gt; UNIT 3

Lesson 6: Constrained optimization

(articles)

Lagrange multipliers, introduction

Lagrange multipliers, examples

Interpretation of Lagrange multipliers

Math &gt; Multivariable calculus &gt; Applications

of multivariable derivatives &gt; Constrained

optimization (articles)

© 2023 Khan Academy

Terms of use

Privacy Policy

Cookie Notice








Plot of the function f(x,y)=2x+yf(x, y) = 2x+yf(x,y) = 2x+ y

Plot of the function f(x,y)=2x+yf(x, y) = 2x+yf(x,y) = 2x+ y

But let's also say you limited yourself to inputs (x,y)(x, y)(x,y) which satisfy the follow

x2+y2=1 \redE{x^2 + y^2 = 1} x2 + y2 = 1

Unit circle

All points (x,y)(x, y)(x,y) satisfying x2+y2=1\redE{x^2 + y^2 = 1}x2 + y2 = 1, also know

In other words, for which point (x,y)(x, y)(x,y) on the unit circle\redE{\text{unit circle}}

This is what's known as a constrained optimization problem. The restriction to po

called a "constraint", and f(x,y)=2x+y\blueE{f(x, y) = 2x + y}f(x,y) = 2x+ y is the functio

Here's one way to visualize this: First draw the graph of f(x,y)\blueE{f(x, y)}f(x

Next, project the circle x2+y2=1\redE{x^2 + y^2 = 1}x2 + y2 = 1 from the xyxyxy

are seeking corresponds with the highest point of this projected circle on the graph.


More general form

In general, constrained optimization problems involve maximizing/minimizing a multiva

dimensions:

f(x,y,z,… )\blueE{f(x, y, z, \dots)}f(x,y,z,…)

Its output will always be one-dimensional, though, since there's not a clear notion of 

The type of constraints that the Lagrange multiplier technique applies to must take t

g(x,y,z,… )\redE{g(x, y, z, \dots)}g(x,y,z,…) being set equal to a constant c\redE{c}

g(x,y,z,… )=c\redE{g(x, y, z, \dots) = c}g(x,y,z,…) = c

Since this is meant to be a constraint on the input of f\blueE{f}f, the number of dimen

f\blueE{f}f. For example, the example outlined above fits this general form as follows

f(x,y)=2x+y\blueE{f(x, y) = 2x+y}f(x,y) = 2x+ y

g(x,y)=x2+y2\redE{g(x, y) = x^2 + y^2}g(x,y) = x2 + y2

c=1\redE{c = 1}c = 1

Using contour maps

Reasoning about this problem becomes easier if we visualize f\blueE{f}f not with a gr

As a reminder, a contour line of f(x,y)\blueE{f(x, y)}f(x,y) is the set of all points where

The following interactive tool shows how this line (drawn in blue) changes as the con

g(x,y)=1\redE{g(x, y) = 1}g(x,y) = 1 is also shown (in red). Try to make kkk as big/sm

to intersect the circle.

Concept check: What does it mean if for a particular value of kkk, the blue line rep

intersect the red circle representing g(x,y)=1\redE{g(x, y) = 1}g(x,y) = 1?

Choose 1 answer:

Choose 1 answer:

See video transcript

[Multiple constraints]

(Choice A)  

There are no values of xxx and yyy satisfying both 2x+y=k\blueE{2x + y = k}2x+

There are no values of xxx and yyy satisfying both 2x+y=k\blueE{2x + y = k}2x

A


Notice, the circle where g(x,y)=1\redE{g(x, y) = 1}g(x,y) = 1 can be thought of as a pa

that, here's the clever way to think about constrained optimization problems:

Key observation: The maximum and minimum values of f\blueE{f}f, subject to the c

with contour lines of f\blueE{f}f that are tangent to the contour representing 

Constrained extrema are tangent.

If f\blueE{f}f were a different function, its contours might not always be straight lines.

For example, take a look at this function:

f(x,y)=2x2+5y\blueE{f(x, y) = 2x^2 + \sqrt{5y}}f(x,y) = 2x2 +

5y

Its contour lines look like this:

That said, the key observation still holds, and is worth repeating: When kkk is a max

contour line for f(x,y)=k\blueE{f(x, y) = k}f(x,y) = k will be tangent to contour represen

Where the gradient comes into play

How do you put the idea of two contour lines being tangent into a formula you can so

To answer this, we turn to our loyal friend the gradient. There are many ways to inte

for computing directional derivatives, etc. But for our purposes here, the property we

point (x0,y0)(x_0, y_0)(x0​,y0​) always gives a vector perpendicular to the con

Gradient vectors are perpendicular to contour lines.

This means when the contour lines of two functions f\blueE{f}f and g\redE{g}

might look like for arbitrary functions f\blueE{f}f and g\redE{g}g:

Check

(Choice B)  

The given optimization problem has no solutions.

The given optimization problem has no solutions.

B






















Wikipedia image of tangent contour lines

The fact that contour lines are tangent tells us nothing about the magnitude of each 

vectors point in the same direction, it means we can multiply one by some constant t

represent a particular point where the contour lines of f\blueE{f}f and g\redE{g}

subscripts just indicates that we are considering constant values, and hence a speci

vectors align, here's what you might write down:

�f(x0,y0)=λ0�g(x0,y0)\begin{aligned} \nabla \blueE{f(x_0, y_0)} = \greenE{\lambda}

Here, λ0\greenE{\lambda}_0λ0​ represents some constant. Some authors use a nega

personally prefer a positive constant, as it gives a cleaner interpretation of λ0

Let's see what this looks like in our example where f(x,y)=2x+y\blueE{f(x, y) = 2x + y}

g(x,y)=x2+y2\redE{g(x, y) = x^2 + y^2}g(x,y) = x2 + y2. The gradient of fff is

�f(x,y)=[∂∂x(2x+y)∂∂y(2x+y)]=[21]\begin{aligned} \nabla f(x, y) = \left[ \begin{array}{c

and the gradient of ggg is

�g(x,y)=[∂∂x(x2+y2−1)∂∂y(x2+y2−1)]=[2x2y]\begin{aligned} \nabla g(x, y) = \left[ 

Therefore, the tangency condition ends up looking like this:

[21]=λ0[2x02y0]\begin{aligned} \left[ \begin{array}{c} 2 \\ 1 \end{array} \right] = 

Solving the problem in the specific case

To sum up where we are so far, we are looking for input points (x0,y0)(x_0, y_0)

g(x0,y0)=1g(x_0, y_0) = 1g(x0​,y0​) = 1, which for our example means

x02+y02=1\quad \redE{x_0^2 + y_0^2 = 1}

x02​ + y02​ = 1

�f(x0,y0)=λ0�g(x0,y0)\nabla f(x_0, y_0) = \greenE{\lambda_0} \nabla g(x_0, y_0)

λ0\greenE{\lambda_0}λ0​, which for our example means

2=2λ0x01=2λ0y0\begin{aligned} \quad {2} &amp;{= 2\greenE{\lambda_0} x_0} \\ {1} &amp;{= 2

There are 333 equations and 333 unknowns, so this is a perfectly solvable situation

The Lagrangian function

Picture of Lagrange

Joseph Louis Lagrange, looking peaceful, content, and sleepy, all at the same time. 

In the 1700's, our buddy Joseph Louis Lagrange studied constrained optimization pr

all of our conditions into a single equation.

You can write these conditions generally by saying we are looking for constants 

following conditions:

The constraint:

g(x0,y0)=c\redE{g(x_0, y_0) = c}g(x0​,y0​) = c

The tangency condition:

[See the final solution]


























The tangency condition:

�f(x0,y0)=λ0�g(x0,y0)\nabla f(x_0, y_0) = \lambda_0 \nabla g(x_0, y_0)�f(x

This can be broken into its components as follows:

fx(x0,y0)=λ0gx(x0,y0){f_x(x_0, y_0) = \lambda_0 g_x(x_0, y_0)}fx​(x0​,y0​) = λ0

fy(x0,y0)=λ0gy(x0,y0){f_y(x_0, y_0) = \lambda_0 g_y(x_0, y_0)}fy​(x0​,y0​) = λ0

Lagrange wrote down a special new function which takes in all the same input variab

λ\lambdaλ, thought of now as a variable rather than a constant.

L(x,y,λ)=f(x,y)−λ(g(x,y)−c) \mathcal{L}(x, y, \lambda) = \blueE{f(x, y)} - \lambda (\redE

For example, consider our example above.

f(x,y)=2x+yg(x,y)=x2+y2c=1\begin{aligned} \quad \blueE{f(x, y)} &amp;= \blueE{2x + y }\\ 

Here's how this new function would look:

L(x,y,λ)=2x+y−λ(x2+y2−1). \mathcal{L}(x, y, \lambda) = \blueE{2x + y} - \lambda(\redE

Notice, the partial derivative of L\mathcal{L}L with respect to λ\lambdaλ is −(g

Lλ(x,y,λ)=∂∂λ(f(x,y)−λ(g(x,y)−c)=0−(g(x,y)−c)\begin{aligned} \quad \mathcal{L}_\lamb

So we can translate the condition g(x,y)=cg(x, y) = cg(x,y) = c as

Lλ(x,y,λ)=−g(x,y)+c=0\begin{aligned} \quad \redE{ \mathcal{L}_\lambda(x, y, \lambda

What's more, look at what we get when we set one of the other partial derivatives eq

Lx(x,y,λ)=0∂∂x(f(x,y)−λ(g(x,y)−c))=0fx(x,y)−λgx(x,y)=0fx(x,y)=λgx(x,y)\begin{aligned} \q

That just so happens to be another one of our conditions! Almost identically, the con

Ly(x,y,λ)=0\mathcal{L}_y(x, y, \lambda) = 0Ly​(x,y,λ) = 0 unravels to become

fy(x,y)=λgy(x,y)\begin{aligned} \quad {f_y(x, y) = \lambda g_y(x, y)} \end{aligned}

Together, these conditions are the same as saying.

�f(x,y)=λ�g(x,y)\begin{aligned} \quad \nabla f(x, y) = \lambda \nabla g(x, y) \end{alig

Therefore, the three conditions we need to solve to find x,yx, yx,y and λ\lambda

being equal to 000. This can be written extremely compactly by setting the gradient o

�L=0\begin{aligned} \quad \nabla \mathcal{L} = \textbf{0} \end{aligned}

�L

For example, using our specific functions from above, we see how this encodes the s

�L=[∂∂x(2x+y−λ(x2+y2−1))∂∂y(2x+y−λ(x2+y2−1))∂∂λ(2x+y−λ(x2+y2−1))]=[2−2

As a tribute to ol' Joey Lou, we call this function L\mathcal{L}L the "Lagrangian

"Lagrange multiplier". Imagine if someone added "-ian" the end of your last name 

sweet!

Warning: Some authors use a convention where the sign of λ\lambdaλ is reversed:

L(x,y,λ)=f(x,y)+λ(g(x,y)−c)\begin{aligned} \quad \mathcal{L}(x, y, \lambda) = f(x, y) \re

This doesn't make any difference when it comes to solving the problem, but you sho

the text you are reading follows this convention.

Summary

[What if the constraint isn't so constraining]










Constrained optimization

Image credit: By Nexcis (Own work) [Public domain], via Wikimedia Commons

When you want to maximize (or minimize) a multivariable function f(x,y,… ) \blueE{f(x

multivariable function equals a constant, g(x,y,… )=c\redE{g(x, y, \dots) = c}g

Step 1: Introduce a new variable λ\greenE{\lambda}λ, and define a new function 

L(x,y,…,λ)=f(x,y,… )−λ(g(x,y,… )−c) \mathcal{L}(x, y, \dots, \greenE{\lambda}) = \blue

This function L\mathcal{L}L is called the "Lagrangian", and the new variable 

Step 2: Set the gradient of L\mathcal{L}L equal to the zero vector.

�L(x,y,…,λ)=0←Zero vector \nabla \mathcal{L}(x, y, \dots, \greenE{\lambda}) = \textb

In other words, find the critical points of L\mathcal{L}L.

Step 3: Consider each solution, which will look something like (x0,y0,…,λ0)(x_0, y_0

into fff. Or rather, first remove the λ0\greenE{\lambda}_0λ0​ component, then plug it 

input. Whichever one gives the greatest (or smallest) value is the maximum (or minim

Questions

Tips &amp; Thanks

Want to join the convers

Log in

Sort by:



Top Voted



alimuldal

7 years ago

In the final "side note" example graph, the equa

= 0, not x + y = 0

•

Answer Comment



Sam

7 years ago

Why is that the maximum or minimum value for 


Why is that the maximum or minimum value for 

and g are tangent? How did you prove it more r

•

Answer Comment



Dahn Jahn

7 years ago

I won't prove this, but imagine them not being

contours cross the constraint at some point. 

always shift the contour to a higher (or lower,

minimising) level and still be crossing the con

any higher is precisely at the level where they

This is all assuming we have well-behaved fu

3 comments



Zaz Brown

7 years ago

“There's a slight twist to this story, best illustrate

•

Answer Comment



Molly Swenson

7 years ago

Use the method of Lagrange Multipliers to dete

= x + y + z subject to the two conditions g(x,y,z) 

0

•

Answer Comment



Alexander Wu

6 years ago

We haven't learned about multiple constraints

constraints is ℒ(x1,x2,...,xn,λ1,λ2,...,λM) = f(x1

the function to be maximized and g1, g2, ..., g

1 to M). Note that here we use gk(x) = 0 inste

We take the three gradients and get �f = 

+ λ2�h, and g = h = 0, so we get: 1 = 2xλ1 + 

- 1 = 0. We see that λ2 = 1, so 2xλ1 = 0. bec

y = +-√2, and λ1 = +-√2/4, and z = 1.

So we get two solutions: (0,√2,1) and (0,-√2,

maximum.

If you can graph this, try it, and you'll see how

work the answers are on the y-z plane!

Comment



Kevin

6 years ago

Hi, thanks for the article. Question ... how does 

lines are tangent to each other? Parallel gradie

functions don't touch right? Thank you.

•

Answer Comment



Alexander Wu




Alexander Wu

6 years ago

Actually, parallel gradients tell us that the con

tangent when they are both touching and para

we had to answer the question "Where are th

contour lines are different at every point.

Therefore, the gradients of the two functions 

�f(0,1) being parallel to �g(1,0) wouldn't be 

�g(0,1).

Of course, this says nothing about where the 

gradients (slants or tilts) are. In fact, it doesn'

are restricting g to g(x,y) = c, and c may be a

g(x,y) = x + y and c = 4, or we can let g(x,y) = 

and c = 104. So how "high" g is doesn't matt

we need.

Of course, sometimes you might be required

"height" of g doesn't matter.

Comment



PTNLemay

3 years ago

What does it mean when you have more than o

equations, 5 unknowns, but the answer you get 

as a nice scalars? For example lambda ends u

•

Answer Comment



Yvan Ou

5 months ago

Hello,

In the chapter explaining When the gradient co

g(x, y) formula (we have x² + y² - 1 instead of x² 

Why do we insert the constraint -1 when compu

•

Answer Comment



Isaac

5 months ago

At that phase in the lesson, I think there is no

gradient there). The problem is that the latter

function multiplied with a Lagrange multiplier

λg with respect to λ to be g = function − c so 

returns the constraint function = c, the consta

Comment



Alexander Wu

7 years ago

The contour graph for f(x,y) = 2x^2 + √(5y) does

(0,2). It should equal √10, yet in the contour gra

f(2,3) should be 8 + √15, about 12, but on the p














f(2,3) should be 8 + √15, about 12, but on the p

I think there is a bug in the program that display

solve the equation, you get roots that weren't th

sides of x = √2, you get x^2 = 2, so x = +-√2. Th

the program.

I graphed the function with my calculator and the

But then, f is a function, so the can only be one 

plot above doesn't seem right.

•

Answer Comment



mausamsion

3 years ago

Hi, in the section "More general form" of Lagr

"Its output will always be one-dimensional, tho

"maximum" with vector-valued outputs."

Although we can have notion of maximum 

Then why the Lagrangian is defined only for 1-D

•

Answer Comment



umraoshikha222

6 years ago

What if there is more than one constraint equat

function

•

Answer Comment













































Smitha Mahesh

5 years ago

You would take del f= (lambda 1)(del g) + (la

equations carefully to find lambda 1 and 2 an

Comment

Show more comments

