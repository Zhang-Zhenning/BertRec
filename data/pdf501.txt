


Markov and Hidden Markov Model

·

Published in

Towards Data Science

8 min read

·

Aug 18, 2020

Listen

Share

Fig.1. Stochastic Process — Image by Author

stochastic process

stochastic

process

index set 

state space

stochastic process 

stochastic process 

Discrete Time.

Stochastic Model

discrete-time process

states

(S) ={hot , cold }

z� S_T

{z1=hot, z2 =cold, z3 =cold, z4

=hot}








Markov Assumptions

Limited Horizon assumption

Eq.1. Limited Horizon Assumption

t

Stationary Process Assumption

Eq.2. Stationary Process Assumption

Notation Convention

State Transition Matrix

Fig.2. State Transition Matrix —Image by Author


Two Main Questions in Markov-model

Probability of particular sequences

Eq.4. Finding probability of particular sequence

above(Fig.2.) 

Hidden Markov Model (HMM)

Markov model

Markov process

hidden

Markov Model

Hidden Markov Model

Assumptions of HMM

Output independence assumption

Eq.5.

Emission Probability Matrix

Hidden Markov Model as a finite state machine


Fig.3. Markov Model as Finite State Machine — Image by Author

observations

 hidden

state 

Emission probabilities

Happy

Grumpy 

Emission probabilities

Transition probabilities

Transition probabilities.

Three important questions in HMM are

1. Probability of Observed Sequence

O(|S|)^T. 

Forward Procedure

Backward Procedure


Example using forward procedure

Fig.4. Given data as matrices — Image by Author

Fig.5. Generated Finite state machines for HMM — Image by Author

We first need to calculate the prior probabilities 

prior

probabilities. 

1. For first observed output x1=v2

Fig.6. Step 1 — Image by Author

2. for observed output x2=v3

Fig.7. Step 2 — Image by Author

3. for observed output x3 and x4

Fig.8. Step 3 and 4 —Image by Author

2. Maximum likelihood assignment

Fig.9. Data for example 2 — Image by Author


Fig.10. Markov Model as a Finite State Machine from Fig.9. data —Image by Author

Viterbi algorithm

Fig.11. The Viterbi algorithm requires to choose the best path —Image by Author

Fig.12. Step-1 — Image by Author

Fig.13. Step-2 — Image by Author

Fig.14. Iterate the algorithm to choose the best path — Image by Author

3. Learn the values for the HMMs parameters A and B

Baum-Welch algorithm


4



Follow



194 Followers

·

Writer for 

Towards Data Science

Engineer (Grad from UoM) | Software Engineer @WSO2



Machine Learning

Computer Science

Time Series Model

Sequence Model

Hidden Markov Models






Simple Search Engine with Elastic Search

·



Zero-ETL, ChatGPT, And The Future of Data Engineering

·






The Portfolio that Got Me a Data Scientist Job

·

·






How does Self Organizing Algorithm works?

·

See all from Vivekvinushanth Christopher

·

See all from Towards Data Science






You’re Using ChatGPT Wrong! Here’s How to Be Ahead of 99% of ChatGPT Users

·

·






The Portfolio that Got Me a Data Scientist Job

·

·






How To Build Your Own Custom ChatGPT With Custom Knowledge Base

·

·






Naïve Bayes algorithm — Simple Explanation with Example

·

·






How ChatGPT Works: The Models Behind The Bot

·

·






Why I Keep Failing Candidates During Google Interviews…

·

·

See more recommendations



