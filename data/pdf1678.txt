


Published in

Towards Data Science



Nov 25, 2018

·

4 min read

Save

Evaluation of Language Models through Perplexity

and Shannon Visualization Method

How good is your natural language processing model?

How good is your language model?

In-vivo evaluation of language models

Limitations

Intrinsic evaluation of language models: Perplexity








Perplexity equations. Image credit: Speech and Language Processing (3rd edition), Chapter 3 Language Modeling

with N-grams, Slide 33, available at http://web.stanford.edu/~jurafsky/slp3/3.pdf

Example Perplexity Values of different N-gram language models trained using 38 million

words and tested using 1.5 million words from The Wall Street Journal dataset

Image credit: Speech and Language Processing (3rd edition), Chapter 3 Language Modeling with N-grams, Slide

36, available at http://web.stanford.edu/~jurafsky/slp3/3.pdf

The intuition behind Perplexity as an evaluation metric and Shannon Visualization

Method

Shannon Visualization Method

Image credit: Speech and Language Processing (3rd edition), Chapter 3 Language Modeling with N-grams, Slide

39, available at http://web.stanford.edu/~jurafsky/slp3/3.pdf

Approximating Shakespeare

Sentences generated from unigram, bigram, trigram and quadrigram language models trained using Shakespeare’s

corpus. Image credit: Speech and Language Processing (3rd edition), Chapter 3 Language Modeling with N-grams,

Figure 3.3, available at http://web.stanford.edu/~jurafsky/slp3/3.pdf

Shakespeare’s corpus and Sentence Generation Limitations using Shannon Visualization

Method


smoothing

over-learning

Approximating The Wall Street Journal

Sentences generated from unigram, bigram and trigram language models trained using The Wall Street Journal’s

corpus. Image credit: Speech and Language Processing (3rd edition), Chapter 3 Language Modeling with N-grams,

Figure 3.4, available at http://web.stanford.edu/~jurafsky/slp3/3.pdf



Follow

Your home for data science. A Medium publication sharing concepts, ideas and codes.



Read more from Towards Data Science

Naturallanguageprocessing

NLP

Language

Model






