
Published in

Analytics Vidhya



Jul 21, 2019

·

7 min read

Baum-Welch algorithm for training a Hidden Markov

Model — Part 2 of the HMM series

How to train a Hidden Markov Model and use it for filtering and smoothing?

Baum-Welch algorithm

A

B

π₀

Initial phase

A B π₀ 

Forward phase






Forward phase

A

B

the starting alpha is the product of probabilities of the emission and the initial state

Backward phase

A

B


Hold on! Why the alpha and the beta functions?

filtering

smoothing

The denominator term is a normalization constant and is usually dropped like this because it does not depend on

the state, and therefore it is not important when comparing the probability of different states at any time k.

Update phase


A B π₀

Summary

2

Analytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem

https://www.analyticsvidhya.com



Read more from Analytics Vidhya

Machine Learning

Markov Chains

Baum Welch

Hidden Markov Models






