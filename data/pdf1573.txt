
Notes on Probability

Peter J. Cameron


ii


Preface

Here are the course lecture notes for the course MAS108, Probability I, at Queen

Mary, University of London, taken by most Mathematics students and some others

in the ï¬rst semester.

The description of the course is as follows:

This course introduces the basic notions of probability theory and de-

velops them to the stage where one can begin to use probabilistic

ideas in statistical inference and modelling, and the study of stochastic

processes. Probability axioms. Conditional probability and indepen-

dence. Discrete random variables and their distributions. Continuous

distributions. Joint distributions. Independence. Expectations. Mean,

variance, covariance, correlation. Limiting distributions.

The syllabus is as follows:

1. Basic notions of probability. Sample spaces, events, relative frequency,

probability axioms.

2. Finite sample spaces. Methods of enumeration. Combinatorial probability.

3. Conditional probability. Theorem of total probability. Bayes theorem.

4. Independence of two events. Mutual independence of n events. Sampling

with and without replacement.

5. Random variables. Univariate distributions - discrete, continuous, mixed.

Standard distributions - hypergeometric, binomial, geometric, Poisson, uni-

form, normal, exponential. Probability mass function, density function, dis-

tribution function. Probabilities of events in terms of random variables.

6. Transformations of a single random variable.

Mean, variance, median,

quantiles.

7. Joint distribution of two random variables. Marginal and conditional distri-

butions. Independence.

iii


iv

8. Covariance, correlation. Means and variances of linear functions of random

variables.

9. Limiting distributions in the Binomial case.

These course notes explain the naterial in the syllabus. They have been â€œï¬eld-

testedâ€ on the class of 2000. Many of the examples are taken from the course

homework sheets or past exam papers.

Set books

The notes cover only material in the Probability I course. The text-

books listed below will be useful for other courses on probability and statistics.

You need at most one of the three textbooks listed below, but you will need the

statistical tables.

â€¢ Probability and Statistics for Engineering and the Sciences by Jay L. De-

vore (ï¬fth edition), published by Wadsworth.

Chapters 2â€“5 of this book are very close to the material in the notes, both in

order and notation. However, the lectures go into more detail at several points,

especially proofs. If you ï¬nd the course difï¬cult then you are advised to buy

this book, read the corresponding sections straight after the lectures, and do extra

exercises from it.

Other books which you can use instead are:

â€¢ Probability and Statistics in Engineering and Management Science by W. W.

Hines and D. C. Montgomery, published by Wiley, Chapters 2â€“8.

â€¢ Mathematical Statistics and Data Analysis by John A. Rice, published by

Wadsworth, Chapters 1â€“4.

You should also buy a copy of

â€¢ New Cambridge Statistical Tables by D. V. Lindley and W. F. Scott, pub-

lished by Cambridge University Press.

You need to become familiar with the tables in this book, which will be provided

for you in examinations. All of these books will also be useful to you in the

courses Statistics I and Statistical Inference.

The next book is not compulsory but introduces the ideas in a friendly way:

â€¢ Taking Chances: Winning with Probability, by John Haigh, published by

Oxford University Press.


v

Web resources

Course material for the MAS108 course is kept on the Web at

the address

http://www.maths.qmw.ac.uk/Ëœpjc/MAS108/

This includes a preliminary version of these notes, together with coursework

sheets, test and past exam papers, and some solutions.

Other web pages of interest include

http://www.dartmouth.edu/Ëœchance/teaching aids/

books articles/probability book/pdf.html

A textbook Introduction to Probability, by Charles M. Grinstead and J. Laurie

Snell, available free, with many exercises.

http://www.math.uah.edu/stat/

The Virtual Laboratories in Probability and Statistics, a set of web-based resources

for students and teachers of probability and statistics, where you can run simula-

tions etc.

http://www.newton.cam.ac.uk/wmy2kposters/july/

The Birthday Paradox (poster in the London Underground, July 2000).

http://www.combinatorics.org/Surveys/ds5/VennEJC.html

An article on Venn diagrams by Frank Ruskey, with history and many nice pic-

tures.

Web pages for other Queen Mary maths courses can be found from the on-line

version of the Maths Undergraduate Handbook.

Peter J. Cameron

December 2000


vi


Contents

1

Basic ideas

1

1.1

Sample space, events . . . . . . . . . . . . . . . . . . . . . . . .

1

1.2

What is probability? . . . . . . . . . . . . . . . . . . . . . . . . .

3

1.3

Kolmogorovâ€™s Axioms

. . . . . . . . . . . . . . . . . . . . . . .

3

1.4

Proving things from the axioms . . . . . . . . . . . . . . . . . . .

4

1.5

Inclusion-Exclusion Principle . . . . . . . . . . . . . . . . . . . .

6

1.6

Other results about sets . . . . . . . . . . . . . . . . . . . . . . .

7

1.7

Sampling

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

8

1.8

Stopping rules . . . . . . . . . . . . . . . . . . . . . . . . . . . .

12

1.9

Questionnaire results . . . . . . . . . . . . . . . . . . . . . . . .

13

1.10 Independence . . . . . . . . . . . . . . . . . . . . . . . . . . . .

14

1.11 Mutual independence . . . . . . . . . . . . . . . . . . . . . . . .

16

1.12 Properties of independence . . . . . . . . . . . . . . . . . . . . .

17

1.13 Worked examples . . . . . . . . . . . . . . . . . . . . . . . . . .

20

2

Conditional probability

23

2.1

What is conditional probability? . . . . . . . . . . . . . . . . . .

23

2.2

Genetics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

25

2.3

The Theorem of Total Probability

. . . . . . . . . . . . . . . . .

26

2.4

Sampling revisited

. . . . . . . . . . . . . . . . . . . . . . . . .

28

2.5

Bayesâ€™ Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . .

29

2.6

Iterated conditional probability . . . . . . . . . . . . . . . . . . .

31

2.7

Worked examples . . . . . . . . . . . . . . . . . . . . . . . . . .

34

3

Random variables

39

3.1

What are random variables?

. . . . . . . . . . . . . . . . . . . .

39

3.2

Probability mass function . . . . . . . . . . . . . . . . . . . . . .

40

3.3

Expected value and variance . . . . . . . . . . . . . . . . . . . .

41

3.4

Joint p.m.f. of two random variables . . . . . . . . . . . . . . . .

43

3.5

Some discrete random variables

. . . . . . . . . . . . . . . . . .

47

3.6

Continuous random variables . . . . . . . . . . . . . . . . . . . .

55

vii


viii

CONTENTS

3.7

Median, quartiles, percentiles . . . . . . . . . . . . . . . . . . . .

57

3.8

Some continuous random variables . . . . . . . . . . . . . . . . .

58

3.9

On using tables . . . . . . . . . . . . . . . . . . . . . . . . . . .

61

3.10 Worked examples . . . . . . . . . . . . . . . . . . . . . . . . . .

63

4

More on joint distribution

67

4.1

Covariance and correlation . . . . . . . . . . . . . . . . . . . . .

67

4.2

Conditional random variables . . . . . . . . . . . . . . . . . . . .

70

4.3

Joint distribution of continuous r.v.s

. . . . . . . . . . . . . . . .

73

4.4

Transformation of random variables . . . . . . . . . . . . . . . .

74

4.5

Worked examples . . . . . . . . . . . . . . . . . . . . . . . . . .

77

A Mathematical notation

79

B

Probability and random variables

83


Chapter 1

Basic ideas

In this chapter, we donâ€™t really answer the question â€˜What is probability?â€™ No-

body has a really good answer to this question. We take a mathematical approach,

writing down some basic axioms which probability must satisfy, and making de-

ductions from these. We also look at different kinds of sampling, and examine

what it means for events to be independent.

1.1

Sample space, events

The general setting is: We perform an experiment which can have a number of

different outcomes. The sample space is the set of all possible outcomes of the

experiment. We usually call it S.

It is important to be able to list the outcomes clearly. For example, if I plant

ten bean seeds and count the number that germinate, the sample space is

S = {0,1,2,3,4,5,6,7,8,9,10}.

If I toss a coin three times and record the result, the sample space is

S = {HHH,HHT,HTH,HTT,THH,THT,TTH,TTT},

where (for example) HTH means â€˜heads on the ï¬rst toss, then tails, then heads

againâ€™.

Sometimes we can assume that all the outcomes are equally likely. (Donâ€™t

assume this unless either you are told to, or there is some physical reason for

assuming it. In the beans example, it is most unlikely. In the coins example,

the assumption will hold if the coin is â€˜fairâ€™: this means that there is no physical

reason for it to favour one side over the other.) If all outcomes are equally likely,

then each has probability 1/|S|. (Remember that |S| is the number of elements in

the set S).

1


2

CHAPTER 1. BASIC IDEAS

On this point, Albert Einstein wrote, in his 1905 paper On a heuristic point

of view concerning the production and transformation of light (for which he was

awarded the Nobel Prize),

In calculating entropy by molecular-theoretic methods, the word â€œprob-

abilityâ€ is often used in a sense differing from the way the word is

deï¬ned in probability theory. In particular, â€œcases of equal probabil-

ityâ€ are often hypothetically stipulated when the theoretical methods

employed are deï¬nite enough to permit a deduction rather than a stip-

ulation.

In other words: Donâ€™t just assume that all outcomes are equally likely, especially

when you are given enough information to calculate their probabilities!

An event is a subset of S. We can specify an event by listing all the outcomes

that make it up. In the above example, let A be the event â€˜more heads than tailsâ€™

and B the event â€˜heads on last throwâ€™. Then

A

=

{HHH,HHT,HTH,THH},

B

=

{HHH,HTH,THH,TTH}.

The probability of an event is calculated by adding up the probabilities of all

the outcomes comprising that event. So, if all outcomes are equally likely, we

have

P(A) = |A|

|S|.

In our example, both A and B have probability 4/8 = 1/2.

An event is simple if it consists of just a single outcome, and is compound

otherwise. In the example, A and B are compound events, while the event â€˜heads

on every throwâ€™ is simple (as a set, it is {HHH}). If A = {a} is a simple event,

then the probability of A is just the probability of the outcome a, and we usually

write P(a), which is simpler to write than P({a}). (Note that a is an outcome,

while {a} is an event, indeed a simple event.)

We can build new events from old ones:

â€¢ AâˆªB (read â€˜A union Bâ€™) consists of all the outcomes in A or in B (or both!)

â€¢ Aâˆ©B (read â€˜A intersection Bâ€™) consists of all the outcomes in both A and B;

â€¢ A\B (read â€˜A minus Bâ€™) consists of all the outcomes in A but not in B;

â€¢ Aâ€² (read â€˜A complementâ€™) consists of all outcomes not in A (that is, S \A);

â€¢ /0 (read â€˜empty setâ€™) for the event which doesnâ€™t contain any outcomes.


1.2. WHAT IS PROBABILITY?

3

Note the backward-sloping slash; this is not the same as either a vertical slash | or

a forward slash /.

In the example, Aâ€² is the event â€˜more tails than headsâ€™, and Aâˆ©B is the event

{HHH,THH,HTH}. Note that P(Aâˆ©B) = 3/8; this is not equal to P(A)Â·P(B),

despite what you read in some books!

1.2

What is probability?

There is really no answer to this question.

Some people think of it as â€˜limiting frequencyâ€™. That is, to say that the proba-

bility of getting heads when a coin is tossed means that, if the coin is tossed many

times, it is likely to come down heads about half the time. But if you toss a coin

1000 times, you are not likely to get exactly 500 heads. You wouldnâ€™t be surprised

to get only 495. But what about 450, or 100?

Some people would say that you can work out probability by physical argu-

ments, like the one we used for a fair coin. But this argument doesnâ€™t work in all

cases, and it doesnâ€™t explain what probability means.

Some people say it is subjective. You say that the probability of heads in a

coin toss is 1/2 because you have no reason for thinking either heads or tails more

likely; you might change your view if you knew that the owner of the coin was a

magician or a con man. But we canâ€™t build a theory on something subjective.

We regard probability as a mathematical construction satisfying some axioms

(devised by the Russian mathematician A. N. Kolmogorov). We develop ways of

doing calculations with probability, so that (for example) we can calculate how

unlikely it is to get 480 or fewer heads in 1000 tosses of a fair coin. The answer

agrees well with experiment.

1.3

Kolmogorovâ€™s Axioms

Remember that an event is a subset of the sample space S. A number of events,

say A1,A2,..., are called mutually disjoint or pairwise disjoint if Ai âˆ© Aj = /0 for

any two of the events Ai and Aj; that is, no two of the events overlap.

According to Kolmogorovâ€™s axioms, each event A has a probability P(A),

which is a number. These numbers satisfy three axioms:

Axiom 1: For any event A, we have P(A) â‰¥ 0.

Axiom 2: P(S) = 1.


4

CHAPTER 1. BASIC IDEAS

Axiom 3: If the events A1,A2,... are pairwise disjoint, then

P(A1 âˆªA2 âˆªÂ·Â·Â·) = P(A1)+P(A2)+Â·Â·Â·

Note that in Axiom 3, we have the union of events and the sum of numbers.

Donâ€™t mix these up; never write P(A1)âˆªP(A2), for example. Sometimes we sep-

arate Axiom 3 into two parts: Axiom 3a if there are only ï¬nitely many events

A1,A2,...,An, so that we have

P(A1 âˆªÂ·Â·Â·âˆªAn) =

n

âˆ‘

i=1

P(Ai),

and Axiom 3b for inï¬nitely many. We will only use Axiom 3a, but 3b is important

later on.

Notice that we write

n

âˆ‘

i=1

P(Ai)

for

P(A1)+P(A2)+Â·Â·Â·+P(An).

1.4

Proving things from the axioms

You can prove simple properties of probability from the axioms. That means,

every step must be justiï¬ed by appealing to an axiom. These properties seem

obvious, just as obvious as the axioms; but the point of this game is that we assume

only the axioms, and build everything else from that.

Here are some examples of things proved from the axioms. There is really no

difference between a theorem, a proposition, and a corollary; they all have to be

proved. Usually, a theorem is a big, important statement; a proposition a rather

smaller statement; and a corollary is something that follows quite easily from a

theorem or proposition that came before.

Proposition 1.1 If the event A contains only a ï¬nite number of outcomes, say

A = {a1,a2,...,an}, then

P(A) = P(a1)+P(a2)+Â·Â·Â·+P(an).

To prove the proposition, we deï¬ne a new event Ai containing only the out-

come ai, that is, Ai = {ai}, for i = 1,...,n. Then A1,...,An are mutually disjoint


1.4. PROVING THINGS FROM THE AXIOMS

5

(each contains only one element which is in none of the others), and A1 âˆª A2 âˆª

Â·Â·Â·âˆªAn = A; so by Axiom 3a, we have

P(A) = P(a1)+P(a2)+Â·Â·Â·+P(an).

Corollary 1.2 If the sample space S is ï¬nite, say S = {a1,...,an}, then

P(a1)+P(a2)+Â·Â·Â·+P(an) = 1.

For P(a1)+P(a2)+Â·Â·Â·+P(an) = P(S) by Proposition 1.1, and P(S) = 1 by

Axiom 2. Notice that once we have proved something, we can use it on the same

basis as an axiom to prove further facts.

Now we see that, if all the n outcomes are equally likely, and their probabil-

ities sum to 1, then each has probability 1/n, that is, 1/|S|. Now going back to

Proposition 1.1, we see that, if all outcomes are equally likely, then

P(A) = |A|

|S|

for any event A, justifying the principle we used earlier.

Proposition 1.3 P(Aâ€²) = 1âˆ’P(A) for any event A.

Let A1 = A and A2 = Aâ€² (the complement of A). Then A1 âˆ©A2 = /0 (that is, the

events A1 and A2 are disjoint), and A1 âˆªA2 = S. So

P(A1)+P(A2)

=

P(A1 âˆªA2)

(Axiom 3)

=

P(S)

=

1

(Axiom 2).

So P(A) = P(A1) = 1âˆ’P(A2).

Corollary 1.4 P(A) â‰¤ 1 for any event A.

For 1 âˆ’ P(A) = P(Aâ€²) by Proposition 1.3, and P(Aâ€²) â‰¥ 0 by Axiom 1; so 1 âˆ’

P(A) â‰¥ 0, from which we get P(A) â‰¤ 1.

Remember that if you ever calculate a probability to be less than 0 or more

than 1, you have made a mistake!

Corollary 1.5 P(/0) = 0.

For /0 = Sâ€², so P(/0) = 1âˆ’P(S) by Proposition 1.3; and P(S) = 1 by Axiom 2,

so P(/0) = 0.


6

CHAPTER 1. BASIC IDEAS

Here is another result. The notation A âŠ† B means that A is contained in B, that

is, every outcome in A also belongs to B.

Proposition 1.6 If A âŠ† B, then P(A) â‰¤ P(B).

This time, take A1 = A, A2 = B \ A. Again we have A1 âˆ© A2 = /0 (since the

elements of B\A are, by deï¬nition, not in A), and A1 âˆªA2 = B. So by Axiom 3,

P(A1)+P(A2) = P(A1 âˆªA2) = P(B).

In other words, P(A)+P(B\A) = P(B). Now P(B\A) â‰¥ 0 by Axiom 1; so

P(A) â‰¤ P(B),

as we had to show.

1.5

Inclusion-Exclusion Principle

















A

B

A Venn diagram for two sets A and B suggests that, to ï¬nd the size of A âˆª B,

we add the size of A and the size of B, but then we have included the size of Aâˆ©B

twice, so we have to take it off. In terms of probability:

Proposition 1.7

P(AâˆªB) = P(A)+P(B)âˆ’P(Aâˆ©B).

We now prove this from the axioms, using the Venn diagram as a guide. We

see that AâˆªB is made up of three parts, namely

A1 = Aâˆ©B,

A2 = A\B,

A3 = B\A.

Indeed we do have AâˆªB = A1 âˆªA2 âˆªA3, since anything in AâˆªB is in both these

sets or just the ï¬rst or just the second. Similarly we have A1âˆªA2 = A and A1âˆªA3 =

B.

The sets A1,A2,A3 are mutually disjoint. (We have three pairs of sets to check.

Now A1 âˆ©A2 = /0, since all elements of A1 belong to B but no elements of A2 do.

The arguments for the other two pairs are similar â€“ you should do them yourself.)


1.6. OTHER RESULTS ABOUT SETS

7

So, by Axiom 3, we have

P(A)

=

P(A1)+P(A2),

P(B)

=

P(A1)+P(A3),

P(AâˆªB)

=

P(A1)+P(A2)+P(A3).

From this we obtain

P(A)+P(B)âˆ’P(Aâˆ©B)

=

(P(A1)+P(A2))+(P(A1)+P(A3))âˆ’P(A1)

=

P(A1)+P(A2)+P(A3)

=

P(AâˆªB)

as required.

The Inclusion-Exclusion Principle extends to more than two events, but gets

more complicated. Here it is for three events; try to prove it yourself.

























A

B

C

To calculate P(AâˆªBâˆªC), we ï¬rst add up P(A), P(B), and P(C). The parts in

common have been counted twice, so we subtract P(Aâˆ©B), P(Aâˆ©C) and P(Bâˆ©C).

But then we ï¬nd that the outcomes lying in all three sets have been taken off

completely, so must be put back, that is, we add P(Aâˆ©Bâˆ©C).

Proposition 1.8 For any three events A,B,C, we have

P(AâˆªBâˆªC) = P(A)+P(B)+P(C)âˆ’P(Aâˆ©B)âˆ’P(Aâˆ©C)âˆ’P(Bâˆ©C)+P(Aâˆ©Bâˆ©C).

Can you extend this to any number of events?

1.6

Other results about sets

There are other standard results about sets which are often useful in probability

theory. Here are some examples.

Proposition 1.9 Let A,B,C be subsets of S.

Distributive laws: (Aâˆ©B)âˆªC = (AâˆªC)âˆ©(BâˆªC) and

(AâˆªB)âˆ©C = (Aâˆ©C)âˆª(Bâˆ©C).

De Morganâ€™s Laws: (AâˆªB)â€² = Aâ€² âˆ©Bâ€² and (Aâˆ©B)â€² = Aâ€² âˆªBâ€².

We will not give formal proofs of these. You should draw Venn diagrams and

convince yourself that they work.


8

CHAPTER 1. BASIC IDEAS

1.7

Sampling

I have four pens in my desk drawer; they are red, green, blue, and purple. I draw a

pen; each pen has the same chance of being selected. In this case, S = {R,G,B,P},

where R means â€˜red pen chosenâ€™ and so on. In this case, if A is the event â€˜red or

green pen chosenâ€™, then

P(A) = |A|

|S| = 2

4 = 1

2.

More generally, if I have a set of n objects and choose one, with each one

equally likely to be chosen, then each of the n outcomes has probability 1/n, and

an event consisting of m of the outcomes has probability m/n.

What if we choose more than one pen? We have to be more careful to specify

the sample space.

First, we have to say whether we are

â€¢ sampling with replacement, or

â€¢ sampling without replacement.

Sampling with replacement means that we choose a pen, note its colour, put

it back and shake the drawer, then choose a pen again (which may be the same

pen as before or a different one), and so on until the required number of pens have

been chosen. If we choose two pens with replacement, the sample space is

{RR,

RG,

RB,

RP,

GR,

GG,

GB,

GP,

BR,

BG,

BB,

BP,

PR,

PG,

PB,

PP}

The event â€˜at least one red penâ€™ is {RR,RG,RB,RP,GR,BR,PR}, and has proba-

bility 7/16.

Sampling without replacement means that we choose a pen but do not put it

back, so that our ï¬nal selection cannot include two pens of the same colour. In

this case, the sample space for choosing two pens is

{

RG,

RB,

RP,

GR,

GB,

GP,

BR,

BG,

BP,

PR,

PG,

PB

}

and the event â€˜at least one red penâ€™ is {RG,RB,RP,GR,BR,PR}, with probability

6/12 = 1/2.


1.7. SAMPLING

9

Now there is another issue, depending on whether we care about the order in

which the pens are chosen. We will only consider this in the case of sampling

without replacement. It doesnâ€™t really matter in this case whether we choose the

pens one at a time or simply take two pens out of the drawer; and we are not

interested in which pen was chosen ï¬rst. So in this case the sample space is

{{R,G},{R,B},{R,P},{G,B},{G,P},{B,P}},

containing six elements. (Each element is written as a set since, in a set, we donâ€™t

care which element is ï¬rst, only which elements are actually present. So the sam-

ple space is a set of sets!) The event â€˜at least one red penâ€™ is {{R,G},{R,B},{R,P}},

with probability 3/6 = 1/2. We should not be surprised that this is the same as in

the previous case.

There are formulae for the sample space size in these three cases. These in-

volve the following functions:

n!

=

n(nâˆ’1)(nâˆ’2)Â·Â·Â·1

nPk

=

n(nâˆ’1)(nâˆ’2)Â·Â·Â·(nâˆ’k +1)

nCk

=

nPk/k!

Note that n! is the product of all the whole numbers from 1 to n; and

nPk =

n!

(nâˆ’k)!,

so that

nCk =

n!

k!(nâˆ’k)!.

Theorem 1.10 The number of selections of k objects from a set of n objects is

given in the following table.

with replacement

without replacement

ordered sample

nk

nPk

unordered sample

nCk

In fact the number that goes in the empty box is n+kâˆ’1Ck, but this is much

harder to prove than the others, and you are very unlikely to need it.

Here are the proofs of the other three cases. First, for sampling with replace-

ment and ordered sample, there are n choices for the ï¬rst object, and n choices

for the second, and so on; we multiply the choices for different objects. (Think of

the choices as being described by a branching tree.) The product of k factors each

equal to n is nk.


10

CHAPTER 1. BASIC IDEAS

For sampling without replacement and ordered sample, there are still n choices

for the ï¬rst object, but now only n âˆ’ 1 choices for the second (since we do not

replace the ï¬rst), and nâˆ’2 for the third, and so on; there are nâˆ’k +1 choices for

the kth object, since k âˆ’1 have previously been removed and nâˆ’(k âˆ’1) remain.

As before, we multiply. This product is the formula for nPk.

For sampling without replacement and unordered sample, think ï¬rst of choos-

ing an ordered sample, which we can do in nPk ways. But each unordered sample

could be obtained by drawing it in k! different orders. So we divide by k!, obtain-

ing nPk/k! = nCk choices.

In our example with the pens, the numbers in the three boxes are 42 = 16,

4P2 = 12, and 4C2 = 6, in agreement with what we got when we wrote them all

out.

Note that, if we use the phrase â€˜sampling without replacement, ordered sam-

pleâ€™, or any other combination, we are assuming that all outcomes are equally

likely.

Example

The names of the seven days of the week are placed in a hat. Three

names are drawn out; these will be the days of the Probability I lectures. What is

the probability that no lecture is scheduled at the weekend?

Here the sampling is without replacement, and we can take it to be either

ordered or unordered; the answers will be the same. For ordered samples, the

size of the sample space is 7P3 = 7 Â· 6 Â· 5 = 210. If A is the event â€˜no lectures at

weekendsâ€™, then A occurs precisely when all three days drawn are weekdays; so

|A| = 5P3 = 5Â·4Â·3 = 60. Thus, P(A) = 60/210 = 2/7.

If we decided to use unordered samples instead, the answer would be 5C3/7C3,

which is once again 2/7.

Example

A six-sided die is rolled twice. What is the probability that the sum of

the numbers is at least 10?

This time we are sampling with replacement, since the two numbers may be

the same or different. So the number of elements in the sample space is 62 = 36.

To obtain a sum of 10 or more, the possibilities for the two numbers are (4,6),

(5,5), (6,4), (5,6), (6,5) or (6,6). So the probability of the event is 6/36 = 1/6.

Example

A box contains 20 balls, of which 10 are red and 10 are blue. We draw

ten balls from the box, and we are interested in the event that exactly 5 of the balls

are red and 5 are blue. Do you think that this is more likely to occur if the draws

are made with or without replacement?

Let S be the sample space, and A the event that ï¬ve balls are red and ï¬ve are

blue.


1.7. SAMPLING

11

Consider sampling with replacement. Then |S| = 2010. What is |A|? The

number of ways in which we can choose ï¬rst ï¬ve red balls and then ï¬ve blue ones

(that is, RRRRRBBBBB), is 105 Â·105 = 1010. But there are many other ways to get

ï¬ve red and ï¬ve blue balls. In fact, the ï¬ve red balls could appear in any ï¬ve of

the ten draws. This means that there are 10C5 = 252 different patterns of ï¬ve Rs

and ï¬ve Bs. So we have

|A| = 252Â·1010,

and so

P(A) = 252Â·1010

2010

= 0.246...

Now consider sampling without replacement. If we regard the sample as being

ordered, then |S| = 20P10. There are 10P5 ways of choosing ï¬ve of the ten red

balls, and the same for the ten blue balls, and as in the previous case there are

10C5 patterns of red and blue balls. So

|A| = (10P5)2 Â· 10C5,

and

P(A) = (10P5)2 Â· 10C5

20P10

= 0.343...

If we regard the sample as being unordered, then |S| = 20C10. There are 10C5

choices of the ï¬ve red balls and the same for the blue balls. We no longer have to

count patterns since we donâ€™t care about the order of the selection. So

|A| = (10C5)2,

and

P(A) = (10C5)2

20C10

= 0.343...

This is the same answer as in the case before, as it should be; the question doesnâ€™t

care about order of choices!

So the event is more likely if we sample with replacement.

Example

I have 6 gold coins, 4 silver coins and 3 bronze coins in my pocket. I

take out three coins at random. What is the probability that they are all of different

material? What is the probability that they are all of the same material?

In this case the sampling is without replacement and the sample is unordered.

So |S| = 13C3 = 286. The event that the three coins are all of different material

can occur in 6Â·4Â·3 = 72 ways, since we must have one of the six gold coins, and

so on. So the probability is 72/286 = 0.252...


12

CHAPTER 1. BASIC IDEAS

The event that the three coins are of the same material can occur in

6C3 + 4C3 + 3C3 = 20+4+1 = 25

ways, and the probability is 25/286 = 0.087...

In a sampling problem, you should ï¬rst read the question carefully and decide

whether the sampling is with or without replacement. If it is without replacement,

decide whether the sample is ordered (e.g. does the question say anything about

the ï¬rst object drawn?). If so, then use the formula for ordered samples. If not,

then you can use either ordered or unordered samples, whichever is convenient;

they should give the same answer. If the sample is with replacement, or if it

involves throwing a die or coin several times, then use the formula for sampling

with replacement.

1.8

Stopping rules

Suppose that you take a typing proï¬ciency test. You are allowed to take the test

up to three times. Of course, if you pass the test, you donâ€™t need to take it again.

So the sample space is

S = {p, f p, f f p, f f f},

where for example f f p denotes the outcome that you fail twice and pass on your

third attempt.

If all outcomes were equally likely, then your chance of eventually passing the

test and getting the certiï¬cate would be 3/4.

But it is unreasonable here to assume that all the outcomes are equally likely.

For example, you may be very likely to pass on the ï¬rst attempt. Let us assume

that the probability that you pass the test is 0.8. (By Proposition 3, your chance

of failing is 0.2.) Let us further assume that, no matter how many times you have

failed, your chance of passing at the next attempt is still 0.8. Then we have

P(p)

=

0.8,

P(f p)

=

0.2Â·0.8 = 0.16,

P(f f p)

=

0.22 Â·0.8 = 0.032,

P(f f f)

=

0.23 = 0.008.

Thus the probability that you eventually get the certiï¬cate is P({p, f p, f f p}) =

0.8+0.16+0.032 = 0.992. Alternatively, you eventually get the certiï¬cate unless

you fail three times, so the probability is 1âˆ’0.008 = 0.992.

A stopping rule is a rule of the type described here, namely, continue the exper-

iment until some speciï¬ed occurrence happens. The experiment may potentially

be inï¬nite.


1.9. QUESTIONNAIRE RESULTS

13

For example, if you toss a coin repeatedly until you obtain heads, the sample

space is

S = {H,TH,TTH,TTTH,...}

since in principle you may get arbitrarily large numbers of tails before the ï¬rst

head. (We have to allow all possible outcomes.)

In the typing test, the rule is â€˜stop if either you pass or you have taken the test

three timesâ€™. This ensures that the sample space is ï¬nite.

In the next chapter, we will have more to say about the â€˜multiplication ruleâ€™ we

used for calculating the probabilities. In the meantime you might like to consider

whether it is a reasonable assumption for tossing a coin, or for someone taking a

series of tests.

Other kinds of stopping rules are possible. For example, the number of coin

tosses might be determined by some other random process such as the roll of a

die; or we might toss a coin until we have obtained heads twice; and so on. We

will not deal with these.

1.9

Questionnaire results

The students in the Probability I class in Autumn 2000 ï¬lled in the following

questionnaire:

1. I have a hat containing 20 balls, 10 red and 10 blue. I draw 10 balls

from the hat. I am interested in the event that I draw exactly ï¬ve red and

ï¬ve blue balls. Do you think that this is more likely if I note the colour of

each ball I draw and replace it in the hat, or if I donâ€™t replace the balls in

the hat after drawing?

More likely with replacement 2

More likely without replacement 2

2. What colour are your eyes?

Blue 2

Brown 2

Green 2

Other 2

3. Do you own a mobile phone?

Yes 2

No 2

After discarding incomplete questionnaires, the results were as follows:

Answer to

â€œMore likely

â€œMore likely

question

with replacementâ€

without replacementâ€

Eyes

Brown

Other

Brown

Other

Mobile phone

35

4

35

9

No mobile phone

10

3

7

1


14

CHAPTER 1. BASIC IDEAS

What can we conclude?

Half the class thought that, in the experiment with the coloured balls, sampling

with replacement make the result more likely. In fact, as we saw in Chapter 1,

actually it is more likely if we sample without replacement. (This doesnâ€™t matter,

since the students were instructed not to think too hard about it!)

You might expect that eye colour and mobile phone ownership would have no

inï¬‚uence on your answer. Letâ€™s test this. If true, then of the 87 people with brown

eyes, half of them (i.e. 43 or 44) would answer â€œwith replacementâ€, whereas in

fact 45 did. Also, of the 83 people with mobile phones, we would expect half (that

is, 41 or 42) would answer â€œwith replacementâ€, whereas in fact 39 of them did. So

perhaps we have demonstrated that people who own mobile phones are slightly

smarter than average, whereas people with brown eyes are slightly less smart!

In fact we have shown no such thing, since our results refer only to the peo-

ple who ï¬lled out the questionnaire. But they do show that these events are not

independent, in a sense we will come to soon.

On the other hand, since 83 out of 104 people have mobile phones, if we

think that phone ownership and eye colour are independent, we would expect

that the same fraction 83/104 of the 87 brown-eyed people would have phones,

i.e. (83 Â· 87)/104 = 69.4 people. In fact the number is 70, or as near as we can

expect. So indeed it seems that eye colour and phone ownership are more-or-less

independent.

1.10

Independence

Two events A and B are said to be independent if

P(Aâˆ©B) = P(A)Â·P(B).

This is the deï¬nition of independence of events. If you are asked in an exam

to deï¬ne independence of events, this is the correct answer. Do not say that two

events are independent if one has no inï¬‚uence on the other; and under no circum-

stances say that A and B are independent if A âˆ© B = /0 (this is the statement that

A and B are disjoint, which is quite a different thing!) Also, do not ever say that

P(A âˆ© B) = P(A) Â· P(B) unless you have some good reason for assuming that A

and B are independent (either because this is given in the question, or as in the

next-but-one paragraph).

Let us return to the questionnaire example. Suppose that a student is chosen

at random from those who ï¬lled out the questionnaire. Let A be the event that this

student thought that the event was more likely if we sample with replacement; B

the event that the student has brown eyes; and C the event that the student has a


1.10. INDEPENDENCE

15

mobile phone. Then

P(A)

=

52/104 = 0.5,

P(B)

=

87/104 = 0.8365,

P(C)

=

83/104 = 0.7981.

Furthermore,

P(Aâˆ©B) = 45/104 = 0.4327,

P(A)Â·P(B) = 0.4183,

P(Aâˆ©C) = 39/104 = 0.375,

P(A)Â·P(C) = 0.3990,

P(Bâˆ©C) = 70/104 = 0.6731,

P(B)âˆ©P(C) = 0.6676.

So none of the three pairs is independent, but in a sense B and C â€˜come closerâ€™

than either of the others, as we noted.

In practice, if it is the case that the event A has no effect on the outcome

of event B, then A and B are independent. But this does not apply in the other

direction. There might be a very deï¬nite connection between A and B, but still it

could happen that P(A âˆ© B) = P(A) Â· P(B), so that A and B are independent. We

will see an example shortly.

Example

If we toss a coin more than once, or roll a die more than once, then

you may assume that different tosses or rolls are independent. More precisely,

if we roll a fair six-sided die twice, then the probability of getting 4 on the ï¬rst

throw and 5 on the second is 1/36, since we assume that all 36 combinations of

the two throws are equally likely. But (1/36) = (1/6) Â· (1/6), and the separate

probabilities of getting 4 on the ï¬rst throw and of getting 5 on the second are both

equal to 1/6. So the two events are independent. This would work just as well for

any other combination.

In general, it is always OK to assume that the outcomes of different tosses of a

coin, or different throws of a die, are independent. This holds even if the examples

are not all equally likely. We will see an example later.

Example

I have two red pens, one green pen, and one blue pen. I choose two

pens without replacement. Let A be the event that I choose exactly one red pen,

and B the event that I choose exactly one green pen.

If the pens are called R1,R2,G,B, then

S

=

{R1R2,R1G,R1B,R2G,R2B,GB},

A

=

{R1G,R1B,R2G,R2B},

B

=

{R1G,R2G,GB}


16

CHAPTER 1. BASIC IDEAS

We have P(A) = 4/6 = 2/3, P(B) = 3/6 = 1/2, P(Aâˆ©B) = 2/6 = 1/3 = P(A)P(B),

so A and B are independent.

But before you say â€˜thatâ€™s obviousâ€™, suppose that I have also a purple pen,

and I do the same experiment. This time, if you write down the sample space

and the two events and do the calculations, you will ï¬nd that P(A) = 6/10 = 3/5,

P(B) = 4/10 = 2/5, P(A âˆ© B) = 2/10 = 1/5 Ì¸= P(A)P(B), so adding one more

pen has made the events non-independent!

We see that it is very difï¬cult to tell whether events are independent or not. In

practice, assume that events are independent only if either you are told to assume

it, or the events are the outcomes of different throws of a coin or die. (There is

one other case where you can assume independence: this is the result of different

draws, with replacement, from a set of objects.)

Example

Consider the experiment where we toss a fair coin three times and

note the results. Each of the eight possible outcomes has probability 1/8. Let A

be the event â€˜there are more heads than tailsâ€™, and B the event â€˜the results of the

ï¬rst two tosses are the sameâ€™. Then

â€¢ A = {HHH,HHT,HTH,THH}, P(A) = 1/2,

â€¢ B = {HHH,HHT,TTH,TTT}, P(B) = 1/2,

â€¢ Aâˆ©B = {HHH,HHT}, P(Aâˆ©B) = 1/4;

so A and B are independent. However, both A and B clearly involve the results of

the ï¬rst two tosses and it is not possible to make a convincing argument that one

of these events has no inï¬‚uence or effect on the other. For example, let C be the

event â€˜heads on the last tossâ€™. Then, as we saw in Part 1,

â€¢ C = {HHH,HTH,THH,TTH}, P(C) = 1/2,

â€¢ Aâˆ©C = {HHH,HTH,THH}, P(Aâˆ©C) = 3/8;

so A and C are not independent.

Are B and C independent?

1.11

Mutual independence

This section is a bit technical. You will need to know the conclusions, though the

arguments we use to reach them are not so important.

We saw in the coin-tossing example above that it is possible to have three

events A,B,C so that A and B are independent, B and C are independent, but A and

C are not independent.


1.12. PROPERTIES OF INDEPENDENCE

17

If all three pairs of events happen to be independent, can we then conclude

that P(Aâˆ©Bâˆ©C) = P(A)Â·P(B)Â·P(C)? At ï¬rst sight this seems very reasonable;

in Axiom 3, we only required all pairs of events to be exclusive in order to justify

our conclusion. Unfortunately it is not true...

Example

In the coin-tossing example, let A be the event â€˜ï¬rst and second tosses

have same resultâ€™, B the event â€˜ï¬rst and third tosses have the same result, and

C the event â€˜second and third tosses have same resultâ€™. You should check that

P(A) = P(B) = P(C) = 1/2, and that the events Aâˆ©B, Bâˆ©C, Aâˆ©C, and Aâˆ©Bâˆ©C

are all equal to {HHH,TTT}, with probability 1/4. Thus any pair of the three

events are independent, but

P(Aâˆ©Bâˆ©C)

=

1/4,

P(A)Â·P(B)Â·P(C)

=

1/8.

So A,B,C are not mutually independent.

The correct deï¬nition and proposition run as follows.

Let A1,...,An be events. We say that these events are mutually independent if,

given any distinct indices i1,i2,...,ik with k â‰¥ 1, the events

Ai1 âˆ©Ai2 âˆ©Â·Â·Â·âˆ©Aikâˆ’1

and

Aik

are independent. In other words, any one of the events is independent of the

intersection of any number of the other events in the set.

Proposition 1.11 Let A1,...,An be mutually independent. Then

P(A1 âˆ©A2 âˆ©Â·Â·Â·âˆ©An) = P(A1)Â·P(A2)Â·Â·Â·P(An).

Now all you really need to know is that the same â€˜physicalâ€™ arguments that

justify that two events (such as two tosses of a coin, or two throws of a die) are

independent, also justify that any number of such events are mutually independent.

So, for example, if we toss a fair coin six times, the probability of getting the

sequence HHTHHT is (1/2)6 = 1/64, and the same would apply for any other

sequence. In other words, all 64 possible outcomes are equally likely.

1.12

Properties of independence

Proposition 1.12 If A and B are independent, then A and Bâ€² are independent.


18

CHAPTER 1. BASIC IDEAS

We are given that P(Aâˆ©B) = P(A)Â·P(B), and asked to prove that P(Aâˆ©Bâ€²) =

P(A)Â·P(Bâ€²).

From Corollary 4, we know that P(Bâ€²) = 1âˆ’P(B). Also, the events Aâˆ©B and

A âˆ© Bâ€² are disjoint (since no outcome can be both in B and Bâ€²), and their union

is A (since every event in A is either in B or in Bâ€²); so by Axiom 3, we have that

P(A) = P(Aâˆ©B)+P(Aâˆ©Bâ€²). Thus,

P(Aâˆ©Bâ€²)

=

P(A)âˆ’P(Aâˆ©B)

=

P(A)âˆ’P(A)Â·P(B)

(since A and B are independent)

=

P(A)(1âˆ’P(B))

=

P(A)Â·P(Bâ€²),

which is what we were required to prove.

Corollary 1.13 If A and B are independent, so are Aâ€² and Bâ€².

Apply the Proposition twice, ï¬rst to A and B (to show that A and Bâ€² are inde-

pendent), and then to Bâ€² and A (to show that Bâ€² and Aâ€² are independent).

More generally, if events A1,...,An are mutually independent, and we replace

some of them by their complements, then the resulting events are mutually inde-

pendent. We have to be a bit careful though. For example, A and Aâ€² are not usually

independent!

Results like the following are also true.

Proposition 1.14 Let events A, B, C be mutually independent. Then A and Bâˆ©C

are independent, and A and BâˆªC are independent.

Example

Consider the example of the typing proï¬ciency test that we looked at

earlier. You are allowed up to three attempts to pass the test.

Suppose that your chance of passing the test is 0.8. Suppose also that the

events of passing the test on any number of different occasions are mutually inde-

pendent. Then, by Proposition 1.11, the probability of any sequence of passes and

fails is the product of the probabilities of the terms in the sequence. That is,

P(p) = 0.8, P(f p) = (0.2)Â·(0.8), P(f f p) = (0.2)2 Â·(0.8), P(f f f) = (0.2)3,

as we claimed in the earlier example.

In other words, mutual independence is the condition we need to justify the

argument we used in that example.


1.12. PROPERTIES OF INDEPENDENCE

19

Example

The electrical apparatus in the diagram

works so long as current can ï¬‚ow from left

to right.

The three components are inde-

pendent. The probability that component A

works is 0.8; the probability that compo-

nent B works is 0.9; and the probability that

component C works is 0.75.

Find the probability that the apparatus works.





A





B





C

At risk of some confusion, we use the letters A, B and C for the events â€˜com-

ponent A worksâ€™, â€˜component B worksâ€™, and â€˜component C worksâ€™, respectively.

Now the apparatus will work if either A and B are working, or C is working (or

possibly both). Thus the event we are interested in is (Aâˆ©B)âˆªC.

Now

P((Aâˆ©B)âˆªC))

=

P(Aâˆ©B)+P(C)âˆ’P(Aâˆ©Bâˆ©C)

(by Inclusionâ€“Exclusion)

=

P(A)Â·P(B)+P(C)âˆ’P(A)Â·P(B)Â·P(C)

(by mutual independence)

=

(0.8)Â·(0.9)+(0.75)âˆ’(0.8)Â·(0.9)Â·(0.75)

=

0.93.

The problem can also be analysed in a different way. The apparatus will not

work if both paths are blocked, that is, if C is not working and one of A and B is

also not working. Thus, the event that the apparatus does not work is (Aâ€²âˆªBâ€²)âˆ©Câ€².

By the Distributive Law, this is equal to (Aâ€² âˆ©Câ€²)âˆª(Bâ€² âˆ©Câ€²). We have

P((Aâ€² âˆ©Câ€²)âˆª(Bâ€² âˆ©Câ€²)

=

P(Aâ€² âˆ©Câ€²)+P(Bâ€² âˆ©Câ€²)âˆ’P(Aâ€² âˆ©Bâ€² âˆ©Câ€²)

(by Inclusionâ€“Exclusion)

=

P(Aâ€²)Â·P(Câ€²)+P(Bâ€²)Â·P(Câ€²)âˆ’P(Aâ€²)Â·P(Bâ€²)Â·P(Câ€²)

(by mutual independence of Aâ€²,Bâ€²,Câ€²)

=

(0.2)Â·(0.25)+(0.1)Â·(0.25)âˆ’(0.2)Â·(0.1)Â·(0.25)

=

0.07,

so the apparatus works with probability 1âˆ’0.07 = 0.93.

There is a trap here which you should take care to avoid. You might be tempted

to say P(Aâ€² âˆ©Câ€²) = (0.2)Â·(0.25) = 0.05, and P(Bâ€² âˆ©Câ€²) = (0.1)Â·(0.25) = 0.025;

and conclude that

P((Aâ€² âˆ©Câ€²)âˆª(Bâ€² âˆ©Câ€²)) = 0.05+0.025âˆ’(0.05)Â·(0.025) = 0.07375

by the Principle of Inclusion and Exclusion. But this is not correct, since the

events Aâ€² âˆ©Câ€² and Bâ€² âˆ©Câ€² are not independent!


20

CHAPTER 1. BASIC IDEAS

Example

We can always assume that successive tosses of a coin are mutually

independent, even if it is not a fair coin. Suppose that I have a coin which has

probability 0.6 of coming down heads. I toss the coin three times. What are the

probabilities of getting three heads, two heads, one head, or no heads?

For three heads, since successive tosses are mutually independent, the proba-

bility is (0.6)3 = 0.216.

The probability of tails on any toss is 1 âˆ’ 0.6 = 0.4. Now the event â€˜two

headsâ€™ can occur in three possible ways, as HHT, HTH, or THH. Each outcome

has probability (0.6) Â· (0.6) Â· (0.4) = 0.144. So the probability of two heads is

3Â·(0.144) = 0.432.

Similarly the probability of one head is 3Â·(0.6)Â·(0.4)2 = 0.288, and the prob-

ability of no heads is (0.4)3 = 0.064.

As a check, we have

0.216+0.432+0.288+0.064 = 1.

1.13

Worked examples

Question

(a) You go to the shop to buy a toothbrush. The toothbrushes there are red, blue,

green, purple and white. The probability that you buy a red toothbrush is

three times the probability that you buy a green one; the probability that you

buy a blue one is twice the probability that you buy a green one; the proba-

bilities of buying green, purple, and white are all equal. You are certain to

buy exactly one toothbrush. For each colour, ï¬nd the probability that you

buy a toothbrush of that colour.

(b) James and Simon share a ï¬‚at, so it would be confusing if their toothbrushes

were the same colour. On the ï¬rst day of term they both go to the shop to

buy a toothbrush. For each of James and Simon, the probability of buying

various colours of toothbrush is as calculated in (a), and their choices are

independent. Find the probability that they buy toothbrushes of the same

colour.

(c) James and Simon live together for three terms. On the ï¬rst day of each term

they buy new toothbrushes, with probabilities as in (b), independently of

what they had bought before. This is the only time that they change their

toothbrushes. Find the probablity that James and Simon have differently

coloured toothbrushes from each other for all three terms. Is it more likely

that they will have differently coloured toothbrushes from each other for


1.13. WORKED EXAMPLES

21

all three terms or that they will sometimes have toothbrushes of the same

colour?

Solution

(a) Let R,B,G,P,W be the events that you buy a red, blue, green, purple and

white toothbrush respectively. Let x = P(G). We are given that

P(R) = 3x,

P(B) = 2x,

P(P) = P(W) = x.

Since these outcomes comprise the whole sample space, Corollary 2 gives

3x+2x+x+x+x = 1,

so x = 1/8. Thus, the probabilities are 3/8, 1/4, 1/8, 1/8, 1/8 respectively.

(b) Let RB denote the event â€˜James buys a red toothbrush and Simon buys a blue

toothbrushâ€™, etc. By independence (given), we have, for example,

P(RR) = (3/8)Â·(3/8) = 9/64.

The event that the toothbrushes have the same colour consists of the ï¬ve

outcomes RR, BB, GG, PP, WW, so its probability is

P(RR)+P(BB)+P(GG)+P(PP)+P(WW)

=

9

64 + 1

16 + 1

64 + 1

64 + 1

64 = 1

4.

(c) The event â€˜different coloured toothbrushes in the ith termâ€™ has probability 3/4

(from part (b)), and these events are independent. So the event â€˜different

coloured toothbrushes in all three termsâ€™ has probability

3

4 Â· 3

4 Â· 3

4 = 27

64.

The event â€˜same coloured toothbrushes in at least one termâ€™ is the comple-

ment of the above, so has probability 1 âˆ’ (27/64) = (37)/(64). So it is

more likely that they will have the same colour in at least one term.

Question

There are 24 elephants in a game reserve. The warden tags six of the

elephants with small radio transmitters and returns them to the reserve. The next

month, he randomly selects ï¬ve elephants from the reserve. He counts how many

of these elephants are tagged. Assume that no elephants leave or enter the reserve,

or die or give birth, between the tagging and the selection; and that all outcomes

of the selection are equally likely. Find the probability that exactly two of the

selected elephants are tagged, giving the answer correct to 3 decimal places.


22

CHAPTER 1. BASIC IDEAS

Solution

The experiment consists of picking the ï¬ve elephants, not the original

choice of six elephants for tagging. Let S be the sample space. Then |S| = 24C5.

Let A be the event that two of the selected elephants are tagged. This involves

choosing two of the six tagged elephants and three of the eighteen untagged ones,

so |A| = 6C2 Â· 18C3. Thus

P(A) =

6C2 Â· 18C3

24C5

= 0.288

to 3 d.p.

Note:

Should the sample should be ordered or unordered? Since the answer

doesnâ€™t depend on the order in which the elephants are caught, an unordered sam-

ple is preferable. If you want to use an ordered sample, the calculation is

P(A) =

6P2 Â· 18P3 Â· 5C2

24P5

= 0.288,

since it is necessary to multiply by the 5C2 possible patterns of tagged and un-

tagged elephants in a sample of ï¬ve with two tagged.

Question

A couple are planning to have a family. They decide to stop having

children either when they have two boys or when they have four children. Sup-

pose that they are successful in their plan.

(a) Write down the sample space.

(b) Assume that, each time that they have a child, the probability that it is a

boy is 1/2, independent of all other times. Find P(E) and P(F) where

E = â€œthere are at least two girlsâ€, F = â€œthere are more girls than boysâ€.

Solution

(a) S = {BB,BGB,GBB,BGGB,GBGB,GGBB,BGGG,GBGG,

GGBG,GGGB,GGGG}.

(b) E = {BGGB,GBGB,GGBB,BGGG,GBGG,GGBG,GGGB,GGGG},

F = {BGGG,GBGG,GGBG,GGGB,GGGG}.

Now we have P(BB) = 1/4, P(BGB) = 1/8, P(BGGB) = 1/16, and similarly

for the other outcomes. So P(E) = 8/16 = 1/2, P(F) = 5/16.


Chapter 2

Conditional probability

In this chapter we develop the technique of conditional probability to deal with

cases where events are not independent.

2.1

What is conditional probability?

Alice and Bob are going out to dinner. They toss a fair coin â€˜best of threeâ€™ to

decide who pays: if there are more heads than tails in the three tosses then Alice

pays, otherwise Bob pays.

Clearly each has a 50% chance of paying. The sample space is

S = {HHH,HHT,HTH,HTT,THH,THT,TTH,TTT},

and the events â€˜Alice paysâ€™ and â€˜Bob paysâ€™ are respectively

A = {HHH,HHT,HTH,THH},

B = {HTT,THT,TTH,TTT}.

They toss the coin once and the result is heads; call this event E. How should

we now reassess their chances? We have

E = {HHH,HHT,HTH,HTT},

and if we are given the information that the result of the ï¬rst toss is heads, then E

now becomes the sample space of the experiment, since the outcomes not in E are

no longer possible. In the new experiment, the outcomes â€˜Alice paysâ€™ and â€˜Bob

paysâ€™ are

Aâˆ©E = {HHH,HHT,HTH},

Bâˆ©E = {HTT}.

23


24

CHAPTER 2. CONDITIONAL PROBABILITY

Thus the new probabilities that Alice and Bob pay for dinner are 3/4 and 1/4

respectively.

In general, suppose that we are given that an event E has occurred, and we

want to compute the probability that another event A occurs. In general, we can no

longer count, since the outcomes may not be equally likely. The correct deï¬nition

is as follows.

Let E be an event with non-zero probability, and let A be any event. The

conditional probability of A given E is deï¬ned as

P(A | E) = P(Aâˆ©E)

P(E)

.

Again I emphasise that this is the deï¬nition. If you are asked for the deï¬nition

of conditional probability, it is not enough to say â€œthe probability of A given that

E has occurredâ€, although this is the best way to understand it. There is no reason

why event E should occur before event A!

Note the vertical bar in the notation. This is P(A | E), not P(A/E) or P(A\E).

Note also that the deï¬nition only applies in the case where P(E) is not equal

to zero, since we have to divide by it, and this would make no sense if P(E) = 0.

To check the formula in our example:

P(A | E) = P(Aâˆ©E)

P(E)

= 3/8

1/2 = 3

4,

P(B | E) = P(Bâˆ©E)

P(E)

= 1/8

1/2 = 1

4.

It may seem like a small matter, but you should be familiar enough with this

formula that you can write it down without stopping to think about the names of

the events. Thus, for example,

P(A | B) = P(Aâˆ©B)

P(B)

if P(B) Ì¸= 0.

Example

A random car is chosen among all those passing through Trafalgar

Square on a certain day. The probability that the car is yellow is 3/100: the

probability that the driver is blonde is 1/5; and the probability that the car is

yellow and the driver is blonde is 1/50.

Find the conditional probability that the driver is blonde given that the car is

yellow.


2.2. GENETICS

25

Solution: If Y is the event â€˜the car is yellowâ€™ and B the event â€˜the driver is blondeâ€™,

then we are given that P(Y) = 0.03, P(B) = 0.2, and P(Y âˆ©B) = 0.02. So

P(B | Y) = P(Bâˆ©Y)

P(Y)

= 0.02

0.03 = 0.667

to 3 d.p. Note that we havenâ€™t used all the information given.

There is a connection between conditional probability and independence:

Proposition 2.1 Let A and B be events with P(B) Ì¸= 0. Then A and B are indepen-

dent if and only if P(A | B) = P(A).

Proof

The words â€˜if and only ifâ€™ tell us that we have two jobs to do: we have to

show that if A and B are independent, then P(A | B) = P(A); and that if P(A | B) =

P(A), then A and B are independent.

So ï¬rst suppose that A and B are independent. Remember that this means that

P(Aâˆ©B) = P(A)Â·P(B). Then

P(A | B) = P(Aâˆ©B)

P(B)

= P(A)Â·P(B)

P(B)

= P(A),

that is, P(A | B) = P(A), as we had to prove.

Now suppose that P(A | B) = P(A). In other words,

P(Aâˆ©B)

P(B)

= P(A),

using the deï¬nition of conditional probability. Now clearing fractions gives

P(Aâˆ©B) = P(A)Â·P(B),

which is just what the statement â€˜A and B are independentâ€™ means.

This proposition is most likely what people have in mind when they say â€˜A

and B are independent means that B has no effect on Aâ€™.

2.2

Genetics

Here is a simpliï¬ed version of how genes code eye colour, assuming only two

colours of eyes.

Each person has two genes for eye colour. Each gene is either B or b. A child

receives one gene from each of its parents. The gene it receives from its father

is one of its fatherâ€™s two genes, each with probability 1/2; and similarly for its

mother. The genes received from father and mother are independent.

If your genes are BB or Bb or bB, you have brown eyes; if your genes are bb,

you have blue eyes.


26

CHAPTER 2. CONDITIONAL PROBABILITY

Example

Suppose that John has brown eyes. So do both of Johnâ€™s parents. His

sister has blue eyes. What is the probability that Johnâ€™s genes are BB?

Solution

Johnâ€™s sister has genes bb, so one b must have come from each parent.

Thus each of Johnâ€™s parents is Bb or bB; we may assume Bb. So the possibilities

for John are (writing the gene from his father ï¬rst)

BB,Bb,bB,bb

each with probability 1/4. (For example, John gets his fatherâ€™s B gene with prob-

ability 1/2 and his motherâ€™s B gene with probability 1/2, and these are indepen-

dent, so the probability that he gets BB is 1/4. Similarly for the other combina-

tions.)

Let X be the event â€˜John has BB genesâ€™ and Y the event â€˜John has brown

eyesâ€™. Then X = {BB} and Y = {BB,Bb,bB}. The question asks us to calculate

P(X | Y). This is given by

P(X | Y) = P(X âˆ©Y)

P(Y)

= 1/4

3/4 = 1/3.

2.3

The Theorem of Total Probability

Sometimes we are faced with a situation where we do not know the probability of

an event B, but we know what its probability would be if we were sure that some

other event had occurred.

Example

An ice-cream seller has to decide whether to order more stock for the

Bank Holiday weekend. He estimates that, if the weather is sunny, he has a 90%

chance of selling all his stock; if it is cloudy, his chance is 60%; and if it rains, his

chance is only 20%. According to the weather forecast, the probability of sunshine

is 30%, the probability of cloud is 45%, and the probability of rain is 25%. (We

assume that these are all the possible outcomes, so that their probabilities must

add up to 100%.) What is the overall probability that the salesman will sell all his

stock?

This problem is answered by the Theorem of Total Probability, which we now

state. First we need a deï¬nition. The events A1,A2,...,An form a partition of the

sample space if the following two conditions hold:

(a) the events are pairwise disjoint, that is, Ai âˆ©Aj = /0 for any pair of events Ai

and Aj;

(b) A1 âˆªA2 âˆªÂ·Â·Â·âˆªAn = S.


2.3. THE THEOREM OF TOTAL PROBABILITY

27

Another way of saying the same thing is that every outcome in the sample space

lies in exactly one of the events A1,A2,...,An. The picture shows the idea of a

partition.

A1

A2

...

An

Now we state and prove the Theorem of Total Probability.

Theorem 2.2 Let A1,A2,...,An form a partition of the sample space with P(Ai) Ì¸=

0 for all i, and let B be any event. Then

P(B) =

n

âˆ‘

i=1

P(B | Ai)Â·P(Ai).

Proof

By deï¬nition, P(B | Ai) = P(Bâˆ©Ai)/P(Ai). Multiplying up, we ï¬nd that

P(Bâˆ©Ai) = P(B | Ai)Â·P(Ai).

Now consider the events B âˆ© A1,B âˆ© A2,...,B âˆ© An. These events are pairwise

disjoint; for any outcome lying in both Bâˆ©Ai and Bâˆ©Aj would lie in both Ai and

Aj, and by assumption there are no such outcomes. Moreover, the union of all

these events is B, since every outcome lies in one of the Ai. So, by Axiom 3, we

conclude that

n

âˆ‘

i=1

P(Bâˆ©Ai) = P(B).

Substituting our expression for P(Bâˆ©Ai) gives the result.

A1

A2

...

An









B

Consider the ice-cream salesman at the start of this section. Let A1 be the

event â€˜it is sunnyâ€™, A2 the event â€˜it is cloudyâ€™, and A3 the event â€˜it is rainyâ€™. Then

A1, A2 and A3 form a partition of the sample space, and we are given that

P(A1) = 0.3,

P(A2) = 0.45,

P(A3) = 0.25.


28

CHAPTER 2. CONDITIONAL PROBABILITY

Let B be the event â€˜the salesman sells all his stockâ€™. The other information we are

given is that

P(B | A1) = 0.9,

P(B | A2) = 0.6,

P(B | A3) = 0.2.

By the Theorem of Total Probability,

P(B) = (0.9Ã—0.3)+(0.6Ã—0.45)+(0.2Ã—0.25) = 0.59.

You will now realise that the Theorem of Total Probability is really being used

when you calculate probabilities by tree diagrams. It is better to get into the habit

of using it directly, since it avoids any accidental assumptions of independence.

One special case of the Theorem of Total Probability is very commonly used,

and is worth stating in its own right. For any event A, the events A and Aâ€² form a

partition of S. To say that both A and Aâ€² have non-zero probability is just to say

that P(A) Ì¸= 0,1. Thus we have the following corollary:

Corollary 2.3 Let A and B be events, and suppose that P(A) Ì¸= 0,1. Then

P(B) = P(B | A)Â·P(A)+P(B | Aâ€²)Â·P(Aâ€²).

2.4

Sampling revisited

We can use the notion of conditional probability to treat sampling problems in-

volving ordered samples.

Example

I have two red pens, one green pen, and one blue pen. I select two

pens without replacement.

(a) What is the probability that the ï¬rst pen chosen is red?

(b) What is the probability that the second pen chosen is red?

For the ï¬rst pen, there are four pens of which two are red, so the chance of

selecting a red pen is 2/4 = 1/2.

For the second pen, we must separate cases. Let A1 be the event â€˜ï¬rst pen redâ€™,

A2 the event â€˜ï¬rst pen greenâ€™ and A3 the event â€˜ï¬rst pen blueâ€™. Then P(A1) = 1/2,

P(A2) = P(A3) = 1/4 (arguing as above). Let B be the event â€˜second pen redâ€™.

If the ï¬rst pen is red, then only one of the three remaining pens is red, so that

P(B | A1) = 1/3. On the other hand, if the ï¬rst pen is green or blue, then two of

the remaining pens are red, so P(B | A2) = P(B | A3) = 2/3.


2.5. BAYESâ€™ THEOREM

29

By the Theorem of Total Probability,

P(B)

=

P(B | A1)P(A1)+P(B | A2)P(A2)+P(B | A3)P(A3)

=

(1/3)Ã—(1/2)+(2/3)Ã—(1/4)+(2/3)Ã—(1/4)

=

1/2.

We have reached by a roundabout argument a conclusion which you might

think to be obvious. If we have no information about the ï¬rst pen, then the second

pen is equally likely to be any one of the four, and the probability should be 1/2,

just as for the ï¬rst pen. This argument happens to be correct. But, until your

ability to distinguish between correct arguments and plausible-looking false ones

is very well developed, you may be safer to stick to the calculation that we did.

Beware of obvious-looking arguments in probability! Many clever people have

been caught out.

2.5

Bayesâ€™ Theorem

There is a very big difference between P(A | B) and P(B | A).

Suppose that a new test is developed to identify people who are liable to suffer

from some genetic disease in later life. Of course, no test is perfect; there will be

some carriers of the defective gene who test negative, and some non-carriers who

test positive. So, for example, let A be the event â€˜the patient is a carrierâ€™, and B

the event â€˜the test result is positiveâ€™.

The scientists who develop the test are concerned with the probabilities that

the test result is wrong, that is, with P(B | Aâ€²) and P(Bâ€² | A). However, a patient

who has taken the test has different concerns. If I tested positive, what is the

chance that I have the disease? If I tested negative, how sure can I be that I am not

a carrier? In other words, P(A | B) and P(Aâ€² | Bâ€²).

These conditional probabilities are related by Bayesâ€™ Theorem:

Theorem 2.4 Let A and B be events with non-zero probability. Then

P(A | B) = P(B | A)Â·P(A)

P(B)

.

The proof is not hard. We have

P(A | B)Â·P(B) = P(Aâˆ©B) = P(B | A)Â·P(A),

using the deï¬nition of conditional probability twice. (Note that we need both A

and B to have non-zero probability here.) Now divide this equation by P(B) to get

the result.


30

CHAPTER 2. CONDITIONAL PROBABILITY

If P(A) Ì¸= 0,1 and P(B) Ì¸= 0, then we can use Corollary 17 to write this as

P(A | B) =

P(B | A)Â·P(A)

P(B | A)Â·P(A)+P(B | Aâ€²)Â·P(Aâ€²).

Bayesâ€™ Theorem is often stated in this form.

Example

Consider the ice-cream salesman from Section 2.3. Given that he sold

all his stock of ice-cream, what is the probability that the weather was sunny?

(This question might be asked by the warehouse manager who doesnâ€™t know what

the weather was actually like.) Using the same notation that we used before, A1

is the event â€˜it is sunnyâ€™ and B the event â€˜the salesman sells all his stockâ€™. We are

asked for P(A1 | B). We were given that P(B | A1) = 0.9 and that P(A1) = 0.3, and

we calculated that P(B) = 0.59. So by Bayesâ€™ Theorem,

P(A1 | B) = P(B | A1)P(A1)

P(B)

= 0.9Ã—0.3

0.59

= 0.46

to 2 d.p.

Example

Consider the clinical test described at the start of this section. Suppose

that 1 in 1000 of the population is a carrier of the disease. Suppose also that the

probability that a carrier tests negative is 1%, while the probability that a non-

carrier tests positive is 5%. (A test achieving these values would be regarded as

very successful.) Let A be the event â€˜the patient is a carrierâ€™, and B the event â€˜the

test result is positiveâ€™. We are given that P(A) = 0.001 (so that P(Aâ€²) = 0.999),

and that

P(B | A) = 0.99,

P(B | Aâ€²) = 0.05.

(a) A patient has just had a positive test result. What is the probability that the

patient is a carrier? The answer is

P(A | B)

=

P(B | A)P(A)

P(B | A)P(A)+P(B | Aâ€²)P(Aâ€²)

=

0.99Ã—0.001

(0.99Ã—0.001)+(0.05Ã—0.999)

=

0.00099

0.05094 = 0.0194.

(b) A patient has just had a negative test result. What is the probability that the

patient is a carrier? The answer is

P(A | Bâ€²)

=

P(Bâ€² | A)P(A)

P(Bâ€² | A)P(A)+P(Bâ€² | Aâ€²)P(Aâ€²)


2.6. ITERATED CONDITIONAL PROBABILITY

31

=

0.01Ã—0.001

(0.01Ã—0.001)+(0.95Ã—0.999)

=

0.00001

0.94095 = 0.00001.

So a patient with a negative test result can be reassured; but a patient with a posi-

tive test result still has less than 2% chance of being a carrier, so is likely to worry

unnecessarily.

Of course, these calculations assume that the patient has been selected at ran-

dom from the population. If the patient has a family history of the disease, the

calculations would be quite different.

Example

2% of the population have a certain blood disease in a serious form;

10% have it in a mild form; and 88% donâ€™t have it at all. A new blood test is

developed; the probability of testing positive is 9/10 if the subject has the serious

form, 6/10 if the subject has the mild form, and 1/10 if the subject doesnâ€™t have

the disease.

I have just tested positive. What is the probability that I have the serious form

of the disease?

Let A1 be â€˜has disease in serious formâ€™, A2 be â€˜has disease in mild formâ€™, and

A3 be â€˜doesnâ€™t have diseaseâ€™. Let B be â€˜test positiveâ€™. Then we are given that A1,

A2, A3 form a partition and

P(A1) = 0.02

P(A2) = 0.1

P(A3) = 0.88

P(B | A1) = 0.9

P(B | A2) = 0.6

P(B | A3) = 0.1

Thus, by the Theorem of Total Probability,

P(B) = 0.9Ã—0.02+0.6Ã—0.1+0.1Ã—0.88 = 0.166,

and then by Bayesâ€™ Theorem,

P(A1 | B) = P(B | A1)P(A1)

P(B)

= 0.9Ã—0.02

0.166

= 0.108

to 3 d.p.

2.6

Iterated conditional probability

The conditional probability of C, given that both A and B have occurred, is just

P(C | Aâˆ©B). Sometimes instead we just write P(C | A,B). It is given by

P(C | A,B) = P(C âˆ©Aâˆ©B)

P(Aâˆ©B)

,


32

CHAPTER 2. CONDITIONAL PROBABILITY

so

P(Aâˆ©Bâˆ©C) = P(C | A,B)P(Aâˆ©B).

Now we also have

P(Aâˆ©B) = P(B | A)P(A),

so ï¬nally (assuming that P(Aâˆ©B) Ì¸= 0), we have

P(Aâˆ©Bâˆ©C) = P(C | A,B)P(B | A)P(A).

This generalises to any number of events:

Proposition 2.5 Let A1,...,An be events. Suppose that P(A1 âˆ© Â·Â·Â· âˆ© Anâˆ’1) Ì¸= 0.

Then

P(A1 âˆ©A2 âˆ©Â·Â·Â·âˆ©An) = P(An | A1,...,Anâˆ’1)Â·Â·Â·P(A2 | A1)P(A1).

We apply this to the birthday paradox.

The birthday paradox is the following statement:

If there are 23 or more people in a room, then the chances are better

than even that two of them have the same birthday.

To simplify the analysis, we ignore 29 February, and assume that the other 365

days are all equally likely as birthdays of a random person. (This is not quite true

but not inaccurate enough to have much effect on the conclusion.) Suppose that

we have n people p1, p2,..., pn. Let A2 be the event â€˜p2 has a different birthday

from p1â€™. Then P(A2) = 1 âˆ’

1

365, since whatever p1â€™s birthday is, there is a 1 in

365 chance that p2 will have the same birthday.

Let A3 be the event â€˜p3 has a different birthday from p1 and p2â€™. It is not

straightforward to evaluate P(A3), since we have to consider whether p1 and p2

have the same birthday or not. (See below). But we can calculate that P(A3 |

A2) = 1âˆ’

2

365, since if A2 occurs then p1 and p2 have birthdays on different days,

and A3 will occur only if p3â€™s birthday is on neither of these days. So

P(A2 âˆ©A3) = P(A2)P(A3 | A2) = (1âˆ’

1

365)(1âˆ’

2

365).

What is A2 âˆ© A3? It is simply the event that all three people have birthdays on

different days.

Now this process extends. If Ai denotes the event â€˜piâ€™s birthday is not on the

same day as any of p1,..., piâˆ’1â€™, then

P(Ai | A1,...,Aiâˆ’1) = 1âˆ’ iâˆ’1

365,


2.6. ITERATED CONDITIONAL PROBABILITY

33

and so by Proposition 2.5,

P(A1 âˆ©Â·Â·Â·âˆ©Ai) = (1âˆ’

1

365)(1âˆ’

2

365)Â·Â·Â·(1âˆ’ iâˆ’1

365).

Call this number qi; it is the probability that all of the people p1,..., pi have

their birthdays on different days.

The numbers qi decrease, since at each step we multiply by a factor less than 1.

So there will be some value of n such that

qnâˆ’1 &gt; 0.5,

qn â‰¤ 0.5,

that is, n is the smallest number of people for which the probability that they all

have different birthdays is less than 1/2, that is, the probability of at least one

coincidence is greater than 1/2.

By calculation, we ï¬nd that q22 = 0.5243, q23 = 0.4927 (to 4 d.p.); so 23

people are enough for the probability of coincidence to be greater than 1/2.

Now return to a question we left open before. What is the probability of the

event A3? (This is the event that p3 has a different birthday from both p1 and p2.)

If p1 and p2 have different birthdays, the probability is 1 âˆ’

2

365: this is the

calculation we already did. On the other hand, if p1 and p2 have the same birthday,

then the probability is 1âˆ’

1

365. These two numbers are P(A3 | A2) and P(A3 | Aâ€²

2)

respectively. So, by the Theorem of Total Probability,

P(A3)

=

P(A3 | A2)P(A2)+P(A3 | Aâ€²

2)P(Aâ€²

2)

=

(1âˆ’

2

365)(1âˆ’

1

365)+(1âˆ’

1

365) 1

365

=

0.9945

to 4 d.p.

Problem

How many people would you need to pick at random to ensure that

the chance of two of them being born in the same month are better than even?

Assuming all months equally likely, if Bi is the event that pi is born in a dif-

ferent month from any of p1,..., piâˆ’1, then as before we ï¬nd that

P(Bi | B1,Â·Â·Â·,Biâˆ’1) = 1âˆ’ iâˆ’1

12 ,

so

P(B1 âˆ©Â·Â·Â·âˆ©Bi) = (1âˆ’ 1

12)(1âˆ’ 2

12)(1âˆ’ iâˆ’1

12 ).

We calculate that this probability is

(11/12)Ã—(10/12)Ã—(9/12) = 0.5729


34

CHAPTER 2. CONDITIONAL PROBABILITY

for i = 4 and

(11/12)Ã—(10/12)Ã—(9/12)Ã—(8/12) = 0.3819

for i = 5. So, with ï¬ve people, it is more likely that two will have the same birth

month.

A true story.

Some years ago, in a probability class with only ten students, the

lecturer started discussing the Birthday Paradox. He said to the class, â€œI bet that

no two people in the room have the same birthdayâ€. He should have been on safe

ground, since q11 = 0.859. (Remember that there are eleven people in the room!)

However, a student in the back said â€œIâ€™ll take the betâ€, and after a moment all the

other students realised that the lecturer would certainly lose his wager. Why?

(Answer in the next chapter.)

2.7

Worked examples

Question

Each person has two genes for cystic ï¬brosis. Each gene is either N

or C. Each child receives one gene from each parent. If your genes are NN or NC

or CN then you are normal; if they are CC then you have cystic ï¬brosis.

(a) Neither of Sallyâ€™s parents has cystic ï¬brosis. Nor does she. However, Sallyâ€™s

sister Hannah does have cystic ï¬brosis. Find the probability that Sally has

at least one C gene (given that she does not have cystic ï¬brosis).

(b) In the general population the ratio of N genes to C genes is about 49 to 1.

You can assume that the two genes in a person are independent. Harry does

not have cystic ï¬brosis. Find the probability that he has at least one C gene

(given that he does not have cystic ï¬brosis).

(c) Harry and Sally plan to have a child. Find the probability that the child will

have cystic ï¬brosis (given that neither Harry nor Sally has it).

Solution

During this solution, we will use a number of times the following prin-

ciple. Let A and B be events with A âŠ† B. Then Aâˆ©B = A, and so

P(A | B) = P(Aâˆ©B)

P(B)

= P(A)

P(B).

(a) This is the same as the eye colour example discussed earlier. We are given

that Sallyâ€™s sister has genes CC, and one gene must come from each parent. But


2.7. WORKED EXAMPLES

35

neither parent is CC, so each parent is CN or NC. Now by the basic rules of

genetics, all the four combinations of genes for a child of these parents, namely

CC,CN,NC,NN, will have probability 1/4.

If S1 is the event â€˜Sally has at least one C geneâ€™, then S1 = {CN,NC,CC}; and

if S2 is the event â€˜Sally does not have cystic ï¬brosisâ€™, then S2 = {CN,NC,NN}.

Then

P(S1 | S2) = P(S1 âˆ©S2)

P(S2)

= 2/4

3/4 = 2

3.

(b) We know nothing speciï¬c about Harry, so we assume that his genes are

randomly and independently selected from the population. We are given that the

probability of a random gene being C or N is 1/50 and 49/50 respectively. Then

the probabilities of Harry having genes CC, CN, NC, NN are respectively (1/50)2,

(1/50) Â· (49/50), (49/50) Â· (1/50), and (49/50)2, respectively. So, if H1 is the

event â€˜Harry has at least one C geneâ€™, and H2 is the event â€˜Harry does not have

cystic ï¬brosisâ€™, then

P(H1 | H2) = P(H1 âˆ©H2)

P(H2)

=

(49/2500)+(49/2500)

(49/2500)+(49/2500)+(2401/2500) = 2

51.

(c) Let X be the event that Harryâ€™s and Sallyâ€™s child has cystic ï¬brosis. As in

(a), this can only occur if Harry and Sally both have CN or NC genes. That is,

X âŠ† S3 âˆ© H3, where S3 = S1 âˆ© S2 and H3 = H1 âˆ© H2. Now if Harry and Sally are

both CN or NC, these genes pass independently to the baby, and so

P(X | S3 âˆ©H3) =

P(X)

P(S3 âˆ©H3) = 1

4.

(Remember the principle that we started with!)

We are asked to ï¬nd P(X | S2 âˆ© H2), in other words (since X âŠ† S3 âˆ© H3 âŠ†

S2 âˆ©H2),

P(X)

P(S2 âˆ©H2).

Now Harryâ€™s and Sallyâ€™s genes are independent, so

P(S3 âˆ©H3)

=

P(S3)Â·P(H3),

P(S2 âˆ©H2)

=

P(S2)Â·P(H2).

Thus,

P(X)

P(S2 âˆ©H2)

=

P(X)

P(S3 âˆ©H3) Â· P(S3 âˆ©H3)

P(S2 âˆ©H2)


36

CHAPTER 2. CONDITIONAL PROBABILITY

=

1

4 Â· P(S1 âˆ©S2)

P(S2)

Â· P(H1 âˆ©H2)

P(H2)

=

1

4 Â·P(S1 | S2)Â·P(H1 | H2)

=

1

4 Â· 2

3 Â· 2

51

=

1

153.

I thank Eduardo Mendes for pointing out a mistake in my previous solution to

this problem.

Question

The Land of Nod lies in the monsoon zone, and has just two seasons,

Wet and Dry. The Wet season lasts for 1/3 of the year, and the Dry season for 2/3

of the year. During the Wet season, the probability that it is raining is 3/4; during

the Dry season, the probability that it is raining is 1/6.

(a) I visit the capital city, Oneirabad, on a random day of the year. What is the

probability that it is raining when I arrive?

(b) I visit Oneirabad on a random day, and it is raining when I arrive. Given this

information, what is the probability that my visit is during the Wet season?

(c) I visit Oneirabad on a random day, and it is raining when I arrive. Given this

information, what is the probability that it will be raining when I return to

Oneirabad in a yearâ€™s time?

(You may assume that in a yearâ€™s time the season will be the same as today but,

given the season, whether or not it is raining is independent of todayâ€™s weather.)

Solution

(a) Let W be the event â€˜it is the wet seasonâ€™, D the event â€˜it is the dry

seasonâ€™, and R the event â€˜it is raining when I arriveâ€™. We are given that P(W) =

1/3, P(D) = 2/3, P(R | W) = 3/4, P(R | D) = 1/6. By the ToTP,

P(R)

=

P(R | W)P(W)+P(R | D)P(D)

=

(3/4)Â·(1/3)+(1/6)Â·(2/3) = 13/36.

(b) By Bayesâ€™ Theorem,

P(W | R) = P(R | W)P(W)

P(R)

= (3/4)Â·(1/3)

13/36

= 9

13.


2.7. WORKED EXAMPLES

37

(c) Let Râ€² be the event â€˜it is raining in a yearâ€™s timeâ€™. The information we are

given is that P(Râˆ©Râ€² | W) = P(R | W)P(Râ€² | W) and similarly for D. Thus

P(Râˆ©Râ€²)

=

P(Râˆ©Râ€² | W)P(W)+P(Râˆ©Râ€² | D)P(D)

=

(3/4)2 Â·(1/3)+(1/6)2 Â·(2/3) = 89

432,

and so

P(Râ€² | R) = P(Râˆ©Râ€²)

P(R)

= 89/432

13/36 = 89

156.


38

CHAPTER 2. CONDITIONAL PROBABILITY


Chapter 3

Random variables

In this chapter we deï¬ne random variables and some related concepts such as

probability mass function, expected value, variance, and median; and look at some

particularly important types of random variables including the binomial, Poisson,

and normal.

3.1

What are random variables?

The Holy Roman Empire was, in the words of the historian Voltaire, â€œneither holy,

nor Roman, nor an empireâ€. Similarly, a random variable is neither random nor a

variable:

A random variable is a function deï¬ned on a sample space.

The values of the function can be anything at all, but for us they will always be

numbers. The standard abbreviation for â€˜random variableâ€™ is r.v.

Example

I select at random a student from the class and measure his or her

height in centimetres.

Here, the sample space is the set of students; the random variable is â€˜heightâ€™,

which is a function from the set of students to the real numbers: h(S) is the height

of student S in centimetres. (Remember that a function is nothing but a rule for

associating with each element of its domain set an element of its target or range

set. Here the domain set is the sample space S, the set of students in the class, and

the target space is the set of real numbers.)

Example

I throw a six-sided die twice; I am interested in the sum of the two

numbers. Here the sample space is

S = {(i, j) : 1 â‰¤ i, j â‰¤ 6},

39


40

CHAPTER 3. RANDOM VARIABLES

and the random variable F is given by F(i, j) = i + j. The target set is the set

{2,3,...,12}.

The two random variables in the above examples are representatives of the two

types of random variables that we will consider. These deï¬nitions are not quite

precise, but more examples should make the idea clearer.

A random variable F is discrete if the values it can take are separated by gaps.

For example, F is discrete if it can take only ï¬nitely many values (as in the second

example above, where the values are the integers from 2 to 12), or if the values of

F are integers (for example, the number of nuclear decays which take place in a

second in a sample of radioactive material â€“ the number is an integer but we canâ€™t

easily put an upper limit on it.)

A random variable is continuous if there are no gaps between its possible

values. In the ï¬rst example, the height of a student could in principle be any real

number between certain extreme limits. A random variable whose values range

over an interval of real numbers, or even over all real numbers, is continuous.

One could concoct random variables which are neither discrete nor continuous

(e.g. the possible, values could be 1, 2, 3, or any real number between 4 and 5),

but we will not consider such random variables.

We begin by considering discrete random variables.

3.2

Probability mass function

Let F be a discrete random variable. The most basic question we can ask is: given

any value a in the target set of F, what is the probability that F takes the value a?

In other words, if we consider the event

A = {x âˆˆ S : F(x) = a}

what is P(A)? (Remember that an event is a subset of the sample space.) Since

events of this kind are so important, we simplify the notation: we write

P(F = a)

in place of

P({x âˆˆ S : F(x) = a}).

(There is a fairly common convention in probability and statistics that random

variables are denoted by capital letters and their values by lower-case letters. In

fact, it is quite common to use the same letter in lower case for a value of the

random variable; thus, we would write P(F = f) in the above example. But

remember that this is only a convention, and you are not bound to it.)


3.3. EXPECTED VALUE AND VARIANCE

41

The probability mass function of a discrete random variable F is the function,

formula or table which gives the value of P(F = a) for each element a in the target

set of F. If F takes only a few values, it is convenient to list it in a table; otherwise

we should give a formula if possible. The standard abbreviation for â€˜probability

mass functionâ€™ is p.m.f.

Example

I toss a fair coin three times. The random variable X gives the number

of heads recorded. The possible values of X are 0,1,2,3, and its p.m.f. is

a

0

1

2

3

P(X = a)

1

8

3

8

3

8

1

8

For the sample space is {HHH,HHT,HTH,HTT,THH,THT,TTH,TTT}, and

each outcome is equally likely. The event X = 1, for example, when written as a

set of outcomes, is equal to {HTT,THT,TTH}, and has probability 3/8.

Two random variables X and Y are said to have the same distribution if the

values they take and their probability mass functions are equal. We write X âˆ¼ Y

in this case.

In the above example, if Y is the number of tails recorded during the experi-

ment, then X and Y have the same distribution, even though their actual values are

different (indeed, Y = 3âˆ’X).

3.3

Expected value and variance

Let X be a discrete random variable which takes the values a1,...,an. The ex-

pected value or mean of X is the number E(X) given by the formula

E(X) =

n

âˆ‘

i=1

aiP(X = ai).

That is, we multiply each value of X by the probability that X takes that value,

and sum these terms. The expected value is a kind of â€˜generalised averageâ€™: if

each of the values is equally likely, so that each has probability 1/n, then E(X) =

(a1 +Â·Â·Â·+an)/n, which is just the average of the values.

There is an interpretation of the expected value in terms of mechanics. If we

put a mass pi on the axis at position ai for i = 1,...,n, where pi = P(X = ai), then

the centre of mass of all these masses is at the point E(X).

If the random variable X takes inï¬nitely many values, say a1,a2,a3,..., then

we deï¬ne the expected value of X to be the inï¬nite sum

E(X) =

âˆ

âˆ‘

i=1

aiP(X = ai).


42

CHAPTER 3. RANDOM VARIABLES

Of course, now we have to worry about whether this means anything, that is,

whether this inï¬nite series is convergent. This is a question which is discussed

at great length in analysis. We wonâ€™t worry about it too much. Usually, discrete

random variables will only have ï¬nitely many values; in the few examples we

consider where there are inï¬nitely many values, the series will usually be a ge-

ometric series or something similar, which we know how to sum. In the proofs

below, we assume that the number of values is ï¬nite.

The variance of X is the number Var(X) given by

Var(X) = E(X2)âˆ’E(X)2.

Here, X2 is just the random variable whose values are the squares of the values of

X. Thus

E(X2) =

n

âˆ‘

i=1

a2

i P(X = ai)

(or an inï¬nite sum, if necessary). The next theorem shows that, if E(X) is a kind

of average of the values of X, then Var(X) is a measure of how spread-out the

values are around their average.

Proposition 3.1 Let X be a discrete random variable with E(X) = Âµ. Then

Var(X) = E((X âˆ’Âµ)2) =

n

âˆ‘

i=1

(ai âˆ’Âµ)2P(X = ai).

For the second term is equal to the third by deï¬nition, and the third is

n

âˆ‘

i=1

(ai âˆ’Âµ)2P(X = ai)

=

n

âˆ‘

i=1

(a2

i âˆ’2Âµai +Âµ2)P(X = ai)

=

ï¿½

n

âˆ‘

i=1

a2

i P(X = ai)

ï¿½

âˆ’2Âµ

ï¿½

n

âˆ‘

i=1

aiP(X = ai)

ï¿½

+Âµ2

ï¿½

n

âˆ‘

i=1

P(X = ai)

ï¿½

.

(What is happening here is that the entire sum consists of n rows with three terms

in each row. We add it up by columns instead of by rows, getting three parts with

n terms in each part.) Continuing, we ï¬nd

E((X âˆ’Âµ)2)

=

E(X2)âˆ’2ÂµE(X)+Âµ2

=

E(X2)âˆ’E(X)2,

and we are done. (Remember that E(X) = Âµ, and that âˆ‘n

i=1 P(X = ai) = 1 since

the events X = ai form a partition.)


3.4. JOINT P.M.F. OF TWO RANDOM VARIABLES

43

Some people take the conclusion of this proposition as the deï¬nition of vari-

ance.

Example

I toss a fair coin three times; X is the number of heads. What are the

expected value and variance of X?

E(X) = 0Ã—(1/8)+1Ã—(3/8)+2Ã—(3/8)+3Ã—(1/8) = 3/2,

Var(X) = 02 Ã—(1/8)+12 Ã—(3/8)+22 Ã—(3/8)+32 Ã—(1/8)âˆ’(3/2)2 = 3/4.

If we calculate the variance using Proposition 3.1, we get

Var(X) =

ï¿½

âˆ’3

2

ï¿½2

Ã— 1

8 +

ï¿½

âˆ’1

2

ï¿½2

Ã— 3

8 +

ï¿½1

2

ï¿½2

Ã— 3

8 +

ï¿½3

2

ï¿½2

Ã— 1

8 = 3

4.

Two properties of expected value and variance can be used as a check on your

calculations.

â€¢ The expected value of X always lies between the smallest and largest values

of X.

â€¢ The variance of X is never negative. (For the formula in Proposition 3.1 is

a sum of terms, each of the form (ai âˆ’ Âµ)2 (a square, hence non-negative)

times P(X = ai) (a probability, hence non-negative).

3.4

Joint p.m.f. of two random variables

Let X be a random variable taking the values a1,...,an, and let Y be a random

variable taking the values b1,...,bm. We say that X and Y are independent if, for

any possible values i and j, we have

P(X = ai,Y = bj) = P(X = ai)Â·P(Y = bj).

Here P(X = ai,Y = bj) means the probability of the event that X takes the value

ai and Y takes the value bj. So we could re-state the deï¬nition as follows:

The random variables X and Y are independent if, for any value ai of

X and any value bj of Y, the events X = ai and Y = bj are independent

(events).

Note the difference between â€˜independent eventsâ€™ and â€˜independent random vari-

ablesâ€™.


44

CHAPTER 3. RANDOM VARIABLES

Example

In Chapter 2, we saw the following: I have two red pens, one green

pen, and one blue pen. I select two pens without replacement. Then the events

â€˜exactly one red pen selectedâ€™ and â€˜exactly one green pen selectedâ€™ turned out to

be independent. Let X be the number of red pens selected, and Y the number of

green pens selected. Then

P(X = 1,Y = 1) = P(X = 1)Â·P(Y = 1).

Are X and Y independent random variables?

No, because P(X = 2) = 1/6, P(Y = 1) = 1/2, but P(X = 2,Y = 1) = 0 (it is

impossible to have two red and one green in a sample of two).

On the other hand, if I roll a die twice, and X and Y are the numbers that come

up on the ï¬rst and second throws, then X and Y will be independent, even if the

die is not fair (so that the outcomes are not all equally likely).

If we have more than two random variables (for example X,Y,Z), we say that

they are mutually independent if the events that the random variables take speciï¬c

values (for example, X = a, Y = b, Z = c) are mutually independent. (You may

want to revise the material on mutually independent events.)

What about the expected values of random variables? For expected value, it is

easy, but for variance it helps if the variables are independent:

Theorem 3.2 Let X and Y be random variables.

(a) E(X +Y) = E(X)+E(Y).

(b) If X and Y are independent, then Var(X +Y) = Var(X)+Var(Y).

We will see the proof later.

If two random variables X and Y are not independent, then knowing the p.m.f.

of each variable does not tell the whole story. The joint probability mass function

(or joint p.m.f.) of X and Y is the table giving, for each value ai of X and each

value bj of Y, the probability that X = ai and Y = bj. We arrange the table so

that the rows correspond to the values of X and the columns to the values of Y.

Note that summing the entries in the row corresponding to the value ai gives the

probability that X = ai; that is, the row sums form the p.m.f. of X. Similarly the

column sums form the p.m.f. of Y. (The row and column sums are sometimes

called the marginal distributions or marginals.)

In particular, X and Y are independent r.v.s if and only if each entry of the

table is equal to the product of its row sum and its column sum.


3.4. JOINT P.M.F. OF TWO RANDOM VARIABLES

45

Example

I have two red pens, one green pen, and one blue pen, and I choose

two pens without replacement. Let X be the number of red pens that I choose and

Y the number of green pens. Then the joint p.m.f. of X and Y is given by the

following table:

Y

0

1

0

0

1

6

X

1

1

3

1

3

2

1

6

0

The row and column sums give us the p.m.f.s for X and Y:

a

0

1

2

P(X = a)

1

6

2

3

1

6

b

0

1

P(Y = b)

1

2

1

2

Now we give the proof of Theorem 3.2.

We consider the joint p.m.f. of X and Y. The random variable X +Y takes the

values ai + b j for i = 1,...,n and j = 1,...,m. Now the probability that it takes

a given value ck is the sum of the probabilities P(X = ai,Y = bj) over all i and j

such that ai +b j = ck. Thus,

E(X +Y)

= âˆ‘

k

ckP(X +Y = ck)

=

n

âˆ‘

i=1

m

âˆ‘

j=1

(ai +b j)P(X = ai,Y = bj)

=

ï¿½

n

âˆ‘

i=1

ai

m

âˆ‘

j=1

P(X = ai,Y = bj)

ï¿½

+

ï¿½

m

âˆ‘

j=1

bj

n

âˆ‘

i=1

P(X = ai,Y = bj)

ï¿½

.

Now âˆ‘m

j=1 P(X = ai,Y = b j) is a row sum of the joint p.m.f. table, so is equal to

P(X = ai), and similarly âˆ‘n

i=1 P(X = ai,Y = bj) is a column sum and is equal to

P(Y = bj). So

E(X +Y)

=

n

âˆ‘

i=1

aiP(X = ai)+

m

âˆ‘

j=1

bjP(Y = bj)

=

E(X)+E(Y).

The variance is a bit trickier. First we calculate

E((X +Y)2) = E(X2 +2XY +Y 2) = E(X2)+2E(XY)+E(Y 2),


46

CHAPTER 3. RANDOM VARIABLES

using part (a) of the Theorem. We have to consider the term E(XY). For this, we

have to make the assumption that X and Y are independent, that is,

P(X = a1,Y = bj) = P(X = ai)Â·P(Y = bj).

As before, we have

E(XY)

=

n

âˆ‘

i=1

m

âˆ‘

j=1

aibjP(X = ai,Y = bj)

=

n

âˆ‘

i=1

n

âˆ‘

j=1

aibjP(X = ai)P(Y = bj)

=

ï¿½

n

âˆ‘

i=1

aiP(X = ai)

ï¿½

Â·

ï¿½

m

âˆ‘

j=1

bjP(Y = bj)

ï¿½

=

E(X)Â·E(Y).

So

Var(X +Y)

=

E((X +Y)2)âˆ’(E(X +Y))2

=

(E(X2)+2E(XY)+E(Y 2))âˆ’(E(X)2 +2E(X)E(Y)+E(Y)2)

=

(E(X2)âˆ’E(X)2)+2(E(XY)âˆ’E(X)E(Y))+(E(Y 2)âˆ’E(Y)2)

=

Var(X)+Var(Y).

To ï¬nish this section, we consider constant random variables. (If the thought

of a â€˜constant variableâ€™ worries you, remember that a random variable is not a

variable at all but a function, and there is nothing amiss with a constant function.)

Proposition 3.3 Let C be a constant random variable with value c. Let X be any

random variable.

(a) E(C) = c, Var(C) = 0.

(b) E(X +c) = E(X)+c, Var(X +c) = Var(X).

(c) E(cX) = cE(X), Var(cX) = c2 Var(X).

Proof

(a) The random variable C takes the single value c with P(C = c) = 1. So

E(C) = cÂ·1 = c. Also,

Var(C) = E(C2)âˆ’E(C)2 = c2 âˆ’c2 = 0.

(For C2 is a constant random variable with value c2.)


3.5. SOME DISCRETE RANDOM VARIABLES

47

(b) This follows immediately from Theorem 3.2, once we observe that the

constant random variable C and any random variable X are independent. (This is

true because P(X = a,C = c) = P(X = a)Â·1.) Then

E(X +c) = E(X)+E(C) = E(X)+c,

Var(X +c) = Var(X)+Var(C) = Var(X).

(c) If a1,...,an are the values of X, then ca1,...,can are the values of cX, and

P(cX = cai) = P(x = ai). So

E(cX)

=

n

âˆ‘

i=1

caiP(cX = cai)

=

c

n

âˆ‘

i=1

aiP(X = ai)

=

cE(X).

Then

Var(cX)

=

E(c2X2)âˆ’E(cX)2

=

c2E(X2)âˆ’(cE(X))2

=

c2(E(X2)âˆ’E(X)2)

=

c2 Var(X).

3.5

Some discrete random variables

We now look at ï¬ve types of discrete random variables, each depending on one or

more parameters. We describe for each type the situations in which it arises, and

give the p.m.f., the expected value, and the variance. If the variable is tabulated

in the New Cambridge Statistical Tables, we give the table number, and some

examples of using the tables. You should have a copy of the tables to follow the

examples.

A summary of this information is given in Appendix B.

Before we begin, a comment on the New Cambridge Statistical Tables. They

donâ€™t give the probability mass function (or p.m.f.), but a closely related function

called the cumulative distribution function. It is deï¬ned for a discrete random

variable as follows.

Let X be a random variable taking values a1,a2,...,an. We assume that these

are arranged in ascending order: a1 &lt; a2 &lt; Â·Â·Â· &lt; an. The cumulative distribution

function, or c.d.f., of X is given by

FX(ai) = P(X â‰¤ ai).


48

CHAPTER 3. RANDOM VARIABLES

We see that it can be expressed in terms of the p.m.f. of X as follows:

FX(ai) = P(X = a1)+Â·Â·Â·+P(X = ai) =

i

âˆ‘

j=1

P(X = aj).

In the other direction, we cn recover the p.m.f. from the c.d.f.:

P(X = ai) = FX(ai)âˆ’FX(aiâˆ’1).

We wonâ€™t use the c.d.f. of a discrete random variable except for looking up

the tables. It is much more important for continuous random variables!

Bernoulli random variable Bernoulli(p)

A Bernoulli random variable is the simplest type of all. It only takes two values,

0 and 1. So its p.m.f. looks as follows:

x

0

1

P(X = x)

q

p

Here, p is the probability that X = 1; it can be any number between 0 and 1.

Necessarily q (the probability that X = 0) is equal to 1 âˆ’ p. So p determines

everything.

For a Bernoulli random variable X, we sometimes describe the experiment as

a â€˜trialâ€™, the event X = 1 asâ€˜successâ€™, and the event X = 0 as â€˜failureâ€™.

For example, if a biased coin has probability p of coming down heads, then

the number of heads that we get when we toss the coin once is a Bernoulli(p)

random variable.

More generally, let A be any event in a probability space S. With A, we asso-

ciate a random variable IA (remember that a random variable is just a function on

S) by the rule

IA(s) =

ï¿½1

if s âˆˆ A;

0

if s /âˆˆ A.

The random variable IA is called the indicator variable of A, because its value

indicates whether or not A occurred. It is a Bernoulli(p) random variable, where

p = P(A). (The event IA = 1 is just the event A.) Some people write 11A instead of

IA.

Calculation of the expected value and variance of a Bernoulli random variable

is easy. Let X âˆ¼ Bernoulli(p). (Remember that âˆ¼ means â€œhas the same p.m.f.

asâ€.)

E(X) = 0Â·q+1Â· p = p;

Var(X) = 02 Â·q+12 Â· pâˆ’ p2 = pâˆ’ p2 = pq.

(Remember that q = 1âˆ’ p.)


3.5. SOME DISCRETE RANDOM VARIABLES

49

Binomial random variable Bin(n, p)

Remember that for a Bernoulli random variable, we describe the event X = 1 as a

â€˜successâ€™. Now a binomial random variable counts the number of successes in n

independent trials each associated with a Bernoulli(p) random variable.

For example, suppose that we have a biased coin for which the probability of

heads is p. We toss the coin n times and count the number of heads obtained. This

number is a Bin(n, p) random variable.

A Bin(n, p) random variable X takes the values 0,1,2,...,n, and the p.m.f. of

X is given by

P(X = k) = nCkqnâˆ’kpk

for k = 0,1,2,...,n, where q = 1âˆ’ p. This is because there are nCk different ways

of obtaining k heads in a sequence of n throws (the number of choices of the k

positions in which the heads occur), and the probability of getting k heads and

nâˆ’k tails in a particular order is qnâˆ’kpk.

Note that we have given a formula rather than a table here. For small values

we could tabulate the results; for example, for Bin(4, p):

k

0

1

2

3

4

P(X = k)

q4

4q3p

6q2p2

4qp3

p4

Note: when we add up all the probabilities in the table, we get

n

âˆ‘

k=0

nCkqnâˆ’kpk = (q+ p)n = 1,

as it should be: here we used the binomial theorem

(x+y)n =

n

âˆ‘

k=0

nCkxnâˆ’kyk.

(This argument explains the name of the binomial random variable!)

If X âˆ¼ Bin(n, p), then

E(X) = np,

Var(X) = npq.

There are two ways to prove this, an easy way and a harder way. The easy way

only works for the binomial, but the harder way is useful for many random vari-

ables. However, you can skip it if you wish: I have set it in smaller type for this

reason.

Here is the easy method. We have a coin with probability p of coming down

heads, and we toss it n times and count the number X of heads. Then X is our

Bin(n, p) random variable. Let Xk be the random variable deï¬ned by

Xk =

ï¿½1

if we get heads on the kth toss,

0

if we get tails on the kth toss.


50

CHAPTER 3. RANDOM VARIABLES

In other words, Xi is the indicator variable of the event â€˜heads on the kth tossâ€™.

Now we have

X = X1 +X2 +Â·Â·Â·+Xn

(can you see why?), and X1,...,Xn are independent Bernoulli(p) random variables

(since they are deï¬ned by different tosses of a coin). So, as we saw earlier, E(Xi) =

p, Var(Xi) = pq. Then, by Theorem 21, since the variables are independent, we

have

E(X)

=

p+ p+Â·Â·Â·+ p = np,

Var(X)

=

pq+ pq+Â·Â·Â·+ pq = npq.

The other method uses a gadget called the probability generating function. We only use it

here for calculating expected values and variances, but if you learn more probability theory you

will see other uses for it. Let X be a random variable whose values are non-negative integers. (We

donâ€™t insist that it takes all possible values; this method is ï¬ne for the binomial Bin(n, p), which

takes values between 0 and n. To save space, we write pk for the probability P(X = k). Now the

probability generating function of X is the power series

GX(x) = âˆ‘ pkxk.

(The sum is over all values k taken by X.)

We use the notation [F(x)]x=1 for the result of substituting x = 1 in the series F(x).

Proposition 3.4 Let GX(x) be the probability generating function of a random variable X. Then

(a) [GX(x)]x=1 = 1;

(b) E(X) =

ï¿½ d

dxGX(x)

ï¿½

x=1;

(c) Var(X) =

ï¿½

d2

dx2 GX(x)

ï¿½

x=1 +E(X)âˆ’E(X)2.

Part (a) is just the statement that probabilities add up to 1: when we substitute x = 1 in the

power series for GX(x) we just get âˆ‘ pk.

For part (b), when we differentiate the series term-by-term (you will learn later in Analysis

that this is OK), we get

d

dxGX(x) = âˆ‘kpkxkâˆ’1.

Now putting x = 1 in this series we get

âˆ‘kpk = E(X).

For part (c), differentiating twice gives

d2

dx2 GX(x) = âˆ‘k(k âˆ’1)pkxkâˆ’2.

Now putting x = 1 in this series we get

âˆ‘k(k âˆ’1)pk = âˆ‘k2pk âˆ’âˆ‘kpk = E(X2)âˆ’E(X).

Adding E(X) and subtracting E(X)2 gives E(X2)âˆ’E(X)2, which by deï¬nition is Var(X).


3.5. SOME DISCRETE RANDOM VARIABLES

51

Now let us appply this to the binomial random variable X âˆ¼ Bin(n, p). We have

pk = P(X = k) = nCkqnâˆ’kpk,

so the probability generating function is

n

âˆ‘

k=0

nCkqnâˆ’kpkxk = (q+ px)n,

by the Binomial Theorem. Putting x = 1 gives (q+ p)n = 1, in agreement with Proposition 3.4(a).

Differentiating once, using the Chain Rule, we get np(q+ px)nâˆ’1. Putting x = 1 we ï¬nd that

E(X) = np.

Differentiating again, we get n(nâˆ’1)p2(q+ px)nâˆ’2. Putting x = 1 gives n(nâˆ’1)p2. Now adding

E(X)âˆ’E(X)2, we get

Var(X) = n(nâˆ’1)p2 +npâˆ’n2p2 = npâˆ’np2 = npq.

The binomial random variable is tabulated in Table 1 of the Cambridge Statis-

tical Tables [1]. As explained earlier, the tables give the cumulative distribution

function.

For example, suppose that the probability that a certain coin comes down

heads is 0.45. If the coin is tossed 15 times, what is the probability of ï¬ve or

fewer heads? Turning to the page n = 15 in Table 1 and looking at the row 0.45,

you read off the answer 0.2608. What is the probability of exactly ï¬ve heads? This

is P(5 or fewer)âˆ’P(4 or fewer), and from tables the answer is 0.2608âˆ’0.1204 =

0.1404.

The tables only go up to p = 0.5. For larger values of p, use the fact that the

number of failures in Bin(n, p) is equal to the number of successes in Bin(n,1 âˆ’

p). So the probability of ï¬ve heads in 15 tosses of a coin with p = 0.55 is 0.9745âˆ’

0.9231 = 0.0514.

Another interpretation of the binomial random variable concerns sampling.

Suppose that we have N balls in a box, of which M are red. We sample n balls

from the box with replacement; let the random variable X be the number of red

balls in the sample. What is the distribution of X? Since each ball has probability

M/N of being red, and different choices are independent, X âˆ¼ Bin(n, p), where

p = M/N is the proportion of red balls in the sample.

What about sampling without replacement? This leads us to our next random

variable:

Hypergeometric random variable Hg(n,M,N)

Suppose that we have N balls in a box, of which M are red. We sample n balls

from the box without replacement. Let the random variable X be the number of


52

CHAPTER 3. RANDOM VARIABLES

red balls in the sample. Such an X is called a hypergeometric random variable

Hg(n,M,N).

The random variable X can take any of the values 0,1,2,...,n. Its p.m.f. is

given by the formula

P(X = k) =

MCk Â· Nâˆ’MCnâˆ’k

NCn

.

For the number of samples of n balls from N is NCn; the number of ways of

choosing k of the M red balls and nâˆ’k of the N âˆ’M others is MCk Â· Nâˆ’MCnâˆ’k; and

all choices are equally likely.

The expected value and variance of a hypergeometric random variable are as

follows (we wonâ€™t go into the proofs):

E(X) = n

ï¿½M

N

ï¿½

,

Var(X) = n

ï¿½M

N

ï¿½ï¿½N âˆ’M

N

ï¿½ï¿½N âˆ’n

N âˆ’1

ï¿½

.

You should compare these to the values for a binomial random variable. If we

let p = M/N be the proportion of red balls in the hat, then E(X) = np, and Var(X)

is equal to npq multiplied by a â€˜correction factorâ€™ (N âˆ’n)/(N âˆ’1).

In particular, if the numbers M and N âˆ’ M of red and non-red balls in the

hat are both very large compared to the size n of the sample, then the difference

between sampling with and without replacement is very small, and indeed the

â€˜correction factorâ€™ is close to 1. So we can say that Hg(n,M,N) is approximately

Bin(n,M/N) if n is small compared to M and N âˆ’M.

Consider our example of choosing two pens from four, where two pens are

red, one green, and one blue. The number X of red pens is a Hg(2,2,4) random

variable. We calculated earlier that P(X = 0) = 1/6, P(X = 1) = 2/3 and P(X =

2) = 1/6. From this we ï¬nd by direct calculation that E(X) = 1 and Var(X) = 1/3.

These agree with the formulae above.

Geometric random variable Geom(p)

The geometric random variable is like the binomial but with a different stopping

rule. We have again a coin whose probability of heads is p. Now, instead of

tossing it a ï¬xed number of times and counting the heads, we toss it until it comes

down heads for the ï¬rst time, and count the number of times we have tossed

the coin. Thus, the values of the variable are the positive integers 1,,2,3,... (In

theory we might never get a head and toss the coin inï¬nitely often, but if p &gt; 0

this possibility is â€˜inï¬nitely unlikelyâ€™, i.e. has probability zero, as we will see.)

We always assume that 0 &lt; p &lt; 1.

More generally, the number of independent Bernoulli trials required until the

ï¬rst success is obtained is a geometric random variable.


3.5. SOME DISCRETE RANDOM VARIABLES

53

The p.m.f of a Geom(p) random variable is given by

P(X = k) = qkâˆ’1p,

where q = 1 âˆ’ p. For the event X = k means that we get tails on the ï¬rst k âˆ’ 1

tosses and heads on the kth, and this event has probability qkâˆ’1p, since â€˜tailsâ€™ has

probability q and different tosses are independent.

Letâ€™s add up these probabilities:

âˆ

âˆ‘

k=1

qkâˆ’1p = p+qp+q2p+Â·Â·Â· =

p

1âˆ’q = 1,

since the series is a geometric progression with ï¬rst term p and common ratio

q, where q &lt; 1. (Just as the binomial theorem shows that probabilities sum to 1

for a binomial random variable, and gives its name to the random variable, so the

geometric progression does for the geometric random variable.)

We calculate the expected value and the variance using the probability gener-

ating function. If X âˆ¼ Geom(p), the result will be that

E(X) = 1/p,

Var(X) = q/p2.

We have

GX(x) =

âˆ

âˆ‘

k=1

qkâˆ’1pxk =

px

1âˆ’qx,

again by summing a geometric progression. Differentiating, we get

d

dxGX(x) = (1âˆ’qx)p+ pxq

(1âˆ’qx)2

=

p

(1âˆ’qx)2 .

Putting x = 1, we obtain

E(X) =

p

(1âˆ’q)2 = 1

p.

Differentiating again gives 2pq/(1âˆ’qx)3, so

Var(X) = 2pq

p3 + 1

p âˆ’ 1

p2 = q

p2 .

For example, if we toss a fair coin until heads is obtained, the expected number

of tosses until the ï¬rst head is 2 (so the expected number of tails is 1); and the

variance of this number is also 2.


54

CHAPTER 3. RANDOM VARIABLES

Poisson random variable Poisson(Î»)

The Poisson random variable, unlike the ones we have seen before, is very closely

connected with continuous things.

Suppose that â€˜incidentsâ€™ occur at random times, but at a steady rate overall.

The best example is radioactive decay: atomic nuclei decay randomly, but the

average number Î» which will decay in a given interval is constant. The Poisson

random variabe X counts the number of â€˜incidentsâ€™ which occur in a given interval.

So if, on average, there are 2.4 nuclear decays per second, then the number of

decays in one second starting now is a Poisson(2.4) random variable.

Another example might be the number of telephone calls a minute to a busy

telephone number.

Although we will not prove it, the p.m.f. for a Poisson(Î») variable X is given

by the formula

P(X = k) = Î»k

k! eâˆ’Î».

Letâ€™s check that these probabilities add up to one. We get

ï¿½

âˆ

âˆ‘

k=0

Î»k

k!

ï¿½

eâˆ’Î» = eÎ» Â·eâˆ’Î» = 1,

since the expression in brackets is the sum of the exponential series.

By analogy with what happened for the binomial and geometric random vari-

ables, you might have expected that this random variable would be called â€˜expo-

nentialâ€™. Unfortunately, this name has been given to a closely-related continuous

random variable which we will meet later. However, if you speak a little French,

you might use as a mnemonic the fact that if I go ï¬shing, and the ï¬sh are biting at

the rate of Î» per hour on average, then the number of ï¬sh I will catch in the next

hour is a Poisson(Î») random variable.

The expected value and variance of a Poisson(Î») random variable X are given

by

E(X) = Var(X) = Î».

Again we use the probability generating function. If X âˆ¼ Poisson(Î»), then

GX(x) =

âˆ

âˆ‘

k=0

(Î»x)k

k!

eâˆ’Î» = eÎ»(xâˆ’1),

again using the series for the exponential function.

Differentiation gives Î»eÎ»(xâˆ’1), so E(X) = Î». Differentiating again gives Î»2eÎ»(xâˆ’1), so

Var(X) = Î»2 +Î»âˆ’Î»2 = Î».


3.6. CONTINUOUS RANDOM VARIABLES

55

The cumulative distribution function of a Poisson random variable is tabulated

in Table 2 of the New Cambridge Statistical Tables. So, for example, we ï¬nd from

the tables that, if 2.4 ï¬sh bite per hour on average, then the probability that I will

catch no ï¬sh in the next hour is 0.0907, while the probability that I catch at ï¬ve or

fewer is 0.9643 (so that the probability that I catch six or more is 0.0357).

There is another situation in which the Poisson distribution arises. Suppose I

am looking for some very rare event which only occurs once in 1000 trials on av-

erage. So I conduct 1000 independent trials. How many occurrences of the event

do I see? This number is really a binomial random variable Bin(1000,1/1000).

But it turns out to be Poisson(1), to a very good approximation. So, for example,

the probability that the event doesnâ€™t occur is about 1/e.

The general rule is:

If n is large, p is small, and np = Î», then Bin(n, p) can be approxi-

mated by Poisson(Î»).

3.6

Continuous random variables

We havenâ€™t so far really explained what a continuous random variable is. Its target

set is the set of real numbers, or perhaps the non-negative real numbers or just an

interval. The crucial property is that, for any real number a, we have (X = a) = 0;

that is, the probability that the height of a random student, or the time I have to

wait for a bus, is precisely a, is zero. So we canâ€™t use the probability mass function

for continuous random variables; it would always be zero and give no information.

We use the cumulative distribution function or c.d.f. instead. Remember from

last week that the c.d.f. of the random variable X is the function FX deï¬ned by

FX(x) = P(X â‰¤ x).

Note: The name of the function is FX; the lower case x refers to the argument

of the function, the number which is substituted into the function. It is common

but not universal to use as the argument the lower-case version of the name of the

random variable, as here. Note that FX(y) is the same function written in terms of

the variable y instead of x, whereas FY(x) is the c.d.f. of the random variable Y

(which might be a completely different function.)

Now let X be a continuous random variable. Then, since the probability that

X takes the precise value x is zero, there is no difference between P(X â‰¤ x) and

P(X &lt; x).

Proposition 3.5 The c.d.f. is an increasing function (this means that FX(x) â‰¤

FX(y) if x &lt; y), and approaches the limits 0 as x â†’ âˆ’âˆ and 1 as x â†’ âˆ.


56

CHAPTER 3. RANDOM VARIABLES

The function is increasing because, if x &lt; y, then

FX(y)âˆ’FX(x) = P(X â‰¤ y)âˆ’P(X â‰¤ x) = P(x &lt; X â‰¤ y) â‰¥ 0.

Also FX(âˆ) = 1 because X must certainly take some ï¬nite value; and FX(âˆ’âˆ) = 0

because no value is smaller than âˆ’âˆ!

Another important function is the probability density function fX. It is ob-

tained by differentiating the c.d.f.:

fX(x) = d

dxFX(x).

Now fX(x) is non-negative, since it is the derivative of an increasing function. If

we know fX(x), then FX is obtained by integrating. Because FX(âˆ’âˆ) = 0, we

have

FX(x) =

Z x

âˆ’âˆ fX(t)dt.

Note the use of the â€œdummy variableâ€ t in this integral. Note also that

P(a â‰¤ X â‰¤ b) = FX(b)âˆ’FX(a) =

Z b

a fX(t)dt.

You can think of the p.d.f. like this: the probability that the value of X lies in a

very small interval from x to x + h is approximately fX(x) Â· h. So, although the

probability of getting exactly the value x is zero, the probability of being close to

x is proportional to fX(x).

There is a mechanical analogy which you may ï¬nd helpful. Remember that

we modelled a discrete random variable X by placing at each value a of X a mass

equal to P(X = a). Then the total mass is one, and the expected value of X is

the centre of mass. For a continuous random variable, imagine instead a wire of

variable thickness, so that the density of the wire (mass per unit length) at the

point x is equal to fX(x). Then again the total mass is one; the mass to the left of

x is FX(x); and again it will hold that the centre of mass is at E(X).

Most facts about continuous random variables are obtained by replacing the

p.m.f. by the p.d.f. and replacing sums by integrals. Thus, the expected value of

X is given by

E(X) =

Z âˆ

âˆ’âˆ x fX(x)dx,

and the variance is (as before)

Var(X) = E(X2)âˆ’E(X)2,

where

E(X2) =

Z âˆ

âˆ’âˆ x2 fX(x)dx.

It is also true that Var(X) = E((X âˆ’Âµ)2), where Âµ = E(X).


3.7. MEDIAN, QUARTILES, PERCENTILES

57

We will see examples of these calculations shortly. But here is a small example

to show the ideas. The support of a continuous random variable is the smallest

interval containing all values of x where fX(x) &gt; 0.

Suppose that the random variable X has p.d.f. given by

fX(x) =

ï¿½2x

if 0 â‰¤ x â‰¤ 1,

0

otherwise.

The support of Xis the interval [0,1]. We check the integral:

Z âˆ

âˆ’âˆ fX(x)dx =

Z 1

0 2x dx =

ï¿½

x2ï¿½x=1

x=0 = 1.

The cumulative distribution function of X is

FX(x) =

Z x

âˆ’âˆ fX(t)dt =

ï¿½0

if x &lt; 0,

x2

if 0 â‰¤ x â‰¤ 1,

1

if x &gt; 1.

(Study this carefully to see how it works.) We have

E(X)

=

Z âˆ

âˆ’âˆ x fX(x)dx =

Z 1

0 2x2dx = 2

3,

E(X2)

=

Z âˆ

âˆ’âˆ x2 fX(x)dx =

Z 1

0 2x3dx = 1

2,

Var(X)

=

1

2 âˆ’

ï¿½2

3

ï¿½2

= 1

18.

3.7

Median, quartiles, percentiles

Another measure commonly used for continuous random variables is the median;

this is the value m such that â€œhalf of the distribution lies to the left of m and half to

the rightâ€. More formally, m should satisfy FX(m) = 1/2. It is not the same as the

mean or expected value. In the example at the end of the last section, we saw that

E(X) = 2/3. The median of X is the value of m for which FX(m) = 1/2. Since

FX(x) = x2 for 0 â‰¤ x â‰¤ 1, we see that m = 1/

âˆš

2.

If there is a value m such that the graph of y = fX(x) is symmetric about x = m,

then both the expected value and the median of X are equal to m.

The lower quartile l and the upper quartile u are similarly deï¬ned by

FX(l) = 1/4,

FX(u) = 3/4.

Thus, the probability that X lies between l and u is 3/4âˆ’1/4 = 1/2, so the quar-

tiles give an estimate of how spread-out the distribution is. More generally, we

deï¬ne the nth percentile of X to be the value of xn such that

FX(xn) = n/100,


58

CHAPTER 3. RANDOM VARIABLES

that is, the probability that X is smaller than xn is n%.

Reminder

If the c.d.f. of X is FX(x) and the p.d.f. is fX(x), then

â€¢ differentiate FX to get fX, and integrate fX to get FX;

â€¢ use fX to calculate E(X) and Var(X);

â€¢ use FX to calculate P(a â‰¤ X â‰¤ b) (this is FX(b) âˆ’ FX(a)), and the median

and percentiles of X.

3.8

Some continuous random variables

In this section we examine three important continuous random variables: the uni-

form, exponential, and normal. The details are summarised in Appendix B.

Uniform random variable U(a,b)

Let a and b be real numbers with a &lt; b. A uniform random variable on the interval

[a,b] is, roughly speaking, â€œequally likely to be anywhere in the intervalâ€. In other

words, its probability density function is constant on the interval [a,b] (and zero

outside the interval). What should the constant value c be? The integral of the

p.d.f. is the area of a rectangle of height c and base b âˆ’ a; this must be 1, so

c = 1/(bâˆ’a). Thus, the p.d.f. of the random variable X âˆ¼ U(a,b) is given by

fX(x) =

ï¿½1/(bâˆ’a)

if a â‰¤ x â‰¤ b,

0

otherwise.

By integration, we ï¬nd that the c.d.f. is

FX(x) =

ï¿½0

if x &lt; a,

(xâˆ’a)/(bâˆ’a)

if a â‰¤ x â‰¤ b,

1

if x &gt; b.

Further calculation (or the symmetry of the p.d.f.) shows that the expected value

and the median of X are both given by (a + b)/2 (the midpoint of the interval),

while Var(X) = (bâˆ’a)2/12.

The uniform random variable doesnâ€™t really arise in practical situations. How-

ever, it is very useful for simulations. Most computer systems include a random

number generator, which apparently produces independent values of a uniform

random variable on the interval [0,1]. Of course, they are not really random, since

the computer is a deterministic machine; but there should be no obvious pattern to


3.8. SOME CONTINUOUS RANDOM VARIABLES

59

the numbers produced, and in a large number of trials they should be distributed

uniformly over the interval.

You will learn in the Statistics course how to use a uniform random variable

to construct values of other types of discrete or continuous random variables. Its

great simplicity makes it the best choice for this purpose.

Exponential random variable Exp(Î»)

The exponential random variable arises in the same situation as the Poisson: be

careful not to confuse them! We have events which occur randomly but at a con-

stant average rate of Î» per unit time (e.g. radioactive decays, ï¬sh biting). The

Poisson random variable, which is discrete, counts how many events will occur

in the next unit of time. The exponential random variable, which is continuous,

measures exactly how long from now it is until the next event occurs. Not that it

takes non-negative real numbers as values.

If X âˆ¼ Exp(Î»), the p.d.f. of X is

fX(x) =

ï¿½

0

if x &lt; 0,

Î»eâˆ’Î»x

if x â‰¥ 0.

By integration, we ï¬nd the c.d.f. to be

FX(x) =

ï¿½

0

if x &lt; 0,

1âˆ’eâˆ’Î»x

if x â‰¥ 0.

Further calculation gives

E(X) = 1/Î»,

Var(X) = 1/Î»2.

The median m satisï¬es 1âˆ’eâˆ’Î»m = 1/2, so that m = log2/Î». (The logarithm is to

base e, so that log2 = 0.69314718056 approximately.

Normal random variable N(Âµ,Ïƒ2)

The normal random variable is the commonest of all in applications, and the most

important. There is a theorem called the central limit theorem which says that, for

virtually any random variable X which is not too bizarre, if you take the sum (or

the average) of n independent random variables with the same distribution as X,

the result will be approximately normal, and will become more and more like a

normal variable as n grows. This partly explains why a random variable affected

by many independent factors, like a manâ€™s height, has an approximately normal

distribution.


60

CHAPTER 3. RANDOM VARIABLES

More precisely, if n is large, then a Bin(n, p) random variable is well approx-

imated by a normal random variable with the same expected value np and the

same variance npq. (If you are approximating any discrete random variable by a

continuous one, you should make a â€œcontinuity correctionâ€ â€“ see the next section

for details and an example.)

The p.d.f. of the random variable X âˆ¼ N(Âµ,Ïƒ2) is given by the formula

fX(x) =

1

Ïƒ

âˆš

2Ï€ eâˆ’(xâˆ’Âµ)2/2Ïƒ2.

We have E(X) = Âµ and Var(X) = Ïƒ2. The picture below shows the graph of this

function for Âµ = 0, the familiar â€˜bell-shaped curveâ€™.

.

..................

..................

..........

.........

..........

.........

..........

..........

.....................

...........

...........

...........

............

...........

..............

..........................

..........................

...........

........ ......

............

..........

...........

..........

..........

.........

.........

..........

..........

...........

..........

............

...... ........

...........

..........................

..........................

.........................

............

...........

...........

...........

.....................

....................

.........

..........

.........

..........

..................

..................

The c.d.f. of X is obtained as usual by integrating the p.d.f. However, it is not

possible to write the integral of this function (which, stripped of its constants, is

eâˆ’x2) in terms of â€˜standardâ€™ functions. So there is no alternative but to make tables

of its values.

The crucial fact that means that we donâ€™t have to tabulate the function for all

values of Âµ and Ïƒ is the following:

Proposition 3.6 If X âˆ¼ N(Âµ,Ïƒ2), and Y = (X âˆ’Âµ)/Ïƒ, then Y âˆ¼ N(0,1).

So we only need tables of the c.d.f. for N(0,1) â€“ this is the so-called standard

normal random variable â€“ and we can ï¬nd the c.d.f. of any normal random vari-

able. The c.d.f. of the standard normal is given in Table 4 of the New Cambridge

Statistical Tables [1]. The function is called Î¦ in the tables.

For example, suppose that X âˆ¼ N(6,25).What is the probability that X â‰¤ 8?

Putting Y = (X âˆ’ 6)/5, so that Y âˆ¼ N(0,1), we ï¬nd that X â‰¤ 8 if and only if

Y â‰¤ (8âˆ’6)/5 = 0.4. From the tables, the probability of this is Î¦(0.4) = 0.6554.

The p.d.f. of a standard normal r.v. Y is symmetric about zero. This means

that, for any positive number c,

Î¦(âˆ’c) = P(Y â‰¤ âˆ’c) = P(Y â‰¥ c) = 1âˆ’P(Y â‰¤ c) = 1âˆ’Î¦(c).

So it is only necessary to tabulate the function for positive values of its argument.

So, if X âˆ¼ N(6,25) and Y = (X âˆ’6)/5 as before, then

P(X â‰¤ 3) = P(Y â‰¤ âˆ’0.6) = 1âˆ’P(Y â‰¤ 0.6) = 1âˆ’0.7257 = 0.2743.


3.9. ON USING TABLES

61

3.9

On using tables

We end this section with a few comments about using tables, not tied particularly

to the normal distribution (though most of the examples will come from there).

Interpolation

Any table is limited in the number of entries it contains. Tabulating something

with the input given to one extra decimal place would make the table ten times as

bulky! Interpolation can be used to extend the range of values tabulated.

Suppose that some function F is tabulated with the input given to three places

of decimals. It is probably true that F is changing at a roughly constant rate

between, say, 0.28 and 0.29. So F(0.283) will be about three-tenths of the way

between F(0.28) and F(0.29).

For example, if Î¦ is the c.d.f. of the normal distribution, then Î¦(0.28) =

0.6103 and Î¦(0.29) = 0.6141, so Î¦(0.283) = 0.6114. (Three-tenths of 0.0038 is

0.0011.)

Using tables in reverse

This means, if you have a table of values of F, use it to ï¬nd x such that F(x) is a

given value c. Usually, c wonâ€™t be in the table and we have to interpolate between

values x1 and x2, where F(x1) is just less than c and F(x2) is just greater.

For example, if Î¦ is the c.d.f. of the normal distribution, and we want the

upper quartile, then we ï¬nd from tables Î¦(0.67) = 0.7486 and Î¦(0.68) = 0.7517,

so the required value is about 0.6745 (since 0.0014/0.0031 = 0.45).

In this case, the percentile points of the standard normal r.v. are given in Table

5 of the New Cambridge Statistical Tables [1], so you donâ€™t need to do this. But

you will ï¬nd it necessary in other cases.

Continuity correction

Suppose we know that a discrete random variable X is well approximated by a

continuous random variable Y. We are given a table of the c.d.f. of Y and want to

ï¬nd information about X. For example, suppose that X takes integer values and

we want to ï¬nd P(a â‰¤ X â‰¤ b), where a and b are integers. This probability is

equal to

P(X = a)+P(x = a+1)+Â·Â·Â·+P(X = b).

To say that X can be approximated by Y means that, for example, P(X = a) is

approximately equal to fY(a), where fY is the p.d.f. of Y. This is equal to the area


62

CHAPTER 3. RANDOM VARIABLES

of a rectangle of height fY(a) and base 1 (from aâˆ’0.5 to a+0.5). This in turn is,

to a good approximation, the area under the curve y = fY(x) from x = a âˆ’ 0.5 to

x = a+0.5, since the pieces of the curve above and below the rectangle on either

side of x = a will approximately cancel. Similarly for the other values.

.

.................................

................................

................................

...............................

..............................

.............................

.............................

............................

y=fY (x)

uP(X=a)

aâˆ’0.5

a

a+0.5

Adding all these pieces. we ï¬nd that P(a â‰¤ X â‰¤ b) is approximately equal to

the area under the curve y = fY(x) from x = a âˆ’ 0.5 to x = b + 0.5. This area is

given by FY(b+0.5)âˆ’FY(aâˆ’0.5), since FY is the integral of fY. Said otherwise,

this is P(aâˆ’0.5 â‰¤ Y â‰¤ b+0.5).

We summarise the continuity correction:

Suppose that the discrete random variable X, taking integer values, is

approximated by the continuous random variable Y. Then

P(a â‰¤ X â‰¤ b) â‰ˆ P(aâˆ’0.5 â‰¤Y â‰¤ b+0.5) = FY(b+0.5)âˆ’FY(aâˆ’0.5).

(Here, â‰ˆ means â€œapproximately equalâ€.) Similarly, for example, P(X â‰¤ b) â‰ˆ

P(Y â‰¤ b+0.5), and P(X â‰¥ a) â‰ˆ P(Y â‰¥ aâˆ’0.5).

Example

The probability that a light bulb will fail in a year is 0.75, and light

bulbs fail independently. If 192 bulbs are installed, what is the probability that the

number which fail in a year lies between 140 and 150 inclusive?

Solution

Let X be the number of light bulbs which fail in a year. Then X âˆ¼

Bin(192,3/4), and so E(X) = 144, Var(X) = 36. So X is approximated by Y âˆ¼

N(144,36), and

P(140 â‰¤ X â‰¤ 150) â‰ˆ P(139.5 â‰¤ Y â‰¤ 150.5)

by the continuity correction.


3.10. WORKED EXAMPLES

63

Let Z = (Y âˆ’144)/6. Then Z âˆ¼ N(0,1), and

P(139.5 â‰¤ Y â‰¤ 150.5)

=

P

ï¿½139.5âˆ’144

6

â‰¤ Z â‰¤ 150.5âˆ’144

6

ï¿½

=

P(âˆ’0.75 â‰¤ Z â‰¤ 1.083)

=

0.8606âˆ’0.2268

(from tables)

=

0.6338.

3.10

Worked examples

Question

I roll a fair die twice. Let the random variable X be the maximum of

the two numbers obtained, and let Y be the modulus of their difference (that is,

the value of Y is the larger number minus the smaller number).

(a) Write down the joint p.m.f. of (X,Y).

(b) Write down the p.m.f. of X, and calculate its expected value and its variance.

(c) Write down the p.m.f. of Y, and calculate its expected value and its variance.

(d) Are the random variables X and Y independent?

Solution

(a)

Y

0

1

2

3

4

5

1

1

36

0

0

0

0

0

2

1

36

2

36

0

0

0

0

3

1

36

2

36

2

36

0

0

0

X

4

1

36

2

36

2

36

2

36

0

0

5

1

36

2

36

2

36

2

36

2

36

0

6

1

36

2

36

2

36

2

36

2

36

2

36

The best way to produce this is to write out a 6Ã—6 table giving all possible values

for the two throws, work out for each cell what the values of X and Y are, and

then count the number of occurrences of each pair. For example: X = 5, Y = 2

can occur in two ways: the numbers thrown must be (5,3) or (3,5).

(b) Take row sums:

x

1

2

3

4

5

6

P(X = x)

1

36

3

36

5

36

7

36

9

36

11

36


64

CHAPTER 3. RANDOM VARIABLES

Hence in the usual way

E(X) = 161

36 ,

Var(X) = 2555

1296.

(c) Take column sums:

y

0

1

2

3

4

5

P(Y = y)

6

36

10

36

8

36

6

36

4

36

2

36

and so

E(Y) = 35

18,

Var(Y) = 665

324.

(d) No: e.g. P(X = 1,Y = 2) = 0 but P(X = 1)Â·P(Y = 2) =

8

1296.

Question

An archer shoots an arrow at a target. The distance of the arrow from

the centre of the target is a random variable X whose p.d.f. is given by

fX(x) =

ï¿½

(3+2xâˆ’x2)/9

if x â‰¤ 3,

0

if x &gt; 3.

The archerâ€™s score is determined as follows:

Distance

X &lt; 0.5

0.5 â‰¤ X &lt; 1

1 â‰¤ X &lt; 1.5

1.5 â‰¤ X &lt; 2

X â‰¥ 2

Score

10

7

4

1

0

Construct the probability mass function for the archerâ€™s score, and ï¬nd the archerâ€™s

expected score.

Solution

First we work out the probability of the arrow being in each of the

given bands:

P(X &lt; 0.5) = FX(0.5)âˆ’FX(0)

=

Z 0.5

0

3+2xâˆ’x2

9

dx

=

ï¿½9x+3x2 âˆ’x3

27

ï¿½1/2

0

=

41

216.

Similarly we ï¬nd that P(0.5 â‰¤ X &lt; 1) = 47/216, P(1 â‰¤ X &lt; 1.5) = 47/216,

P(1.5 â‰¤ X &lt; 2) = 41/216, and P(X â‰¥ 2) = 40/216. So the p.m.f. fot the archerâ€™s

score S is

s

0

1

4

7

10

P(S = s)

40

216

41

216

47

216

47

216

41

216


3.10. WORKED EXAMPLES

65

Hence

E(S) = 41+47Â·4+47Â·7+41Â·10

216

= 121

27 .

Question

Let T be the lifetime in years of new bus engines. Suppose that T is

continuous with probability density function

fT(x) =

ï£±

ï£´

ï£²

ï£´

ï£³

0

for x &lt; 1

d

x3

for x &gt; 1

for some constant d.

(a) Find the value of d.

(b) Find the mean and median of T.

(c) Suppose that 240 new bus engines are installed at the same time, and that

their lifetimes are independent. By making an appropriate approximation,

ï¬nd the probability that at most 10 of the engines last for 4 years or more.

Solution

(a) The integral of fT(x), over the support of T, must be 1. That is,

1

=

Z âˆ

1

d

x3 dx

=

ï¿½âˆ’d

2x2

ï¿½âˆ

1

=

d/2,

so d = 2.

(b) The c.d.f. of T is obtained by integrating the p.d.f.; that is, it is

FT(x) =

ï£±

ï£´

ï£²

ï£´

ï£³

0

for x &lt; 1

1âˆ’ 1

x2

for x &gt; 1

The mean of T is

Z âˆ

1 x fT(x) dx =

Z âˆ

1

2

x2 dx = 2.

The median is the value m such that FT(m) = 1/2. That is, 1 âˆ’ 1/m2 = 1/2,

or m =

âˆš

2.


66

CHAPTER 3. RANDOM VARIABLES

(c) The probability that an engine lasts for four years or more is

1âˆ’FT(4) = 1âˆ’

ï¿½

1âˆ’

ï¿½1

4

ï¿½2ï¿½

= 1

16.

So, if 240 engines are installed, the number which last for four years or more

is a binomial random variable X âˆ¼ Bin(240,1/16), with expected value 240 Ã—

(1/16) = 15 and variance 240Ã—(1/16)Ã—(15/16) = 225/16.

We approximate X by Y âˆ¼ N(15,(15/4)2). Using the continuity correction,

P(X â‰¤ 10) â‰ˆ P(Y â‰¤ 10.5).

Now, if Z = (Y âˆ’15)/(15/4), then Z âˆ¼ N(0,1), and

P(Y â‰¤ 10.5)

=

P(Z â‰¤ âˆ’1.2)

=

1âˆ’P(Z â‰¤ 1.2)

=

0.1151

using the table of the standard normal distribution.

Note that we start with the continuous random variable T, move to the discrete

random variable X, and then move on to the continuous random variables Y and

Z, where ï¬nally Z is standard normal and so is in the tables.

A true story

The answer to the question at the end of the last chapter: As the

students in the class obviously knew, the class included a pair of twins! (The twins

were Leo and Willy Moser, who both had successful careers as mathematicians.)

But what went wrong with our argument for the Birthday Paradox? We as-

sumed (without saying so) that the birthdays of the people in the room were inde-

pendent; but of course the birthdays of twins are clearly not independent!


Chapter 4

More on joint distribution

We have seen the joint p.m.f. of two discrete random variables X and Y, and we

have learned what it means for X and Y to be independent. Now we examine

this further to see measures of non-independence and conditional distributions of

random variables.

4.1

Covariance and correlation

In this section we consider a pair of discrete random variables X andY. Remember

that X and Y are independent if

P(X = ai,Y = bj) = P(X = ai)Â·P(Y = bj)

holds for any pair (ai,bj) of values of X and Y. We introduce a number (called

the covariance of X and Y) which gives a measure of how far they are from being

independent.

Look back at the proof of Theorem 21(b), where we showed that if X and Y

are independent then Var(X +Y) = Var(X)+Var(Y). We found that, in any case,

Var(X +Y) = Var(X)+Var(Y)+2(E(XY)âˆ’E(X)E(Y)),

and then proved that if X and Y are independent then E(XY) = E(X)E(Y), so that

the last term is zero.

Now we deï¬ne the covariance of X and Y to be E(XY) âˆ’ E(X)E(Y). We

write Cov(X,Y) for this quantity. Then the argument we had earlier shows the

following:

Theorem 4.1

(a) Var(X +Y) = Var(X)+Var(Y)+2Cov(X,Y).

(b) If X and Y are independent, then Cov(X,Y) = 0.

67


68

CHAPTER 4. MORE ON JOINT DISTRIBUTION

In fact, a more general version of (a), proved by the same argument, says that

Var(aX +bY) = a2 Var(X)+b2 Var(Y)+2abCov(X,Y).

(4.1)

Another quantity closely related to covariance is the correlation coefï¬cient,

corr(X,Y), which is just a â€œnormalisedâ€ version of the covariance. It is deï¬ned as

follows:

corr(X,Y) =

Cov(X,Y)

ï¿½

Var(X)Var(Y)

.

The point of this is the ï¬rst part of the following theorem.

Theorem 4.2 Let X and Y be random variables. Then

(a) âˆ’1 â‰¤ corr(X,Y) â‰¤ 1;

(b) if X and Y are independent, then corr(X,Y) = 0;

(c) if Y = mX +c for some constants m Ì¸= 0 and c, then corr(X,Y) = 1 if m &gt; 0,

and corr(X,Y) = âˆ’1 if m &lt; 0.

The proof of the ï¬rst part is optional: see the end of this section. But note that

this is another check on your calculations: if you calculate a correlation coefï¬cient

which is bigger than 1 or smaller than âˆ’1, then you have made a mistake. Part (b)

follows immediately from part (b) of the preceding theorem.

For part (c), suppose that Y = mX +c. Let E(X) = Âµ and Var(X) = Î±, so that E(X2) = Âµ2 +Î±.

Now we just calculate everything in sight.

E(Y)

=

E(mX +c) = mE(X)+c = mÂµ+c

E(Y 2)

=

E(m2X2 +2mcX +c2) = m2(Âµ2 +Î±)+2mcÂµ+c2

Var(Y)

=

E(Y 2)âˆ’E(Y)2 = m2Î±

E(XY)

=

E(mX2 +cX) = m(Âµ2 +Î±)+cÂµ;

Cov(X,Y)

=

E(XY)âˆ’E(X)E(Y) = mÎ±

corr(X,Y)

=

Cov(X,Y)/

ï¿½

Var(X)Var(Y) = mÎ±/

âˆš

m2Î±2

=

ï¿½+1

if m &gt; 0,

âˆ’1

if m &lt; 0.

Thus the correlation coefï¬cient is a measure of the extent to which the two

variables are related. It is +1 if Y increases linearly with X; 0 if there is no relation

between them; and âˆ’1 if Y decreases linearly as X increases. More generally, a

positive correlation indicates a tendency for larger X values to be associated with

larger Y values; a negative value, for smaller X values to be associated with larger

Y values.


4.1. COVARIANCE AND CORRELATION

69

Example

I have two red pens, one green pen, and one blue pen, and I choose

two pens without replacement. Let X be the number of red pens that I choose and

Y the number of green pens. Then the joint p.m.f. of X and Y is given by the

following table:

Y

0

1

0

0

1

6

X

1

1

3

1

3

2

1

6

0

From this we can calculate the marginal p.m.f. of X and of Y and hence ï¬nd

their expected values and variances:

E(X) = 1,

Var(X) = 1/3,

E(Y) = 1/2,

Var(Y) = 1/4.

Also, E(XY) = 1/3, since the sum

E(XY) = âˆ‘

i,j

aibjP(X = ai,Y = bj)

contains only one term where all three factors are non-zero. Hence

Cov(X,Y) = 1/3âˆ’1/2 = âˆ’1/6,

and

corr(X,Y) = âˆ’1/6

ï¿½

1/12

= âˆ’ 1

âˆš

3.

The negative correlation means that small values of X tend to be associated with

larger values of Y. Indeed, if X = 0 then Y must be 1, and if X = 2 then Y must

be 0, but if X = 1 then Y can be either 0 or 1.

Example

We have seen that if X and Y are independent then Cov(X,Y) = 0.

However, it doesnâ€™t work the other way around. Consider the following joint

p.m.f.

Y

âˆ’1

0

1

âˆ’1

1

5

0

1

5

X

0

0

1

5

0

1

1

5

0

1

5


70

CHAPTER 4. MORE ON JOINT DISTRIBUTION

Now calculation shows that E(X) = E(Y) = E(XY) = 0, so Cov(X,Y) = 0. But

X and Y are not independent: for P(X = âˆ’1) = 2/5, P(Y = 0) = 1/5, but P(X =

âˆ’1,Y = 0) = 0.

We call two random variables X and Y uncorrelated if Cov(X,Y) = 0 (in other

words, if corr(X,Y) = 0). So we can say:

Independent random variables are uncorrelated, but uncorrelated ran-

dom variables need not be independent.

Here is the proof that the correlation coefï¬cient lies between âˆ’1 and 1. Clearly this is exactly

equivalent to proving that its square is at most 1, that is, that

Cov(X,Y)2 â‰¤ Var(X)Â·Var(Y).

This depends on the following fact:

Let p,q,r be real numbers with p &gt; 0. Suppose that px2 +2qx +r â‰¥ 0 for all real

numbers x. Then q2 â‰¤ pr.

For, when we plot the graph y = px2 +2qx+r, we get a parabola; the hypothesis means that this

parabola never goes below the X-axis, so that either it lies entirely above the axis, or it touches it

in one point. This means that the quadratic equation px2 +2qx+r = 0 either has no real roots, or

has two equal real roots. From high-school algebra, we know that this means that q2 â‰¤ pr.

Now let p = Var(X), q = Cov(X,Y), and r = Var(Y). Equation (4.1) shows that

px2 +2qx+r = Var(xX +Y).

(Note that x is an arbitrary real number here and has no connection with the random variable X!)

Since the variance of a random variable is never negative, we see that px2 +2qx+r â‰¥ 0 for all

choices of x. Now our argument above shows that q2 â‰¤ pr, that is, Cov(X,Y)2 â‰¤ Var(X)Â·Var(Y),

as required.

4.2

Conditional random variables

Remember that the conditional probability of event B given event A is P(B | A) =

P(Aâˆ©B)/P(A).

Suppose that X is a discrete random variable. Then the conditional probability

that X takes a certain value ai, given A, is just

P(X = ai | A) = P(A holds and X = ai)

P(A)

.

This deï¬nes the probability mass function of the conditional random variable

X | A.

So we can, for example, talk about the conditional expectation

E(X | A) = âˆ‘

i

aiP(X = ai | A).


4.2. CONDITIONAL RANDOM VARIABLES

71

Now the event A might itself be deï¬ned by a random variable; for example, A

might be the event that Y takes the value bj. In this case, we have

P(X = ai | Y = bj) = P(X = ai,Y = bj)

P(Y = bj)

.

In other words, we have taken the column of the joint p.m.f. table of X and Y

corresponding to the value Y = b j. The sum of the entries in this column is just

P(Y = bj), the marginal distribution of Y. We divide the entries in the column by

this value to obtain a new distribution of X (whose probabilities add up to 1).

In particular, we have

E(X | Y = bj) = âˆ‘

i

aiP(X = ai | Y = bj).

Example

I have two red pens, one green pen, and one blue pen, and I choose

two pens without replacement. Let X be the number of red pens that I choose and

Y the number of green pens. Then the joint p.m.f. of X and Y is given by the

following table:

Y

0

1

0

0

1

6

X

1

1

3

1

3

2

1

6

0

In this case, the conditional distributions of X corresponding to the two values

of Y are as follows:

a

0

1

2

P(X = a | Y = 0)

0

2

3

1

3

a

0

1

2

P(X = a | Y = 1)

1

3

2

3

0

We have

E(X | Y = 0) = 4

3,

E(X | Y = 1) = 2

3.

If we know the conditional expectation of X for all values of Y, we can ï¬nd

the expected value of X:

Proposition 4.3 E(X) = âˆ‘

j

E(X | Y = bj)P(Y = bj).

Proof:

E(X)

= âˆ‘

i

aiP(X = ai)


72

CHAPTER 4. MORE ON JOINT DISTRIBUTION

= âˆ‘

i

aiâˆ‘

j

P(X = ai | Y = bj)P(Y = bj)

= âˆ‘

j

ï¿½

âˆ‘

i

aiP(X = ai | Y = bj

ï¿½

P(Y = bj)

= âˆ‘

j

E(X | Y = bj)P(Y = bj).

In the above example, we have

E(X)

=

E(X | Y = 0)P(Y = 0)+E(X | Y = 1)P(Y = 1)

=

(4/3)Ã—(1/2)+(2/3)Ã—(1/2)

=

1.

Example

Let us revisit the geometric random variable and calculate its expected

value. Recall the situation: I have a coin with probability p of showing heads; I

toss it repeatedly until heads appears for the ï¬rst time; X is the number of tosses.

Let Y be the Bernoulli random variable whose value is 1 if the result of the

ï¬rst toss is heads, 0 if it is tails. If Y = 1, then we stop the experiment then and

there; so if Y = 1, then necessarily X = 1, and we have E(X | Y = 1) = 1. On

the other hand, if Y = 0, then the sequence of tosses from that point on has the

same distribution as the original experiment; so E(X | Y = 0) = 1 + E(X) (the 1

counting the ï¬rst toss). So

E(X)

=

E(X | Y = 0)P(Y = 0)+E(X | Y = 1)P(Y = 1)

=

(1+E(X))Â·q+1Â· p

=

E(X)(1âˆ’ p)+1;

rearranging this equation, we ï¬nd that E(X) = 1/p, conï¬rming our earlier value.

In Proposition 2.1, we saw that independence of events can be characterised

in terms of conditional probabilities: A and B are independent if and only if they

satisfy P(A | B) = P(A). A similar result holds for independence of random vari-

ables:

Proposition 4.4 Let X and Y be discrete random variables. Then X and Y are

independent if and only if, for any values ai and b j of X and Y respectively, we

have

P(X = ai | Y = bj) = P(X = ai).

This is obtained by applying Proposition 15 to the events X = ai and Y = bj.

It can be stated in the following way: X and Y are independent if the conditional

p.m.f. of X | (Y = bj) is equal to the p.m.f. of X, for any value bj of Y.


4.3. JOINT DISTRIBUTION OF CONTINUOUS R.V.S

73

4.3

Joint distribution of continuous r.v.s

For continuous random variables, the covariance and correlation can be deï¬ned

by the same formulae as in the discrete case; and Equation (4.1) remains valid.

But we have to examine what is meant by independence for continuous random

variables. The formalism here needs even more concepts from calculus than we

have used before: functions of two variables, partial derivatives, double integrals.

I assume that this is unfamiliar to you, so this section will be brief and can mostly

be skipped.

Let X andY be continuous random variables. The joint cumulative distribution

function of X and Y is the function FX,Y of two real variables given by

FX,Y(x,y) = P(X â‰¤ x,Y â‰¤ y).

We deï¬ne X and Y to be independent if P(X â‰¤ x,Y â‰¤ y) = P(X â‰¤ x) Â· P(Y â‰¤ y),

for any x and y, that is, FX,Y(x,y) = FX(x) Â· FY(y). (Note that, just as in the one-

variable case, X is part of the name of the function, while x is the argument of the

function.)

The joint probability density function of X and Y is

fX,Y(x,y) =

âˆ‚2

âˆ‚xâˆ‚yFX,Y(x,y).

In other words, differentiate with respect to x keeping y constant, and then differ-

entiate with respect to y keeping x constant (or the other way round: the answer is

the same for all functions we consider.)

The probability that the pair of values of (X,Y) corresponds to a point in some

region of the plane is obtained by taking the double integral of fX,Y over that

region. For example,

P(a â‰¤ X â‰¤ b,c â‰¤ Y â‰¤ d) =

Z d

c

Z b

a fX,Y(x,y)dx dy

(the right hand side means, integrate with respect to x between a and b keeping y

ï¬xed; the result is a function of y; integrate this function with respect to y from c

to d.)

The marginal p.d.f. of X is given by

fX(x) =

Z âˆ

âˆ’âˆ fX,Y(x,y)dy,

and the marginal p.d.f. of Y is similarly

fY(y) =

Z âˆ

âˆ’âˆ fX,Y(x,y)dx.


74

CHAPTER 4. MORE ON JOINT DISTRIBUTION

Then the conditional p.d.f. of X | (Y = b) is

fX|(Y=b)(x) = fX,Y(x,b)

fY(b)

.

The expected value of XY is, not surprisingly,

E(XY) =

Z âˆ

âˆ’âˆ

Z âˆ

âˆ’âˆ xyfX,Y(x,y)dx dy,

and then as in the discrete case

Cov(X,Y) = E(XY)âˆ’E(X)E(Y),

corr(X,Y) =

Cov(X,Y)

ï¿½

Var(X)Var(Y)

.

Finally, and importantly,

The continuous random variables X and Y are independent if and only

if

fX,Y(x,y) = fX(x)Â· fY(y).

As usual this holds if and only if the conditional p.d.f. of X | (Y = b) is equal to

the marginal p.d.f. of X, for any value b. Also, if X and Y are independent, then

Cov(X,Y) = corr(X,Y) = 0 (but not conversely!).

4.4

Transformation of random variables

If a continuous random variable Y is a function of another r.v. X, we can ï¬nd the

distribution of Y in terms of that of X.

Example

Let X and Y be random variables. Suppose that X âˆ¼ U[0,4] (uniform

on [0,4]) and Y =

âˆš

X. What is the support of Y? Find the cumulative distribution

function and the probability density function of Y.

Solution

(a) The support of X is [0,4], and Y =

âˆš

X, so the support of Y is [0,2].

(b) We have fX(x) = x/4 for 0 â‰¤ x â‰¤ 4. Now

FY(y)

=

P(Y â‰¤ y)

=

P(X â‰¤ y2)

=

FX(y2)

=

y2/4


4.4. TRANSFORMATION OF RANDOM VARIABLES

75

for 0 â‰¤ y â‰¤ 2; of course FY(y) = 0 for y &lt; 0 and FY(y) = 1 for y &gt; 2. (Note that

Y â‰¤ y if and only if X â‰¤ y2, since Y =

âˆš

X.)

(c) We have

fY(y) = d

dyFY(y) =

ï¿½y/2

if 0 â‰¤ y â‰¤ 2,

0

otherwise.

The argument in (b) is the key. If we know Y as a function of X, say Y = g(X),

where g is an increasing function, then the event Y â‰¤ y is the same as the event

X â‰¤ h(Y), where h is the inverse function of g. This means that y = g(x) if and

only if x = h(y). (In our example, g(x) = âˆšx, and so h(y) = y2.) Thus

FY(y) = FX(h(y)),

and so, by the Chain Rule,

fY(y) = fX(h(y))hâ€²(y),

where hâ€² is the derivative of h. (This is because fX(x) is the derivative of FX(x)

with respect to its argument x, and the Chain Rule says that if x = h(y) we must

multiply by hâ€²(y) to ï¬nd the derivative with respect to y.)

Applying this formula in our example we have

fY(y) = 1

4 Â·2y = y

2

for 0 â‰¤ y â‰¤ 2, since the p.d.f. of X is fX(x) = 1/4 for 0 â‰¤ x â‰¤ 4.

Here is a formal statement of the result.

Theorem 4.5 Let X be a continuous random variable. Let g be a real function

which is either strictly increasing or strictly decreasing on the support of X, and

which is differentiable there. Let Y = g(X). Then

(a) the support of Y is the image of the support of X under g;

(b) the p.d.f. of Y is given by fY(y) = fX(h(y))|hâ€²(y)|, where h is the inverse

function of g.

For example, here is the proof of Proposition 3.6: if X âˆ¼ N(Âµ,Ïƒ2) and Y =

(X âˆ’Âµ)/Ïƒ, then Y âˆ¼ N(0,1). Recall that

fX(x) =

1

Ïƒ

âˆš

2Ï€ eâˆ’(xâˆ’Âµ)2/2Ïƒ2.


76

CHAPTER 4. MORE ON JOINT DISTRIBUTION

We have Y = g(X), where g(x) = (x âˆ’ Âµ)/Ïƒ; this function is everywhere strictly

increasing (the graph is a straight line with slope 1/Ïƒ), and the inverse function is

x = h(y) = Ïƒy+Âµ. Thus, hâ€²(y) = Ïƒ, and

fY(y) = fX(Ïƒy+Âµ)Â·Ïƒ =

1

âˆš

2Ï€ eâˆ’y2/2,

the p.d.f. of a standard normal variable.

However, rather than remember this formula, together with the conditions for

its validity, I recommend going back to the argument we used in the example.

If the transforming function g is not monotonic (that is, not either increasing

or decreasing), then life is a bit more complicated. For example, if X is a random

variable taking both positive and negative values, and Y = X2, then a given value

y of Y could arise from either of the values âˆšy and âˆ’âˆšy of X, so we must work

out the two contributions and add them up.

Example

X âˆ¼ N(0,1) and Y = X2. Find the p.d.f. of Y.

The p.d.f. of X is (1/

âˆš

2Ï€)eâˆ’x2/2. Let Î¦(x) be its c.d.f., so that P(X â‰¤ x) =

Î¦(x), and

Î¦â€²(x) =

1

âˆš

2Ï€eâˆ’x2/2.

Now Y = X2, so Y â‰¤ y if and only if âˆ’âˆšy â‰¤ X â‰¤ âˆšy. Thus

FY(y)

=

P(Y â‰¤ y)

=

P(âˆ’

ï¿½

y â‰¤ X â‰¤

ï¿½

y)

=

Î¦(

ï¿½

y)âˆ’Î¦(âˆ’

ï¿½

y)

=

Î¦(

ï¿½

yâˆ’(1âˆ’Î¦(

ï¿½

y))

(by symmetry of N(0,1))

=

2Î¦(

ï¿½

y)âˆ’1.

So

fY(y)

=

d

dyFY(y)

=

2Î¦â€²(âˆšy)Â·

1

2âˆšy

(by the Chain Rule)

=

1

âˆš2Ï€yeâˆ’y/2.

Of course, this is valid for y &gt; 0; for y &lt; 0, the p.d.f. is zero.


4.5. WORKED EXAMPLES

77

Note the 2 in the line labelled â€œby the Chain Ruleâ€. If you blindly applied

the formula of Theorem 4.5, using h(y) = âˆšy, you would not get this 2; it arises

from the fact that, since Y = X2, each value of Y corresponds to two values of X

(one positive, one negative), and each value gives the same contribution, by the

symmetry of the p.d.f. of X.

4.5

Worked examples

Question

Two numbers X and Y are chosen independently from the uniform

distribution on the unit interval [0,1]. Let Z be the maximum of the two numbers.

Find the p.d.f. of Z, and hence ï¬nd its expected value, variance and median.

Solution

The c.d.f.s of X and Y are identical, that is,

FX(x) = FY(x) =

ï¿½0

if x &lt; 0,

x

if 0 &lt; x &lt; 1,

1

if x &gt; 1.

(The variable can be called x in both cases; its name doesnâ€™t matter.)

The key to the argument is to notice that

Z = max(X,Y) â‰¤ x

if and only if

X â‰¤ x and Y â‰¤ x.

(For, if both X and Y are smaller than a given value x, then so is their maximum;

but if at least one of them is greater than x, then again so is their maximum.) For

0 â‰¤ x â‰¤ 1, we have P(X â‰¤ x) = P(Y â‰¤ x) = x; by independence,

P(X â‰¤ x and Y â‰¤ x) = xÂ·x = x2.

Thus P(Z â‰¤ x) = x2. Of course this probability is 0 if x &lt; 0 and is 1 if x &gt; 1. So

the c.d.f. of Z is

FZ(x) =

ï¿½0

if x &lt; 0,

x2

if 0 &lt; x &lt; 1,

1

if x &gt; 1.

The median of Z is the value of m such that FZ(m) = 1/2, that is m2 = 1/2, or

m = 1/

âˆš

2.

We obtain the p.d.f. of Z by differentiating:

fZ(x) =

ï¿½2x

if 0 &lt; x &lt; 1,

0

otherwise.

Then we can ï¬nd E(Z) and Var(Z) in the usual way:

E(Z) =

Z 1

0 2x2dx = 2

3,

Var(Z) =

Z 1

0 2x3dxâˆ’

ï¿½2

3

ï¿½2

= 1

18.


78

CHAPTER 4. MORE ON JOINT DISTRIBUTION

Question

I roll a fair die bearing the numbers 1 to 6. If N is the number showing

on the die, I then toss a fair coin N times. Let X be the number of heads I obtain.

(a) Write down the p.m.f. for X.

(b) Calculate E(X) without using this information.

Solution

(a) If we were given that N = n, say, then X would be a binomial

Bin(n,1/2) random variable. So P(X = k | N = n) = nCk(1/2)n.

By the ToTP,

P(X = k) =

6

âˆ‘

n=1

P(X = k | N = n)P(N = n).

Clearly P(N = n) = 1/6 for n = 1,...,6. So to ï¬nd P(X = k), we add up the

probability that X = k for a Bin(n,1/2) r.v. for n = k,...,6 and divide by 6. (We

start at k because you canâ€™t get k heads with fewer than k coin tosses!) The answer

comes to

k

0

1

2

3

4

5

6

P(X = k)

63

384

120

384

99

384

64

384

29

384

8

384

1

384

For example,

P(X = 4) =

4C4(1/2)4 + 5C4(1/2)5 + 6C4(1/2)6

6

= 4+10+15

384

.

(b) By Proposition 4.3,

E(X) =

6

âˆ‘

n=1

E(X | (N = n))P(N = n).

Now if we are given that N = n then, as we remarked, X has a binomial Bin(n,1/2)

distribution, with expected value n/2. So

E(X) =

6

âˆ‘

n=1

(n/2)Â·(1/6) = 1+2+3+4+5+6

2Â·6

= 7

4.

Try working it out from the p.m.f. to check that the answer is the same!


Appendix A

Mathematical notation

The Greek alphabet

Mathematicians use the Greek alpha-

bet for an extra supply of symbols.

Some, like Ï€, have standard meanings.

You donâ€™t need to learn this; keep it

for reference. Apologies to Greek stu-

dents: you may not recognise this, but

it is the Greek alphabet that mathe-

maticians use!

Pairs that are often confused are zeta

and xi, or nu and upsilon, which look

alike; and chi and xi, or epsilon and

upsilon, which sound alike.

Name

Capital

Lowercase

alpha

A

Î±

beta

B

Î²

gamma

Î“

Î³

delta

âˆ†

Î´

epsilon

E

Îµ

zeta

Z

Î¶

eta

H

Î·

theta

Î˜

Î¸

iota

I

Î¹

kappa

K

Îº

lambda

Î›

Î»

mu

M

Âµ

nu

N

Î½

xi

Î

Î¾

omicron

O

o

pi

Î 

Ï€

rho

P

Ï

sigma

Î£

Ïƒ

tau

T

Ï„

upsilon

Ï’

Ï…

phi

Î¦

Ï†

chi

X

Ï‡

psi

Î¨

Ïˆ

omega

â„¦

Ï‰

79


80

APPENDIX A. MATHEMATICAL NOTATION

Numbers

Notation

Meaning

Example

N

Natural numbers

1,2,3,...

(some people include 0)

Z

Integers

...,âˆ’2,âˆ’1,0,1,2,...

R

Real numbers

1

2,

âˆš

2,Ï€,...

|x|

modulus

|2| = 2,|âˆ’3| = 3

a/b or a

b

a over b

12/3 = 4, 2/4 = 0.5

a | b

a divides b

4 | 12

mCn or

ï¿½m

n

ï¿½

m choose n

5C2 = 10

n!

n factorial

5! = 120

b

âˆ‘

i=a

xi

xa +xa+1 +Â·Â·Â·+xb

3

âˆ‘

i=1

i2 = 12 +22 +32 = 14

(see section on Summation below)

x â‰ˆ y

x is approximately equal to y

Sets

Notation

Meaning

Example

{...}

a set

{1,2,3}

NOTE: {1,2} = {2,1}

x âˆˆ A

x is an element of the set A

2 âˆˆ {1,2,3}

{x : ...}

the set of all x such that ...

{x : x2 = 4} = {âˆ’2,2}

or {x | ...}

|A|

cardinality of A

|{1,2,3}| = 3

(number of elements in A)

AâˆªB

A union B

{1,2,3}âˆª{2,4} = {1,2,3,4}

(elements in either A or B)

Aâˆ©B

A intersection B

{1,2,3}âˆ©{2,4} = {2}

(elements in both A and B)

A\B

set difference

{1,2,3}\{2,4} = {1,3}

(elements in A but not B)

A âŠ† B

A is a subset of B (or equal)

{1,3} âŠ† {1,2,3}

Aâ€²

complement of A

everything not in A

/0

empty set (no elements)

{1,2}âˆ©{3,4} = /0

(x,y)

ordered pair

NOTE: (1,2) Ì¸= (2,1)

AÃ—B

Cartesian product

{1,2}Ã—{1,3} =

(set of all ordered pairs)

{(1,1),(2,1),(1,3),(2,3)}


81

Summation

What is it?

Let a1,a2,a3,... be numbers. The notation

n

âˆ‘

i=1

ai

(read â€œsum, from i equals 1 to n, of aiâ€), means: add up the numbers a1,a2,...,an;

that is,

n

âˆ‘

i=1

ai = a1 +a2 +Â·Â·Â·+an.

The notation

n

âˆ‘

j=1

aj means exactly the same thing. The variable i or j is called

a â€œdummy variableâ€.

The notation

m

âˆ‘

i=1

ai is not the same, since (if m and n are different) it is telling

us to add up a different number of terms.

The sum doesnâ€™t have to start at 1. For example,

20

âˆ‘

i=10

ai = a10 +a11 +Â·Â·Â·+a20.

Sometimes I get lazy and donâ€™t bother to write out the values: I just say âˆ‘

i

ai

to mean: add up all the relevant values. For example, if X is a discrete random

variable, then we say that

E(X) = âˆ‘

i

aiP(X = ai)

where the sum is over all i such that ai is a value of the random variable X.

Manipulation

The following three rules hold.

n

âˆ‘

i=1

(ai +bi) =

n

âˆ‘

i=1

ai +

n

âˆ‘

i=1

bi.

(A.1)

Imagine the as and bs written out with a1 + b1 on the ï¬rst line, a2 + b2 on the

second line, and so on. The left-hand side says: add the two terms in each line,


82

APPENDIX A. MATHEMATICAL NOTATION

and then add up all the results. The right-hand side says: add the ï¬rst column (all

the as) and the second column (all the bs), and then add the results. The answers

must be the same.

ï¿½

n

âˆ‘

i=1

ai

ï¿½

Â·

ï¿½

m

âˆ‘

j=1

bj

ï¿½

=

n

âˆ‘

i=1

m

âˆ‘

j=1

aibj.

(A.2)

The double sum says add up all these products, for all values of i and j. A simple

example shows how it works: (a1 +a2)(b1 +b2) = a1b1 +a1b2 +a2b1 +a2b2.

If in place of numbers, we have functions of x, then we can â€œdifferentiate

term-by-termâ€:

d

dx

n

âˆ‘

i+1

fi(x) =

n

âˆ‘

i+1

d

dx fi(x).

(A.3)

The left-hand side says: add up the functions and differentiate the sum. The right

says: differentiate each function and add up the derivatives.

Another useful result is the Binomial Theorem:

(x+y)n =

n

âˆ‘

k=0

nCkxnâˆ’kyk.

Inï¬nite sums

Sometimes we meet inï¬nite sums, which we write as

âˆ

âˆ‘

i=1

ai for example. This

doesnâ€™t just mean â€œadd up inï¬nitely many valuesâ€, since that is not possible. We

need Analysis to give us a deï¬nition in general. But sometimes we know the

answer another way: for example, if ai = ariâˆ’1, where âˆ’1 &lt; r &lt; 1, then

âˆ

âˆ‘

i=1

ai = a+ar +ar2 +Â·Â·Â· =

a

1âˆ’r,

using the formula for the sum of the â€œgeometric seriesâ€. You also need to know

the sum of the â€œexponential seriesâ€

âˆ

âˆ‘

i=0

xi

i! = 1+x+ x2

2 + x3

6 + x4

24 +Â·Â·Â· = ex.

Do the three rules of the preceding section hold? Sometimes yes, sometimes

no. In Analysis you will see some answers to this question.

In all the examples you meet in this book, the rules will be valid.


Appendix B

Probability and random variables

Notation

In the table, A and B are events, X and Y are random variables.

Notation

Meaning

Page

P(A)

probability of A

3

P(A | B)

conditional probability of A given B

24

X = Y

the values of X and Y are equal

X âˆ¼ Y

X and Y have the same distribution

41

(that is, same p.m.f. or same p.d.f.)

E(X)

expected value of X

41

Var(X)

variance of X

42

Cov(X,Y)

covariance of X and Y

67

corr(X,Y)

correlation coefï¬cient of X and Y

68

X | B

conditional random variable

70

X | (Y = b)

71

Bernoulli random variable Bernoulli(p) (p. 48)

â€¢ Occurs when there is a single trial with a ï¬xed probability p of success.

â€¢ Takes only the values 0 and 1.

â€¢ p.m.f. P(X = 0) = q, P(X = 1) = p, where q = 1âˆ’ p.

â€¢ E(X) = p, Var(X) = pq.

83


84

APPENDIX B. PROBABILITY AND RANDOM VARIABLES

Binomial random variable Bin(n, p) (p. 49)

â€¢ Occurs when we are counting the number of successes in n independent

trials with ï¬xed probability p of success in each trial, e.g. the number of

heads in n coin tosses. Also, sampling with replacement from a population

with a proportion p of distinguished elements.

â€¢ The sum of n independent Bernoulli(p) random variables.

â€¢ Values 0,1,2,...,n.

â€¢ p.m.f. P(X = k) = nCkqnâˆ’kpk for 0 â‰¤ k â‰¤ n, where q = 1âˆ’ p.

â€¢ E(X) = np, Var(X) = npq.

Hypergeometric random variable Hg(n,M,N) (p. 51)

â€¢ Occurs when we are sampling n elements without replacement from a pop-

ulation of N elements of which M are distinguished.

â€¢ Values 0,1,2,...,n.

â€¢ p.m.f. P(X = k) = (MCk Â· Nâˆ’MCnâˆ’k)/NCn.

â€¢ E(X) = n

ï¿½M

N

ï¿½

, Var(X) = n

ï¿½M

N

ï¿½ï¿½N âˆ’M

N

ï¿½ï¿½N âˆ’n

N âˆ’1

ï¿½

.

â€¢ Approximately Bin(n,M/N) if n is small compared to N,M,N âˆ’M.

Geometric random variable Geom(p) (p. 52)

â€¢ Describes the number of trials up to and including the ï¬rst success in a

sequence of independent Bernoulli trials, e.g. number of tosses until the

ï¬rst head when tossing a coin.

â€¢ Values 1,2,... (any positive integer).

â€¢ p.m.f. P(X = k) = qkâˆ’1p, where q = 1âˆ’ p.

â€¢ E(X) = 1/p, Var(X) = q/p2.


85

Poisson random variable Poisson(Î») (p. 54)

â€¢ Describes the number of occurrences of a random event in a ï¬xed time

interval, e.g. the number of ï¬sh caught in a day.

â€¢ Values 0,1,2,... (any non-negative integer)

â€¢ p.m.f. P(X = k) = eâˆ’Î»Î»k/k! .

â€¢ E(X) = Î», Var(X) = Î».

â€¢ If n is large, p is small, and np = Î», then Bin(n, p) is approximately equal

to Poisson(Î») (in the sense that the p.m.f.s are approximately equal).

Uniform random variable U[a,b] (p. 58)

â€¢ Occurs when a number is chosen at random from the interval [a,b], with all

values equally likely.

â€¢ p.d.f. f(x) =

ï¿½0

if x &lt; a,

1/(bâˆ’a)

if a â‰¤ x â‰¤ b,

0

if x &gt; b.

â€¢ c.d.f. F(x) =

ï¿½0

if x &lt; a,

(xâˆ’a)/(bâˆ’a)

if a â‰¤ x â‰¤ b,

1

if x &gt; b.

â€¢ E(X) = (a+b)/2, Var(X) = (bâˆ’a)2/12.

Exponential random variable Exp(Î») (p. 59)

â€¢ Occurs in the same situations as the Poisson random variable, but measures

the time from now until the ï¬rst occurrence of the event.

â€¢ p.d.f. f(x) =

ï¿½

0

if x &lt; 0,

Î» eâˆ’Î»x

if x â‰¥ 0.

â€¢ c.d.f. F(x) =

ï¿½

0

if x &lt; 0,

1âˆ’eâˆ’Î»x

if x â‰¥ 0.

â€¢ E(X) = 1/Î», Var(X) = 1/Î»2.

â€¢ However long you wait, the time until the next occurrence has the same

distribution.


86

APPENDIX B. PROBABILITY AND RANDOM VARIABLES

Normal random variable N(Âµ,Ïƒ2) (p. 59)

â€¢ The limit of the sum (or average) of many independent Bernoulli random

variables. This also works for many other types of random variables: this

statement is known as the Central Limit Theorem.

â€¢ p.d.f. f(x) =

1

Ïƒ

âˆš

2Ï€ eâˆ’(xâˆ’Âµ)2/2Ïƒ2.

â€¢ No simple formula for c.d.f.; use tables.

â€¢ E(X) = Âµ, Var(X) = Ïƒ2.

â€¢ For large n, Bin(n, p) is approximately N(np,npq).

â€¢ Standard normal N(0,1) is given in the table. If X âˆ¼ N(Âµ,Ïƒ2), then (X âˆ’

Âµ)/Ïƒ âˆ¼ N(0,1).

The c.d.f.s of the Binomial, Poisson, and Standard Normal random variables

are tabulated in the New Cambridge Statistical Tables, Tables 1, 2 and 4.

