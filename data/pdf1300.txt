


Published in

Towards Data Science



Jun 29, 2020

·

10 min read

Save

Transformers

Or as I like to call it Attention on Steroids. ��

Photo by Arseny Togulev on Unsplash

What is a Transformer?

novel architecture

W ITHOUT







A picture of Transformer from the movie franchise.




Understanding Attention In Deep Learning

Few things to know before diving into Transformers

Self-Attention

Attention allowed us to focus on parts of our input sequence while we predicted our

output sequence

Self attention

self attention helps us create similar connections but within the same

sentence.

cup

it

full

bottle

it

empty

The three kinds of Attention possible in a model:

Encoder-Decoder Attention: 

Self attention in the input sequence:

Self attention in the output sequence:

Keys, Values, and Queries:


Keys, Values, and Queries:

Query Vector

Key Vector

Value Vector:

hidden size

The values represent the index for q, k and i.

Calculating Self attention from q, k and v:

Formula for self-attention. Source: paper.

Step 1:

ⱼ

Step 2:

 for better gradient flow 

Step 3:

Step 4:

Calculating output of self attention for the ith input word. If you are looking for an analogy between self attention

and attention, think of z serving the purpose of context vectors and not global alignment weights.

The Transformer

Showed how q and k are softmax-ed and then a dot product with gives us the final output.

The calculation at each step shown mathematically.


A word of caution

(left) The Transformer architecture. Source: paper. (right) An abstracted version of the same for better

understanding.

Beast #1: Encoder-Decoder stacks

Encoder

multi-head self attention mechanism

fully connected feed-forward network

Seriously you can’t miss

this!!! 

Decoder

masked multi-head self attention mechanism 

multi-head attention mechanism 

fully connected feed-forward network

Beast #2 Inside Encoder-Decoder stacks — Multi-Head Attention:

The three kinds of attention in encoder and decoder stacks along with feed forward neural networks.

calculating self attention

multiple times with different sets

The architecture of Transformer from the paper with encoder, decoder and pre-processing parts labelled.

Diagram showing where each kind of attention is calculated in the architecture.


(left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several attention layers running in

parallel. Source: paper.

Beast #3— Input and Output Pre-processing:

determine the position of individual word wrt each

other 

.

Beast #4 — Decoder stack: Revisited

k 

v

q

Conclusion

Steps to calculate dot product attention and multi headed attention, taken from the paper.


Conclusion

References + Recommended Reads

learn more about

positional encoding.


paper explaining self attention

2



Follow

Artificial Intelligence

Machine Learning

NLP

Transformers

AI


Your home for data science. A Medium publication sharing concepts, ideas and codes.



Read more from Towards Data Science





