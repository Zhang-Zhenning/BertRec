


 



 



6.2  The Generative Mixture Model

The probability of generating a data vector xt from a C-component mixture model given assumptions M is:

p(xt|M) =

C

Ã¥

c=1

p(c|M0) p(xt|Mc,c)       (6.1)

A data vector is generated by choosing one of the C components stochastically under p(c|M0) and then drawing from p(xt|Mc,c). M =

{M0,M1,...,MC} is the vector of component model assumptions, Mc, and assumptions about the mixture process, M0. The assumptions represent

everything that essentially defines the model - values of fixed parameters, model structure, details of the component switching method, any prior

information etc.. p(xt|M) is the evidence for model M and quantifies the likelihood of the observed data under model M. 

The variable c indicates which component of the mixture model is chosen to generate a given data vector x. If p(c|M0) is a vector of probabilities

and each component p(xt|Mc,c) is a Gaussian, then (6.1) simply describes a MoG. If the MoG is adapted through a maximum likelihood approach

then M represents a list of point estimates for the corresponding parameters. In the ICA mixture model presented here, however, each component

has a non-Gaussian density derived from the ICA model presented in the previous Chapter, and M represents assumptions concerning the

distribution of possible parameter values. Figure 6.2 shows a generative model for a data vector x. Circular nodes represent random variables,

square nodes are assumptions and rounded rectangles represent the ICA sub-networks.



Figure 6.2: ICA mixture model.

As the diagram in Figure 6.2 implies, each ICA component has access to its own set of sources. This means that each manifold in the data-space is

described by its own locally-adapted coordinate system, with a different distribution of points along each coordinate axis (if need be for

independence). Such a mixture model will class together observations that share features with each other, but not with others. The dataset will be

partitioned into C mutually exclusive classes, albeit with probabilistic memberships. 

An alternative formulation would be to impose a global set of sources. Data manifolds will again be described by separate coordinate frames, but

each adapted such that the distribution of points along each axis is the same. This has its problems, though, due to the scale indeterminancy in ICA

source reconstruction. This is discussed further in section 6.5.3.



 



 



