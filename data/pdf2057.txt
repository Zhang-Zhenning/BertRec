
 sohaib730 / Gaussian-Mixture-Model Public

 10 stars  13 forks

View code

README.md

Gaussian-Mixture-Model

Expectation Maximization Algorithm

Gaussian Mixture Models (GMM) are effective for multi model density representation. In this experiment GMM Parameters are

estimated using Expectation Maximization(EM) algorithm results are shown for two datasets. The GMM algorithm and plotting functions

are given in python code.

Following are the requirements to run this code: Python 3.7.2

To run this code type:

python main.py

Modify main.py, if number of components of GMM or particular feature in dataset needs to be selected.

For our experiments we considered two data sets:

1. Iris

2. Glass Classification Dataset

1. GMM Density Estimation of Iris Dataset:

First for each feature in Iris dataset, Gaussian mixture models (GMM) parameters are estimated by using two or three GMM

components. The Number of components in GMM are determined by visualizing respective feature's histogram. usually for this dataset

features, two components were enough.

 Star



Notifications

 

Code

 

Issues

 

Pull requests

 

Actions

 

Projects

 

Security

 

Insights

 master 



 

Sign up













GMM Estimation for Two Features:

GMM can properly learn the distribution with only two components.
















2. GMM Density Estimation of Glass Classification Dataset:

This dataset contains eight features. Following results are the density estimation of each feature using GMM. Different number of

components of GMM are used for each feature, determined by visualizing histogram of that feature. 




























Releases

No releases published

Packages

No packages published 

Languages

 Python 100.0%

 Â© 2023 GitHub, Inc.

Terms

Privacy

Security

Status

Docs

Contact GitHub

Pricing

API

Training

Blog

About

