
36





• Problem with all discounting methods:

– discounting treats unseen words equally (add or subtract ε)

– some words are more frequent than others

• Idea: use background probabilities

– “interpolate” ML estimates with General English expectations

(computed as relative frequency of a word in a large collection)

– reflects expected frequency of events



interpolation methods

ML estimate

background probability

final estimate = 

36

37

• Correctly setting λ is very important

• Start simple

– set λ to be a constant, independent of document, query

• Tune to optimize retrieval performance

– optimal value of λ varies with different databases, query 

sets, etc.



Jelinek Mercer smoothing

37


38

• Problem with Jelinek-Mercer:

– longer documents provide better estimates

– could get by with less smoothing

• Make smoothing depend on sample size

• N is length of sample = document length

• µ is a constant



Dirichlet smoothing

38

39

• A step further:

– condition smoothing on “redundancy” of the example

– long, redundant example requires little smoothing

– short, sparse example requires a lot of smoothing

• Derived by considering the proportion of new events

as we walk through example

– N is total number of events = document length

– V is number of unique events = number of unique terms in doc



Witten-Bell smoothing

39

