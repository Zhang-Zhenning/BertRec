
HMMs and the forward-backward algorithm

Ramesh Sridharan∗

These notes give a short review of Hidden Markov Models (HMMs) and the forward-

backward algorithm.

They’re written assuming familiarity with the sum-product belief

propagation algorithm, but should be accessible to anyone who’s seen the fundamentals

of HMMs before.

The notation here is borrowed from Introduction to Probability by Bertsekas &amp; Tsitsiklis:

random variables are represented with capital letters, values they take are represented with

lowercase letters, pX represents a probability distribution for random variable X, and pX(x)

represents the probability of value x (according to pX).

Hidden Markov Models

Figure 1 shows the (undirected) graphical model for HMMs. Here’s a quick recap of the

important facts:

















  …  

Y2

X2

X3

X1

Xn

Yn

Y1

Y3

Figure 1: An undirected graphical model for the HMM. Connections between nodes indicate

dependence.

• We observe Y1 through Yn, which we model as being observed from hidden states X1

through Xn.

• Any particular state variable Xk depends only on Xk−1 (what came before it), Xk+1

(what comes after it), and Yk (the observation associated with it).

• The goal of the forward-backward algorithm is to ﬁnd the conditional distribution over

hidden states given the data.

• In order to specify an HMM, we need three pieces:

∗Contact: rameshvs@csail.mit.edu

1


















  …  

Y2

X2

X3

X1

Xn

Yn

Y1

Y3

m1!2(x2)

m2!3(x3)

m3!4(x4)

m2!1(x1)

m3!2(x2)

m4!3(x3)

Figure 2: A visualization of the forward and backward messages. Each message is a table

that indicates what the node at the start point believes about the node at the end point.

– A transition distribution, pXk+1|Xk(xk+1|xk) = W(xk+1|xk) 1, which describes the

distribution for the next state given the current state. This is often represented

as a matrix that we’ll call A. Rows of A correspond to the current state, columns

correspond to the next state, and each entry corresponds to the transition prob-

ability. So, the entry at row i and column j, Aij, is pXk+1|Xk(j|i), or equivalently

W(j|i).

– An observation distribution (also called an “emission distribution”) pYk|Xk(yk|xk) =

pY |X(yk|xk) 2, which describes the distribution for the output given the current

state. We’ll represent this with matrix B. Here, rows correspond to the current

state, and columns correspond to the observation. So, Bij = pY |X(j|i): the prob-

ability of observing output j from state i is Bij. Since the number of possible

observations isn’t necessarily the same as the number of possible states, B won’t

necessarily be square.

– An initial state distribution pX1, which describes the starting distribution over

states. We’ll represent this with a vector called π0, where item i in the vector

represents pX1(i).

• The forward-backward algorithm computes forward and backward messages as follows:

m(k−1)→k(xk) =

�

xk−1

prev. message

�

��

�

m(k−2)→(k−1)(xk−1)

observation term

�

��

�

pY |X(yk−1|xk−1)

transition term

�

��

�

W(xk−1|xk)

m(k+1)→k(xk) =

�

xk+1

m(k+2)→(k+1)(xk+1)

�

��

�

prev. message

pY |X(yk+1|xk+1)

�

��

�

observation term

W(xk|xk+1)

�

��

�

transition term

These messages are illustrated in Figure 2. The ﬁrst forward message m0→1(x1) is

initialized to π0(x1) = pX1(x1). The ﬁrst backward message m(n+1)→n(xn) is initialized

to uniform (this is equivalent to not including it at all).

Figure 3 illustrates the computation of one forward message m2→3(x3).

• To obtain a marginal distribution for a particular state given all the observations,

pXk|Y1,...,Yn, we simply multiply the incoming messages together with the observation

1We’re only going to worry about homogeneous Markov chains, where the transition distribution doesn’t

change over time: that’s why our W and A notations only depend on the values and not the timepoints.

2Once again, we’ll focus on Markov chains where the emission distribution is the same for every state.

2


term, and then normalize:

pXk|Y1,...,Yn(xk|y1, . . . , yn) ∝ m(k−1)→k(xk)m(k+1)→k(xk)pY |X(yk|xk)

Here, the symbol ∝ means “is proportional to”, and indicates that we have to normalize

at the end so that the answer sums to 1.

• Traditionally, the forward-backward algorithm computes a slightly diﬀerent set of mes-

sages. The forward message αk represents a message from k − 1 to k that includes

pY |X(yk|xk), and the backward message βk represents a message from k + 1 to k iden-

tical to m(k+1)→k above.

αk(xk) =

observation term

�

��

�

pY |X(yk|xk)

�

xk−1

prev. message

�

��

�

αk−1(xk−1)

transition term

�

��

�

W(xk−1|xk)

βk(xk) =

�

xk+1

βk+1(xk+1)

�

��

�

prev. message

pY |X(yk+1|xk+1)

�

��

�

observation term

W(xk|xk+1)

�

��

�

transition term

These messages have a particularly nice interpretation as probabilities:

αk(xk) = pY1,Y2,...,Yk,Xk(y1, y2, . . . , yk, xk)

βk(xk) = pYk+1,Yk+2,...,Yn|Xk(yk+1, yk+2, . . . , yn|xk)

The initial forward α message is initialized to α1(x1) = pX1(x1)pY |X(y1|x1). To obtain

a marginal distribution, we simply multiply the messages together and normalize:

pXk|Y1,...,Yn(xk|y1, . . . , yn) ∝ αk(xk)βk(xk)

Example

Suppose you send a robot to Mars. Unfortunately, it gets stuck in a canyon while landing

and most of its sensors break. You know the canyon has 3 areas. Areas 1 and 3 are sunny

and hot, while Area 2 is cold. You decide to plan a rescue mission for the robot from Area

3, knowing the following things about the robot:

















  …  

Y2

X2

X3

X1

Xn

Yn

Y1

Y3

m1!2(x2)

m2!3(x3)

pY |X(y2|x2)

W(x3|x2)

Figure 3: An illustration of how to compute m2→3(x3). In order for node 2 to summarize

its belief about X3, it must incorporate the previous message m1→2(x2), its observation

pY |X(y2|x2), and the relationship W(x3|x2) between X2 and X3.

3


• Every hour, it tries to move forward by one area (i.e. from Area 1 to Area 2, or Area 2

to Area 3). It succeeds with probability 0.75 and fails with probability 0.25. If it fails,

it stays where it is. If it is in Area 3, it always stays there (and waits to be rescued).

• The temperature sensor still works. Every hour, we get a binary reading telling us

whether the robot’s current environment is hot or cold.

• We have no idea where the robot initially got stuck.

Solution:

(a) Construct an HMM for this problem: deﬁne a transition matrix A, an observation matrix

B, and an initial state distribution π0.

(b) Suppose we observe the sequence (hot, cold, hot). First, before doing any computation,

determine the sequence of locations. Then, compute the forward and backward messages,

and determine the distribution for the second state using the messages. Do your answers

match up?

(a) We’ll start with the transition matrix. Remember that each row corresponds to the

current state, and each column corresponds to the next state. We’ll use 3 states, each

corresponding to an area.

• If the robot is in Area 1, it stays where it is with probability 0.25, moves to Area

2 with probability 0.75, and can’t move to Area 3.

• Similarly, if the robot is in Area 2, it stays where it is with probability 0.25, can’t

move back to Area 1, and moves to Area 3 with probability 0.75.

• If the robot is in Area 3, it always stays in Area 3.

Each item above gives us one row of A. Putting it all together, we obtain

A =

1

2

3

�

�

1

0.25

0.75

0

2

0

0.25

0.75

3

0

0

1

Next, let’s look at the observation matrix. There are two possible observations, hot and

cold. Areas 1 and 3 always produce “hot” readings while Area 2 always produces a

“cold” reading:

B =

hot

cold

�

�

1

1

0

2

0

1

3

1

0

4


Last but not least, since we have no idea where the robot starts, our initial state distri-

bution will be uniform:

π0 =

�

�

1

1/3

2

1/3

3

1/3

(b) Before doing any computation, we see that the sequence (hot,cold,hot) could only have

been observed from the hidden state sequence (1,2,3). Make sure you convince yourself

this is true before continuing!

We’ll start with the forward messages.

m1→2 =

�

x1

m0→1(x1)pY |X(y1|x1)

�

��

�

depends only on x1 and y1

ψ(x1, x2)

The output message should have three diﬀerent possibilities, one for each value of x2.

We can therefore represent it as a vector indexed by x2:

� �

·

value for x2 = 1

·

value for x2 = 2

·

value for x2 = 3

For each term in the sum (i.e., each possible value of x1):

• m0→1 comes from from the initial distribution. Normally it would come from the

previous message, but our ﬁrst forward message is always set to initial state distri-

bution.

• pY |X(y1|x1) comes from the column of B corresponding to our observation y1 = hot.

• ψ comes from a row of A: we are ﬁxing x1 and asking about possible values for

x2, which corresponds exactly to the transition distributions given in the rows of

A (remember that the rows of A correspond to the current state and the columns

correspond to the next state).

So, we obtain

m1→2 =

x1=1

�

��

�

1

3 · 1 ·





.25

.75

0



 +

x1=2

�

��

�

1

3 · 0 ·





0

.25

.75



 +

x1=3

�

��

�

1

3 · 1 ·





0

0

1





∝





1

3

4





Since our probabilities are eventually computed by multiplying messages and normaliz-

ing, we can arbitrary renormalize at any step to make the computation easier.

5


For the second message, we perform a similar computation:

m2→3 =

�

x2

m1→2(x2)˜φ(x2)ψ(x2, x3)

=

x2=1

�

��

�

1 · 0 ·





.25

.75

0



 +

x2=2

�

��

�

3 · 1 ·





0

.25

.75



 +

x2=3

�

��

�

4 · 0 ·





0

0

1





∝





0

1

3





The backwards messages are computed using a similar formula:

m3→2 =

�

x3

m4→3(x3)˜φ(x3)

�

��

�

depends only on x3

ψ(x2, x3)

The ﬁrst backwards message, m4→3(x3), is always initialized to uniform since we have

no information about what the last state should be. Note that this is equivalent to not

including that term at all.

For each value of x3, the transition term ψ(x2, x3) is now drawn from a column of A,

since we are interested in the probability of arriving at x3 from each possible state for

x2. We compute the messages as:

m3→2 =

x3=1

�

��

�

1 ·





.25

0

0



 +

x3=2

�

��

�

0 ·





.75

.25

0



 +

x3=3

�

��

�

1 ·





0

.75

1





∝





1

3

4





Similarly, the second backwards message is:

m2→1 =

x2=1

�

��

�

1 · 0 ·





.25

0

0



 +

x2=2

�

��

�

3 · 1 ·





.75

.25

0



 +

x2=3

�

��

�

4 · 0 ·





0

.75

1





∝





3

1

0





Notice from the symmetry of the problem that our forwards messages and backwards

messages were the same.

6


To compute the marginal distribution for X2 given the data, we multiply the messages

and the observation:

pX2|Y1,...,Yn(x2|y1, . . . , yn) ∝ m1→2(x2)m3→2(x2)˜φ(x2)

∝





1

3

4



 ·





1

3

4



 ·





0

1

0





=





0

1

0





Notice that in this case, because of our simpliﬁed observation model, the observation

“cold” allowed us to determine the state. This matches up with our earlier conclusion

that the robot must have been in Area 2 during the second hour.

If we were to compute α messages, we would start with our initial message, α1:

α1(x1) = pX1(x1)pY |X(y1|x1) =





1/3

0

1/3





The ﬁrst real message is computed as follows:

α2 =





0

1

0



 ·













x1=1

�

��

�

·1/3 ·





.25

.75

0



 +

x1=2

�

��

�

·0 ·





0

.25

.75



 +

x1=3

�

��

�

·1/3 ·





0

0

1

















∝





0

1

0





The second message is similar:

α3 =





1

0

1



 ·













x1=1

�

��

�

·0 ·





.25

.75

0



 +

x1=2

�

��

�

·1 ·





0

.25

.75



 +

x1=3

�

��

�

·0 ·





0

0

1

















∝





1

0

1





The β messages would be identical to our backwards messages computed earlier.

7

