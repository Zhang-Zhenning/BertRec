
RESEARCH-ARTICLE

Mining topics in documents: standing on the shoulders of big data

Authors: 

 

Authors Info &amp; Claims

KDD '14: Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining • August 2014

• Pages 1116–1125 • https://doi.org/10.1145/2623330.2623622

Published: 24 August 2014 Publication History

Zhiyuan Chen,

Bing Liu



Next 

Pages 1116–1125

 Previous



KDD '14: Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining

Mining topics in documents: standing on the shoulders of big data





Topic modeling has been widely used to mine topics from documents. However, a key weakness of topic modeling is that it needs a

large amount of data (e.g., thousands of documents) to provide reliable statistics to generate coherent topics. However, in practice,

many document collections do not have so many documents. Given a small number of documents, the classic topic model LDA

generates very poor topics. Even with a large volume of data, unsupervised learning of topic models can still produce unsatisfactory

results. In recently years, knowledge-based topic models have been proposed, which ask human users to provide some prior domain

knowledge to guide the model to produce better topics. Our research takes a radically different approach. We propose to learn as

humans do, i.e., retaining the results learned in the past and using them to help future learning. When faced with a new task, we first

mine some reliable (prior) knowledge from the past learning/modeling results and then use it to guide the model inference to generate

more coherent topics. This approach is possible because of the big data readily available on the Web. The proposed algorithm mines

two forms of knowledge: must-link (meaning that two words should be in the same topic) and cannot-link (meaning that two words

should not be in the same topic). It also deals with two problems of the automatically mined knowledge, i.e., wrong knowledge and

knowledge transitivity. Experimental results using review documents from 100 product domains show that the proposed approach

makes dramatic improvements over state-of-the-art baselines.

ABSTRACT

 Get Access

 







 92  1,512

 Sign in



KDD




Supplemental Material

p1116-sidebyside.mp4

MP4

280.7 MB

 Play stream

 Download

References

1.

2.

3.

4.

5.

6.

7.

8.

9.

10.

11.

12.

13.

14.

D. Andrzejewski, X. Zhu, and M. Craven. Incorporating domain knowledge into topic modeling via Dirichlet Forest priors. In ICML, pages

25--32, 2009. 

D. Andrzejewski, X. Zhu, M. Craven, and B. Recht. A framework for incorporating general domain knowledge into latent Dirichlet

allocation using first-order logic. In IJCAI, pages 1171--1177, 2011. 

D. M. Blei and J. D. McAuliffe. Supervised Topic Models. In NIPS, pages 121--128, 2007.

D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet Allocation. Journal of Machine Learning Research, 3:993--1022, 2003. 

S. R. K. Branavan, H. Chen, J. Eisenstein, and R. Barzilay. Learning Document-Level Semantic Properties from Free-Text Annotations.

In ACL, pages 263--271, 2008.

J. Chang, J. Boyd-Graber, W. Chong, S. Gerrish, and D. M. Blei. Reading Tea Leaves: How Humans Interpret Topic Models. In NIPS,

pages 288--296, 2009.

Z. Chen and B. Liu. Topic Modeling using Topics from Many Domains, Lifelong Learning and Big Data. In ICML, 2014.

Z. Chen, A. Mukherjee, and B. Liu. Aspect Extraction with Automated Prior Knowledge Learning. In ACL, pages 347--358, 2014.

Z. Chen, A. Mukherjee, B. Liu, M. Hsu, M. Castellanos, and R. Ghosh. Discovering Coherent Topics Using General Knowledge. In CIKM,

pages 209--218, 2013. 

Z. Chen, A. Mukherjee, B. Liu, M. Hsu, M. Castellanos, and R. Ghosh. Exploiting Domain Knowledge in Aspect Extraction. In EMNLP,

pages 1655--1667, 2013.

G. Heinrich. A Generic Approach to Topic Models. In ECML PKDD, pages 517 -- 532, 2009. 

T. Hofmann. Probabilistic Latent Semantic Analysis. In UAI, pages 289--296, 1999. 

M. Hu and B. Liu. Mining and Summarizing Customer Reviews. In KDD, pages 168--177, 2004. 

Y. Hu, J. Boyd-Graber, and B. Satinoff. Interactive Topic Modeling. In ACL, pages 248--257, 2011. 


15.

16.

17.

18.

19.

20.

21.

22.

23.

24.

25.

26.

27.

28.

29.

30.

31.

32.

33.

34.

35.

36.

J. Jagarlamudi, H. D. III, and R. Udupa. Incorporating Lexical Priors into Topic Models. In EACL, pages 204--213, 2012. 

Y. Jo and A. H. Oh. Aspect and sentiment unification model for online review analysis. In WSDM, pages 815--824, Feb. 2011. 

J.-h. Kang, J. Ma, and Y. Liu. Transfer Topic Modeling with Ease and Scalability. In SDM, pages 564--575, 2012.

B. Liu. Web data mining. Springer, 2007.

B. Liu. Sentiment Analysis and Opinion Mining. Morgan &amp; Claypool Publishers, 2012.

B. Liu, W. Hsu, and Y. Ma. Mining association rules with multiple minimum supports. In KDD, pages 337--341. ACM, 1999. 

Y. Lu and C. Zhai. Opinion integration through semi- supervised topic modeling. In WWW, pages 121--130, 2008. 

H. Mahmoud. Polya Urn Models. Chapman &amp; Hall/CRC Texts in Statistical Science, 2008. 

Q. Mei, X. Ling, M. Wondra, H. Su, and C. Zhai. Topic sentiment mixture: modeling facets and opinions in weblogs. In WWW, pages

171--180, 2007. 

D. Mimno, H. M. Wallach, E. Talley, M. Leenders, and A. McCallum. Optimizing semantic coherence in topic models. In EMNLP, pages

262--272, 2011. 

S. Moghaddam and M. Ester. The FLDA Model for Aspect-based Opinion Mining: Addressing the Cold Start Problem. In WWW, pages

909--918, 2013. 

A. Mukherjee and B. Liu. Aspect Extraction through Semi-Supervised Modeling. In ACL, pages 339--348, 2012. 

S. J. Pan and Q. Yang. A Survey on Transfer Learning. IEEE Trans. Knowl. Data Eng., 22(10):1345--1359, 2010. 

J. Petterson, A. Smola, T. Caetano, W. Buntine, and S. Narayanamurthy. Word Features for Latent Dirichlet Allocation. In NIPS, pages

1921--1929, 2010.

D. Ramage, D. Hall, R. Nallapati, and C. D. Manning. Labeled LDA: a supervised topic model for credit attribution in multi-labeled

corpora. In EMNLP, pages 248--256, 2009. 

D. L. Silver, Q. Yang, and L. Li. Lifelong Machine Learning Systems: Beyond Learning Algorithms. In AAAI Spring Symposium: Lifelong

Machine Learning, 2013.

S. Thrun. Lifelong Learning Algorithms. In S. Thrun and L. Pratt, editors, Learning To Learn. Kluwer Academic Publishers, 1998. 

I. Titov and R. McDonald. Modeling online reviews with multi-grain topic models. In WWW, pages 111--120, 2008. 

H. Wang, Y. Lu, and C. Zhai. Latent aspect rating analysis on review text data: a rating regression approach. In KDD, pages 783--792,

2010. 

G. Xue, W. Dai, Q. Yang, and Y. Yu. Topic-bridged PLSA for cross-domain text classification. In SIGIR, pages 627--634, 2008. 

S. H. Yang, S. P. Crain, and H. Zha. Bridging the Language Gap: Topic Adaptation for Documents with Different Technicality. In

AISTATS, volume 15, pages 823--831, 2011.

Z. Zhai, B. Liu, H. Xu, and P. Jia. Constrained LDA for grouping product features in opinion mining. In PAKDD, pages 448--459, May

2011. 


Read More

Read More

Read More

37.

38.

W. X. Zhao, J. Jiang, H. Yan, and X. Li. Jointly Modeling Aspects and Opinions with a MaxEnt-LDA Hybrid. In EMNLP, pages 56--65,

2010. 

G. K. Zipf. Selective Studies and the Principle of Relative Frequency in Language. Harvard University Press, 1932.

Index Terms



Mining topics in documents: standing on the shoulders of big data

Information systems

Information retrieval

Document representation

Recommendations

Mining Aspect-Specific Opinion using a Holistic Lifelong Topic Model

A biterm topic model for short texts

Research on Multi-document Summarization Based on LDA Topic Model

Comments


Check if you have access through your login credentials or your institution to get full access on this article.



Sign in

Get this Publication

Information

Contributors

Login options

Full Access

KDD '14: Proceedings of the 20th ACM SIGKDD international conference on Knowledge

discovery and data mining

August 2014 2028 pages

ISBN:

9781450329569

DOI:

10.1145/2623330

General Chairs:

Sofus Macskassy,



Claudia Perlich,Program Chairs:



Jure Leskovec,

Wei Wang,

Rayid Ghani

Copyright © 2014 ACM

Association for Computing Machinery

New York, NY, United States

Published: 24 August 2014

Request permissions about this article.

Request Permissions

Published in

Publisher

Publication History

Permissions


Bibliometrics

Citations



92

opinion aspect extraction

lifelong learning

topic model

Research-Article

KDD '14 Paper Acceptance Rate 151 of 1,036 submissions, 15%Overall Acceptance Rate 1,133 of 8,635 submissions, 13%

More



KDD '23

Sponsor:

SIGKDD

SIGMOD

The 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining

  August 6 - 10, 2023

  Long Beach , CA , USA

Check for updates

Author Tags

Qualifiers

Acceptance Rates

Upcoming Conference


View or Download as a PDF file.

 PDF

View online with eReader.

 eReader

Figures

Other

https://dl.acm.org/doi/10.1145/2623330.2623622



 Copy Link

30

0

92

Total

Citations

View Citations

1,512

Total

Downloads

Downloads (Last 12 months)

Downloads (Last 6 weeks)



View Author Metrics

Article Metrics

Other Metrics

PDF Format

eReader

Share this Publication link

Share on Social Media




View Table Of Contents

















0





Categories

















About

















Join









Connect













The ACM Digital Library is published by the Association for Computing Machinery. Copyright © 2023 ACM, Inc.

Terms of Usage 

Privacy Policy 

Code of Ethics

 





