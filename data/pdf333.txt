


Published in

Towards Data Science



Mar 28, 2020

·

23 min read

·

Save

Hidden Markov Model — Implemented from scratch

A short pause in the summer heat. Portugal, 2019.

subscribe

Introduction

gentle step by step practical implementation

Notation








A 

B 

A

B

Fundamental definitions

≤

≤



≤

≤

ProbabilityVector

@classmethod

__eq__

__mul__

__rmul__

__matmul__

__truediv__

argmax

__getitem__

Example


Probability Matrix

Probability Matrix

A

B


observable

Example


Implementing Hidden Markov Chain

HiddenMarkovChain

A B

Computing score

A B

∏

∏

score


Example


Score with forward-pass


Example

Simulation and convergence

A B

A 

B 

Example


Figure 1. An example of a Markov process. The states and the observable sequences are shown.

Latent states

A 

Example

Figure 2. Convergence of the probabilities against the length of the chain.


HiddenMarkovChain

Expanding the class

≠


Validation

.run

.uncover

Example


Training the model

A B

Expanding the class

HiddenMarkovModel_Uncover

A 

B

A B 


A B

._difammas

A B 

A B 


Example


Figure 3. Example of the score funciton during training.

Verification



Figure 4. Result after training of the model. The dotted lines represent the matched sequences. The lines represent

the frequency of occurrence for a particular sequence: trained model (red) and freshly initialized (black). The

initialized results in almost perfect uniform distribution of sequences, while the trained model gives a strong

preference towards the observable sequence.

Conclusion


There will be more…

subscribe to my newsletter. 

9



Follow

Your home for data science. A Medium publication sharing concepts, ideas and codes.



Read more from Towards Data Science



Data Science

Machine Learning

Python

Probability

Algorithms




