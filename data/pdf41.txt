
Maximum Likelihood (ML),  

Expectation Maximization (EM) 

 

 

Pieter Abbeel 

UC Berkeley EECS 

 

 

 

 

Many slides adapted from Thrun, Burgard and Fox, Probabilistic Robotics 

 

TexPoint fonts used in EMF




n  Maximum likelihood (ML) 

n  Priors, and maximum a posteriori (MAP) 

n  Cross-validation 

n  Expectation Maximization (EM) 

Outline 




n  Let µ = P(up),  1-µ = P(down) 

n  How to determine µ ? 

n  Empirical estimate:  8 up, 2 down à 

Thumbtack 
























n 

http://web.me.com/todd6ton/Site/Classroom_Blog/Entries/2009/10/7_A_Thumbtack_Experiment.html 






n  µ = P(up),  1-µ = P(down) 

n  Observe: 

n  Likelihood of the observation sequence depends on µ: 

n  Maximum likelihood finds  

 

à  extrema at µ = 0, µ = 1, µ = 0.8 

à  Inspection of each extremum yields  µML = 0.8  

Maximum Likelihood 
































n 

More generally, consider binary-valued random variable with µ = P(1), 1-µ = 

P(0), assume we observe n1 ones, and n0 zeros 

n  Likelihood: 

n  Derivative: 

n  Hence we have for the extrema: 

n  n1/(n0+n1) is the maximum 

n 

= empirical counts.  

Maximum Likelihood 










n  The function 

 

 

 

is a monotonically increasing function of x 

n  Hence for any (positive-valued) function f: 

n  In practice often more convenient to optimize the log-

likelihood rather than the likelihood itself 

n  Example:  

 

 

Log-likelihood 












n  Reconsider thumbtacks: 8 up, 2 down 

n  Likelihood 

n  Definition: A function f is concave if and only 

n  Concave functions are generally easier to maximize then 

non-concave functions  

Log-likelihood ßà Likelihood 





n  log-likelihood 

Concave 

Not Concave 








f is concave if and only 

 

 

 

 

 

 

 

 

“Easy” to maximize 

Concavity and Convexity 





x1 

x2 

¸ x2+(1-¸)x2 





f is convex if and only 

 

 

 

 

 

 

 

 

“Easy” to minimize 



x1 

x2 

¸ x2+(1-¸)x2 








n  Consider having received samples 

ML for Multinomial 














n  Given samples 

n  Dynamics model: 

n  Observation model:   

 

 

 

 

à Independent ML problems for each        and each  

ML for Fully Observed HMM 






















n  Consider having received samples 

n  3.1, 8.2, 1.7 

ML for Exponential Distribution 



Source: wikipedia 









ll 






n  Consider having received samples 

n  

ML for Exponential Distribution 



Source: wikipedia 














n  Consider having received samples 

n  

Uniform 














n  Consider having received samples 

n  

ML for Gaussian 




















Equivalently: 

 

 

More generally: 

ML for Conditional Gaussian 














ML for Conditional Gaussian 




















ML for Conditional Multivariate Gaussian 


















Aside: Key Identities for Derivation on 

Previous Slide 






n  Consider the Linear Gaussian setting: 

n  Fully observed, i.e., given 

n  à Two separate ML estimation problems for conditional 

multivariate Gaussian:  

n  1: 

n  2:    

ML Estimation in Fully Observed 

Linear Gaussian Bayes Filter Setting 




















n  Let µ = P(up),  1-µ = P(down) 

n  How to determine µ ? 

n  ML estimate:  5 up, 0 down à 

n  Laplace estimate: add a fake count of 1 for each outcome 

Priors --- Thumbtack 


















n  Alternatively, consider µ to be random variable 

n  Prior P(µ) / µ(1-µ) 

n  Measurements: P( x | µ ) 

n  Posterior: 

n  Maximum A Posterior (MAP) estimation  

n  = find µ that maximizes the posterior     

à 

Priors --- Thumbtack 


















Priors --- Beta Distribution 











Figure source: Wikipedia 




n  Generalizes Beta distribution 

n  MAP estimate corresponds to adding fake counts n1, …, nK 

Priors --- Dirichlet Distribution 








n 

Assume variance known.  (Can be extended to also find MAP for variance.) 

n  Prior:  

MAP for Mean of Univariate Gaussian 












n  Assume variance known.  (Can be extended to also find MAP 

for variance.) 

n  Prior:  

MAP for Univariate Conditional Linear 

Gaussian 













[Interpret!] 






MAP for Univariate Conditional Linear 

Gaussian: Example 









TRUE --- 

Samples . 

ML --- 

MAP --- 






n  Choice of prior will heavily influence quality of result 

n  Fine-tune choice of prior through cross-validation: 

n  1. Split data into “training” set and “validation” set 

n  2. For a range of priors,  

n  Train: compute µMAP on training set 

n  Cross-validate: evaluate performance on validation set by evaluating 

the likelihood of the validation data under µMAP just found 

n  3. Choose prior with highest validation score  

n  For this prior, compute µMAP on (training+validation) set 

n 

Typical training / validation splits: 

n  1-fold: 70/30, random split 

n  10-fold: partition into 10 sets, average performance for each of the sets being the 

validation set and the other 9 being the training set 

Cross Validation 




n  Maximum likelihood (ML) 

n  Priors, and maximum a posteriori (MAP) 

n  Cross-validation 

n  Expectation Maximization (EM) 

Outline 




n  Generally: 

n  Example:  

n  ML Objective: given data z(1), …, z(m) 

n 

Setting derivatives w.r.t. µ, µ, § equal to zero does not enable to solve 

for their ML estimates in closed form 

We can evaluate function à we can in principle perform local optimization.  In this lecture: “EM” algorithm, 

which is typically used to efficiently optimize the objective (locally)  

Mixture of Gaussians 














n 

Example: 

n  Model: 

n  Goal:  

n  Given data z(1), …, z(m)  (but no x(i) observed) 

n  Find maximum likelihood estimates of µ1, µ2 

n  EM basic idea: if x(i) were known à two easy-to-solve separate ML 

problems 

n  EM iterates over 

n  E-step: For i=1,…,m   fill in missing data x(i) according to what is most 

likely given the current model µ 

n  M-step: run ML for completed data, which gives new model µ 

Expectation Maximization (EM) 






n  EM solves a Maximum Likelihood problem of the form: 

 

µ: parameters of the probabilistic model we try to find 

x: unobserved variables 

z: observed variables 

 

 

EM Derivation 





Jensen’s Inequality 




Jensen’s inequality 





x1 

x2 

E[X] = ¸ x2+(1-¸)x2 





Illustration:  

P(X=x1) = 1-¸,  

P(X=x2) = ¸ 




EM Algorithm: Iterate 

 1. E-step: Compute 

 

 2. M-step: Compute  

 

EM Derivation (ctd) 



Jensen’s Inequality: equality holds when

 

 

    is an affine  

 

function.  This is achieved for   









M-step optimization can be done efficiently in most cases 

E-step is usually the more expensive step 

It does not fill in the missing data x with hard values, but finds a distribution q(x) 




n  M-step objective is upper-

bounded by true objective 

n  M-step objective is equal 

to true objective at 

current parameter 

estimate 

 

EM Derivation (ctd) 



n  à Improvement in true objective is at least as large as 

improvement in M-step objective 






n  Estimate 1-d mixture of two Gaussians with unit variance: 

n  

n  one parameter µ ; µ1 = µ - 7.5, µ2 = µ+7.5 

EM 1-D Example --- 2 iterations 






n  X ~ Multinomial Distribution, P(X=k ; µ) = µk 

n  Z ~ N(µk, §k) 

n  Observed: z(1), z(2), …, z(m) 

 

EM for Mixture of Gaussians 






n  E-step: 

n  M-step: 

EM for Mixture of Gaussians 
















n  Given samples 

n  Dynamics model: 

n  Observation model:   

n  ML objective: 

 

 

 

à  No simple decomposition into independent ML problems for    

each        and each  

à  No closed form solution found by setting derivatives equal to zero 

ML Objective HMM 


















n  

à  µ and ° computed from “soft” counts  

EM for HMM --- M-step 










n  No need to find conditional full joint  

n  Run smoother to find: 

EM for HMM --- E-step 








n  Linear Gaussian setting: 

n  Given 

n  ML objective: 

n  EM-derivation: same as HMM 

ML Objective for Linear Gaussians 










n  Forward: 

n  Backward: 

EM for Linear Gaussians --- E-Step 










EM for Linear Gaussians --- M-step 



[Updates for A, B, C, d. TODO: Fill in once found/derived.] 




n  When running EM, it can be good to keep track of the log-

likelihood score --- it is supposed to increase every iteration 

EM for Linear Gaussians --- The 

Log-likelihood  










n  As the linearization is only an approximation, when 

performing the updates, we might end up with parameters 

that result in a lower (rather than higher) log-likelihood 

score 

n  à Solution: instead of updating the parameters to the newly 

estimated ones, interpolate between the previous parameters 

and the newly estimated ones.  Perform a “line-search” to 

find the setting that achieves the highest log-likelihood score 

EM for Extended Kalman Filter Setting 

