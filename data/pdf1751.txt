


13 Citations

13 Citations

13 Citations

16 References

Related Papers

DOI: 10.1145/1277741.1277891  • Corpus ID: 6717784

IDF revisited: a simple new derivation within the Robertson-Spärck

Jones probabilistic model

Lillian Lee  • Published in 

 8 May 2007  • Economics

There have been a number of prior attempts to theoretically justify the effectiveness of the inverse document frequency (IDF). Those that take as their

starting point Robertson and Sparck Jones's probabilistic model are based on strong or complex assumptions. We show that a more intuitively plausible

assumption suffices. Moreover, the new assumption, while conceptually very simple, provides a solution to an estimation problem that had been deemed

intractable by Robertson and Walker (1997). 

Annual International ACM…

View on ACM





cs.cornell.edu









Sort by Relevance

Generalized inverse document frequency

Generalized inverse document frequency

Donald Metzler  • Computer Science  • CIKM '08  • 2008

 A new, more generalized form of IDF is derived that is based on the Robertson-Sparck Jones relevance weight, and it is

shown that generalized IDF outperforms classical versions of IDF on a number of ad hoc retrieval tasks.



37



PDF

 • 

Efficient and Effective Higher Order Proximity Modeling

Efficient and Effective Higher Order Proximity Modeling

Xiaolu Lu, Alistair Moffat, J. Culpepper  • Computer Science  • ICTIR  • 2016

 This work provides further evidence that term-dependency features not captured by bag-of-words models can reliably

improve retrieval effectiveness, and presents a new variation on the highly-effective MRF model that relies on a BM25-derived

potential.



9



PDF

 • 

Automatic Term Reweighting for Query Expansion

Automatic Term Reweighting for Query Expansion

Reuben Crimp, A. Trotman  • Computer Science  • ADCS  • 2017

 This work found that reweighting through term frequency merging is more effective than standard query expansion,

which reduces the impact of spurious expansion terms being over represented in the modified query.



6



PDF

 • 

Interpreting TF-IDF term weights as making relevance decisions

Interpreting TF-IDF term weights as making relevance decisions

H. Wu, R. Luk, Kam-Fai Wong, K. Kwok  • Computer Science  • TOIS  • 2008

 A novel probabilistic retrieval model forms a basis to interpret the TF-IDF term weights as making relevance decisions,

and it is shown that the term-frequency factor of the ranking formula can be rendered into different term- frequency factors of

existing retrieval systems.



757



PDF

 • 

Cs 674/info 630: Advanced Language Technologies

Cs 674/info 630: Advanced Language Technologies

Lillian Lee Scribes, Nam Nguyen, M. Ott  • Computer Science  • 2007

P~ θ : V 7→ [0, 1], where ~ θ is an element of the m-dimensional probability simplex. Hence the probability assigned to a single

term vj is defined as: P~ θ (vj) def = θ[j]. Also recall from the… 



PDF

 • 

TLDR

TLDR

Expand

View 1 excerpt, cites background

Save

Alert

TLDR

TLDR

Expand

View 1 excerpt, cites methods

Save

Alert

TLDR

TLDR

Expand

View 1 excerpt, cites methods

Save

Alert

TLDR

TLDR

Expand

View 11 excerpts, cites methods, background and results

Save

Alert

Expand

View 1 excerpt, cites background

Save

Alert



Sign In

By clicking accept or continuing to use the site, you agree to the terms outlined in our Privacy Policy, Terms of Service, and Dataset License



ACCEPT &amp; CONTINUE






16 References

16 References







Efficient and effective retrieval using Higher-Order proximity models

Efficient and effective retrieval using Higher-Order proximity models

X. Lu  • Computer Science, Business  • 2017

 Information Retrieval systems leveraging proximity heuristics to estimate the relevance of a document have shown to be

effective, however, the computational cost is high.

Improvements to BM25 and Language Models Examined

Improvements to BM25 and Language Models Examined

A. Trotman, Antti Puurula, Blake Burgess  • Computer Science  • ADCS  • 2014

 This investigation finds that once trained (using particle swarm optimization) there is very little difference in

performance between these functions, that relevance feedback is effective, that stemming is effective and that it remains

unclear which function is best over-all.



128



PDF

 • 

Scalable Text Mining with Sparse Generative Models

Scalable Text Mining with Sparse Generative Models

Antti Puurula  • Computer Science  • ArXiv  • 2016

 A unifying formalization for generative text models is defined, bringing together research traditions that have used

formally equivalent models, but ignored parallel developments, and reduces the computational complexity of the common text

mining operations according to sparsity.



2



PDF

 • 

Combining Modifications to Multinomial Naive Bayes for Text Classification

Combining Modifications to Multinomial Naive Bayes for Text Classification

Antti Puurula  • Computer Science  • AIRS  • 2012

 The optimized combination of popular modifications to generative models in the context of MNB text classification

results in over 20% mean reduction in classification errors compared to baseline MNB models, reducing the gap between SVM

and MNB mean performance by over 60%.



10

 • 

Notice of RetractionEmpirical study of IDF on text classification dataset

Notice of RetractionEmpirical study of IDF on text classification dataset

Ziqiang Li, Mingtian Zhou  • Computer Science  • 2010 3rd International Conference on Computer Science and Information Technology  • 2010

 The observation shows that IDF has little ability of category recognization and contribute a little to text when used by

itself only, and it seems that the novelty or expressive force of a feature can be formulated as the linear combination of IDF,

average occuring frequence and it`s standard deviation.

1

2

TLDR

TLDR

Expand

Save

Alert

TLDR

TLDR

Expand

Save

Alert

TLDR

TLDR

Expand

View 1 excerpt, cites background

Save

Alert

TLDR

TLDR

Expand

Save

Alert

TLDR

TLDR

Expand

Save

Alert







Sort by Relevance

Understanding inverse document frequency: on theoretical arguments for IDF

Understanding inverse document frequency: on theoretical arguments for IDF

S. Robertson  • Computer Science  • J. Documentation  • 2004

 It is shown that the Information Theory approaches are problematic, but that there are good theoretical justifications of

both IDF and TF*IDF in the traditional probabilistic model of information retrieval.



1,362



PDF

 • 

Relevance information: a loss of entropy but a gain for IDF?

Relevance information: a loss of entropy but a gain for IDF?

A. D. Vries, T. Roelleke  • Computer Science  • SIGIR '05  • 2005

 The main result is a formal framework uncovering the close relationship of a generalised idf and the BIR model, and a

Poisson-based idf is superior to the classical idf, where the superiority is particularly evident for long queries.



31



PDF

 • 

Inverse Document Frequency (IDF): A Measure of Deviations from Poisson

Inverse Document Frequency (IDF): A Measure of Deviations from Poisson

TLDR

TLDR

Expand

View 1 excerpt, references methods

Save

Alert

TLDR

TLDR

Expand

View 1 excerpt, references background

Save

Alert




Related Papers

Related Papers









Kenneth Ward Church, W. Gale  • Economics  • VLC@ACL  • 1995

 In inverse document frequency (IDF), a quantity borrowed from Information Retrieval, is used to distinguish words like

somewhat and boycott, but boycott is a better keyword because its IDF is farther from what would be expected by chance

(Poisson).



247



PDF

 • 

A Note on Inverse Document Frequency Weighting Scheme

A Note on Inverse Document Frequency Weighting Scheme

S. Wong, Yiyu Yao  • Computer Science  • 1989

 It is shown that IDF weights can be derived from the proposed approach by assuming that each index term has an even

distribution within a subset of documents.



3

 • 

Why Inverse Document Frequency?

Why Inverse Document Frequency?

K. Papineni  • Computer Science  • NAACL  • 2001

 It is shown that the IDF is the optimal weight associated with a word-feature in an information retrieval setting where the

authors treat each document as the query that retrieves itself, which means IDF is optimal for document self-retrieval.



124



PDF

 • 

Using Probabilistic Models of Document Retrieval without Relevance Information

Using Probabilistic Models of Document Retrieval without Relevance Information

W. Bruce Croft, David J. Harper  • Computer Science  • J. Documentation  • 1979

 This paper considers the situation where no relevance information is available, that is, at the start of the search, based

on a probabilistic model, and proposes strategies for the initial search and an intermediate search.



529

 • 

A theory of term weighting based on exploratory data analysis

A theory of term weighting based on exploratory data analysis

W. R. Grei  • Computer Science  • SIGIR 1998  • 1998

 It is argued that exploratory data analysis can be a valuable tool for research whose goal is the development of an

explanatory theory of information retrieval.



71

 • 

A formal study of information retrieval heuristics

A formal study of information retrieval heuristics

H. Fang, Tao Tao, ChengXiang Zhai  • Computer Science, Business  • SIGIR '04  • 2004

 A formal study of retrieval heuristics is presented and it is found that the empirical performance of a retrieval formula is

tightly related to how well it satisfies basic desirable constraints.



342



PDF

 • 

Relevance weighting of search terms

Relevance weighting of search terms

S. Robertson, Karen Spärck Jones  • Computer Science  • J. Am. Soc. Inf. Sci.  • 1976

 This paper examines statistical techniques for exploiting relevance information to weight search terms using

information about the distribution of index terms in documents in general and shows that specific weighted search methods

are implied by a general probabilistic theory of retrieval.



2,438

 • 

A statistical interpretation of term specificity and its application in retrieval

A statistical interpretation of term specificity and its application in retrieval

Karen Spärck Jones  • Psychology  • J. Documentation  • 2004

 It is argued that terms should be weighted according to collection frequency, so that matches on less frequent, more

specific, terms are of greater value than matches on frequent terms.



4,085



PDF

 • 

1

2

TLDR

TLDR

Expand

View 1 excerpt, references background

Save

Alert

TLDR

TLDR

Expand

View 1 excerpt, references background

Save

Alert

TLDR

TLDR

Expand

View 1 excerpt, references background

Save

Alert

TLDR

TLDR

Expand

View 9 excerpts, references background and methods

Save

Alert

TLDR

TLDR

Expand

View 3 excerpts, references background

Save

Alert

TLDR

TLDR

Expand

View 1 excerpt, references background

Save

Alert

TLDR

TLDR

Expand

View 1 excerpt, references methods

Save

Alert

TLDR

TLDR

Expand

View 1 excerpt, references background

Save

Alert
















Stay Connected With Semantic Scholar

Stay Connected With Semantic Scholar

Your E-mail Address



Sign Up

What Is Semantic Scholar?

Semantic Scholar is a free, AI-powered research tool for scientific literature, based at the

Allen Institute for AI.

Learn More

About

About Us

Publishers

Blog

AI2 Careers

Product

Product Overview

Beta Program

S2AG API

Semantic Reader

Research

Publications

Team

Research Careers

Resources

Help

FAQ

Librarians

Tutorials

Contact









Proudly built by AI2

Collaborators &amp; Attributions • Terms of Service • Privacy Policy

