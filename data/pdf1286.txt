






One stop guide to computer science students for solved questions, Notes, tutorials, solved exercises,

online quizzes, MCQs and more on DBMS, Advanced DBMS, Data Structures, Operating Systems,

Machine learning, Natural Language Processing etc.



Advanced Database Concepts

Data structures, Operating Systems

Natural Language Processing

Quiz Questions and Answers

DBMS, ADBMS Question Bank

SQL

RDBMS Exam and Interview Questions

Parallel Databases

ADBMS Quizzes

Advanced DBMS Concepts

Distributed Databases

Modern Databases - Special Purpose Databases

Object Based Database Systems

Please visit, subscribe and share 10 Minutes Lectures in Computer Science

Sunday, February 28, 2021

What is smoothing in NLP and why do we need it

Smoothing is the process of flattening a probability distribution implied by a language model so

that all reasonable word sequences can occur with some probability. This often involves

broadening the distribution by redistributing weight from high probability regions to zero

probability regions.

Smoothing not only prevents zero probabilities, attempts to improves the accuracy of the model as

a whole.

In a language model, we use parameter estimation (MLE) on training data. We can’t actually

evaluate our MLE models on unseen test data because both are likely to contain words/n-grams

that these models assign zero probability to. Relative frequency estimation assigns all probability

mass to events in the training corpus. But we need to reserve some probability mass to events that

don’t occur (unseen events) in the training data.

Example:

Training data: The cow is an animal.

Test data: The dog is an animal.

If we use unigram model to train;

P(the) = count(the)/(Total number of words in training set) = 1/5.

Likewise, P(cow) = P(is) = P(an) = P(animal) = 1/5

To evaluate (test) the unigram model;

P(the cow is an animal) = P(the) * P(cow) * P(is) * P(an) * P(animal) = 0.00032

 

While we use unigram model on the test data, it becomes zero because P(dog) = 0. The term ‘dog’

never occurred in the training data. Hence, we use smoothing.

 

****************

 

 

What is smoothing in the context of natural language processing, define smoothing in NLP, what is the purpose of smoothing in nlp,

is smoothing an important task in language model

Smoothing in NLP

Why do we need smoothing?

Explain the concept of smoothing in NLP

Why do we need smoothing

What is the advantage of smoothing the data in language models

Related posts:

Language model in natural language processing

Bi-gram, tri-gram and n-gram models

Natural Language Processing Glossary

Natural Language Processing Home Page

Translate

Share Your Articles





You can share your articles,

questions, etc on any of the

computer science subjects by

clicking the above IMAGE

Home

RDBMS Exam and Interview Questions

Quiz Questions and Answers

Other Computer Science Subjects

Parallel Databases

ADBMS Quizzes

Advanced DBMS Concepts

Distributed Databases

Advanced Database Concepts

Links to Useful Video Lectures

SQL

DBMS, ADBMS Question Bank

Animations, Graphics, and Videos

Modern Databases - Special Purpose

Databases

Object Based Database Systems

Miscellaneous

Privacy policy

Natural Language Processing

Pages

Ranked within top 200 in Asia (QS - Asia

University Rankings 2022.

Seven Subjects of VIT are ranked by QS

World University Ranking by Subject

2021.

12th best research institution of India

(NIRF Ranking, Govt. of India 2021).

NAAC Accreditation with highest grade in

the last three consecutive cycles.

Recognized as Institution of

Eminence(IoE), Govt. of India.

Vellore Institute of Technology

Normalization 

(114)

Database 

Quizzes 

(87)

Labels






data recovery

Newer Post

Older Post

Home

Subscribe to: Post Comments (Atom)



Natural Language



Processing MCQ



- W...



Natural Language



Processing MCQ



- C...



Natural Language



Processing MCQ



- I...



Natural Language



Processing MCQ



- F...



Natural Language



Processing MCQ



- L...

By K Saravanakumar Vellore Institute of Technology - February 28, 2021 

Labels: natural language processing, NLP

RELATED POSTS:





















No comments:

Post a Comment

MCQ in Natural Language Processing, Quiz questions with answers in NLP, Top interview questions in NLP with answers Multiple Choice Que...

Featured Content

Multiple choice questions in Natural Language Processing Home

Relational algebra in database management systems solved exercise

Relational algebra in database management systems solved exercise Relational algebra – solved exercise Question: Consider the fo...

Machine Learning Multiple Choice Questions and Answers Home

Top 5 Machine Learning Quiz Questions with Answers explanation, Interview questions on machine learning, quiz questions for data scienti...

Machine Learning Multiple Choice Questions and Answers 01

Top 5 Machine Learning Quiz Questions with Answers explanation, Interview questions on machine learning, quiz questions for data scientist...

Bigram probability estimate of a word sequence

Bigram probability estimate of a word sequence, Probability estimation for a sentence using Bigram language model Bigram Model - Probab...

Bigram, Trigram, and NGram Models in NLP

Bigram Trigram and NGram in NLP, How to calculate the unigram, bigram, trigram, and ngram probabilities of a sentence? Maximum likelihood...

All time most popular contents

Machine Learning Quiz (76)

Distributed Database (52) NLP (49)

Data Structures (41) Question Bank

(36) 

NLP 

Quiz 

Questions 

(35)

Transaction Management (35) Solved

Exercises (34) ER Model (33) DBMS

Question Paper (29) SQL (23) Real

Time Database (22) Minimal cover (20)

Parallel Database (17) Indexing (16)

Normal Forms (16) Object Databases (14)

2PC Protocol (13) NLP solved exercise (13)

natural language processing (13) Disk

Storage Access Exercises (12) SQL

Exercise (12) Concurrency Control (11)

Deadlock (11) Distributed Database Quiz

(9) Serializability (9) Transaction (8) ACID

(7) Database Languages (7) 

















K Saravanakumar Vellore Institute of Technology



Saravanakumar Kandasamy

Contributors

Report Abuse

Dear readers, though most of the content of this site is written by the authors and contributors of this site, some of the content are searched, found and compiled from various other Internet sources for the benefit of

readers.

Disclaimer

Copyright © exploredatabase.com 2020. All rights reserved. Theme images by gaffera. Powered by Blogger.

