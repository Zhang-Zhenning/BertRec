
RESEARCH-ARTICLE

Information Retrieval Meets Game Theory: The Ranking Competition Between Documents'

Authors

Authors: 

 

 

 

Authors Info &amp; Claims

SIGIR '17: Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval

• August 2017 • Pages 465–474 • https://doi.org/10.1145/3077136.3080785

Published: 07 August 2017 Publication History

Nimrod Raifer,

Fiana Raiber,



Moshe Tennenholtz,

Oren Kurland



Next 

Pages 465–474

 Previous



SIGIR '17: Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval

Information Retrieval Meets Game Theory: The Ranking Competition Between Documents' Authors





In competitive search settings as the Web, there is an ongoing ranking competition between document authors (publishers) for certain

queries. The goal is to have documents highly ranked, and the means is document manipulation applied in response to rankings.

Existing retrieval models, and their theoretical underpinnings (e.g., the probability ranking principle), do not account for post-ranking

corpus dynamics driven by this strategic behavior of publishers. However, the dynamics has major effect on retrieval effectiveness

since it affects content availability in the corpus. Furthermore, while manipulation strategies observed over the Web were reported in

past literature, they were not analyzed as ongoing, and changing, post-ranking response strategies, nor were they connected to the

foundations of classical ad hoc retrieval models (e.g., content-based document-query surface level similarities and document

relevance priors). We present a novel theoretical and empirical analysis of the strategic behavior of publishers using these

foundations. Empirical analysis of controlled ranking competitions that we organized reveals a key strategy of publishers: making their

documents (gradually) become similar to documents ranked the highest in previous rankings. Our theoretical analysis of the ranking

competition as a repeated game, and its minmax regret equilibrium, yields a result that supports the merits of this publishing strategy.

We further show that it can be predicted with high accuracy, and without explicit knowledge of the ranking function, whether

documents will be promoted to the highest rank in our competitions. The prediction utilizes very few features which quantify changes

of documents, specifically with respect to those previously ranked the highest.

ABSTRACT

 Get Access

 







 16  563

 Sign in





IR

IR








References

1.

2.

3.

4.

5.

6.

7.

8.

9.

10.

11.

12.

13.

14.

15.

16.

17.

18.

19.

R. Aumann and M. Maschler 1995. Repeated Games with Incomplete Information. MIT Press.

Ran Ben-Basat and Elad Kravi 2016. The ranking game Proceedings of the 19th International Workshop on Web and Databases. 7.

Ran Ben-Basat, Moshe Tennenholtz, and Oren Kurland. 2015. The Probability Ranking Principle is Not Optimal in Adversarial Retrieval

Settings Proceedings of ICTIR. 51--60.

Michael Bendersky, W. Bruce Croft, and Yanlei Diao. 2011. Quality-biased ranking of web documents. In Proceedings of WSDM. 95--

104. 

Jaime G. Carbonell and Jade Goldstein 1998. The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing

Summaries Proceedings of SIGIR. 335--336.

Carlos Castillo and Brian D. Davison 2010. Adversarial Web Search. Foundations and Trends in Information Retrieval, Vol. 4, 5 (2010),

377--486. 

Gordon V. Cormack, Mark D. Smucker, and Charles L. A. Clarke. 2011. Efficient and effective spam filtering and re-ranking for large

web datasets. Informaltiom Retrieval Journal Vol. 14, 5 (2011), 441--465. 

Nilesh Dalvi, Pedro Domingos, Mausam, Sumit Sanghai, and Deepak Verma 2004. Adversarial Classification. In Proceedings of KDD.

99--108. 

Fernando Diaz. 2005. Regularizing Ad Hoc Retrieval Scores. In Proceedings of CIKM. 672--679. 

Ran El-Yaniv and Mordechai Nisenson 2010. On the Foundations of Adversarial Single-Class Classification. CoRR (2010).

Kfir Eliaz and Ran Spiegler 2011. A simple model of search engine pricing. The Economic Journal Vol. 121, 556 (2011), F329--F339. 

Kfir Eliaz and Ran Spiegler 2016. Search design and broad matching. American Economic Review Vol. 106, 3 (2016), 563--586. 

Jonathan L. Elsas and Susan T. Dumais 2010. Leveraging temporal dynamics of document content in relevance ranking Proceedings

of WSDM. 1--10.

Hui Fang, Tao Tao, and ChengXiang Zhai 2004. A formal study of information retrieval heuristics Proceedings of SIGIR. 49--56.

Norbert Fuhr. 2008. A probability ranking principle for interactive information retrieval. Information Retrieval Vol. 11, 3 (2008), 251--

265. 

Zoltán Gyöngyi and Hector Garcia-Molina 2005. Web Spam Taxonomy Proceedings of AIRWeb 2005, First International Workshop on

Adversarial Information Retrieval on the Web. 39--47.

Nathanael Hyafil and Craig Boutilier 2004. Regret Minimizing Equilibria and Mechanisms for Games with Strict Type Uncertainty

Proceedings of UAI. 268--277.

N. Jardine and C. J. van Rijsbergen 1971. The use of hierarchic clustering in information retrieval. Information Storage and Retrieval

Vol. 7, 5 (1971), 217--240. 

John D. Lafferty and Chengxiang Zhai 2001. Document language models, query models, and risk minimization for information retrieval

Proceedings of SIGIR. 111--119.


20.

21.

22.

23.

24.

25.

26.

27.

28.

29.

30.

31.

Tie-Yan Liu. 2011. Learning to Rank for Information Retrieval. Springer. I--XVII, 1--285 pages.

Alexandros Ntoulas, Marc Najork, Mark Manasse, and Dennis Fetterly 2006. Detecting spam web pages through content analysis.

Proceedings of WWW. 83--92.

Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter

Prettenhofer, Ron Weiss, Vincent Dubourg, Jake VanderPlas, Alexandre Passos, David Cournapeau, Matthieu Brucher, Matthieu Perrot,

and Edouard Duchesnay 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research Vol. 12 (2011), 2825--

2830.

Kira Radinsky and Paul N. Bennett 2013. Predicting content change on the web. In Proceedings of WSDM. 415--424. 

Justus J. Randolph. 2016. Online Kappa Calculator (2008). Retrieved February 6, http://justus.randolph.name/kappa. (2016).

Stephen E. Robertson. 1977. The Probability Ranking Principle in IR. Journal of Documentation (1977), 294--304. Reprinted in K.

Sparck Jones and P. Willett (eds), Readings in Information Retrieval, pp. 281--286, 1997.

Aécio S. R. Santos, Bruno Pasini, and Juliana Freire. 2016. A First Study on Temporal Dynamics of Topics on the Web Proceedings

of WWW. 849--854.

Marc Sloan and Jun Wang 2012. Dynamical information retrieval modelling: a portfolio-armed bandit machine approach Proceedings

WWW. 603--604.

Hong Wang, Wei Xing, Kaiser Asif, and Brian D. Ziebart. 2015. Adversarial Prediction Games for Multivariate Losses Proceedings of

NIPS. 2728--2736.

Qiang Wu, Christopher J. C. Burges, Krysta Marie Svore, and Jianfeng Gao 2010. Adapting boosting for information retrieval

measures. Information Retrieval Vol. 13, 3 (2010), 254--270. 

Grace Hui Yang, Marc Sloan, and Jun Wang 2016. Dynamic Information Retrieval Modeling. Morgan &amp; Claypool Publishers.

Yinan Zhang and Chengxiang Zhai 2015. Information Retrieval as Card Playing: A Formal Model for Optimizing Interactive Retrieval

Interface. In Proceedings of SIGIR. 685--694. 

Index Terms



Information Retrieval Meets Game Theory: The Ranking Competition Between Documents' Authors

Information systems

Information retrieval

Retrieval models and ranking

Search engine architectures and scalability

Adversarial retrieval

Recommendations

Towards a Game-Theoretic Framework for Information Retrieval


Read More

Read More

Read More

Check if you have access through your login credentials or your institution to get full access on this article.



Sign in

Get this Publication

Information

Contributors

Towards a Game-Theoretic Framework for Information Retrieval

Information Retrieval Meets Game Theory

When time meets information retrieval

Comments

Login options

Full Access

Published in


SIGIR '17: Proceedings of the 40th International ACM SIGIR Conference on Research and

Development in Information Retrieval

August 2017 1476 pages

ISBN:

9781450350228

DOI:

10.1145/3077136

General Chairs:

Noriko Kando,



Tetsuya Sakai,



Hideo Joho,Program Chairs:

Hang Li,



Arjen P. de Vries,

Ryen W. White

Copyright © 2017 ACM

Association for Computing Machinery

New York, NY, United States

Published: 7 August 2017

Request permissions about this article.

Request Permissions

game theory

ad hoc retrieval

ranking competition

Research-Article

SIGIR '17 Paper Acceptance Rate 78 of 362 submissions, 22%Overall Acceptance Rate 792 of 3,983 submissions, 20%

More



Publisher

Publication History

Permissions

Check for updates

Author Tags

Qualifiers

Acceptance Rates


Bibliometrics

Citations



16

View or Download as a PDF file.

 PDF

View online with eReader.

 eReader

Figures

Other

55

3

16

Total

Citations

View Citations

563

Total

Downloads

Downloads (Last 12 months)

Downloads (Last 6 weeks)



View Author Metrics

Article Metrics

Other Metrics

PDF Format

eReader




View Table Of Contents

https://dl.acm.org/doi/abs/10.1145/3077136.3080785



 Copy Link

Share this Publication link

Share on Social Media

















0





Categories

















About

















Join









Connect













The ACM Digital Library is published by the Association for Computing Machinery. Copyright © 2023 ACM, Inc.

Terms of Usage 

Privacy Policy 

Code of Ethics

 





