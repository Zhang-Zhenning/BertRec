


Dec 20, 2021

·

9 min read

Ultimate guide to Query Generation Model(GPT-3)

If a worm with 302 neurons is conscious, so says Ethics professor

David Chalmers, “then I am open to the idea that GPT-3 with 175bn

parameters is conscious too.”

What is GPT3?

Generative Pre-trained Transformer 3 GPT-3




Why it is so powerful?

Consider some of the limitations of GPT-3 listed below:

GPT-3 lacks long-term memory 

Lack of interpretability 

Limited input size 

Slow inference time 

GPT-3 suffers from bias 


How the transformer language model works?

transforming

encoder

vector

decoder

attention

weights

Engines Available

ase Series

davinci

curie

babbage

ada

Use cases:

B

D


Use cases:

Use cases:

Use cases:

Let’s look at the code for predicting Gremlin Queries

C

B

A




prompt1

Output for Promt1 input

prompt2

Output for prompt2 input

Building Knowledge Graph on Cosmos DB




Follow







