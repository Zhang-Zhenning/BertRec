


Published in

Towards Data Science



Jan 31, 2022

Â·

8 min read

Save

Training Hidden Markov Models

The Baum-Welch and Forward-Backward Algorithms

Two Parts to Train: the Markov Chain and the Observations








Baum-Welch Algorithm: the Fine Print

The Forward-Backward Algorithm


The Great Boogeyman: Local Optima

Different initial conditions in the Baum-Welch algorithm, even training on the same data, can yield wildly different

final outputs due to the presence of many local optima.


Parting Words

3

Hidden Markov Models

Data Science

Stochastic Process

Viterbi Algorithm

Algorithms




Follow

Your home for data science. A Medium publication sharing concepts, ideas and codes.



Read more from Towards Data Science





